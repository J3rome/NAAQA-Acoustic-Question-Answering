{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic functions -- Run Once\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "html_str = \"<style>.container { width:99% !important; }\\n\"\n",
    "html_str += \"div.cell.selected { border-left-width: 1px !important; }\\n\"\n",
    "html_str += \"div.output_scroll { resize: vertical !important }</style>\"\n",
    "display(HTML(html_str))\n",
    "\n",
    "# Move up one folder to reach the repo root\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths, Imports & Configs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.generic import get_answer_to_family_map, chain_load_experiment_stats, separate_stats_by_set\n",
    "from utils.generic import chain_load_batch_metrics\n",
    "from utils.notebook.result_analysis import load_experiment_predictions, sort_correct_incorrect_predictions\n",
    "from utils.notebook.result_analysis import plot_confusion_matrix, plot_predictions_distribution_per_question_family\n",
    "from utils.notebook.result_analysis import plot_predictions_confidence, plot_acc_loss_by_epoch, plot_predictions_confidence_gap\n",
    "from utils.notebook.generic import separate_preds_ground_truth\n",
    "\n",
    "root_data_path = \"data\"\n",
    "root_output_path = \"output_synced/training\"\n",
    "\n",
    "normalize_histograms = False\n",
    "normalize_confusion_matrices = False\n",
    "\n",
    "#experiment_name = \"v3_noReverbnoBackground_5k_40_inst_1024_win_50_overlap_BEAST\"\n",
    "#experiment_name = \"v3_fixed_5k_40_inst_1024_win_50_overlap_hpc-puget-necotis\"\n",
    "#experiment_name = \"v3_fixed_2k_40_inst_1024_win_50_overlap_BEAST-pool-batch-64\"\n",
    "experiment_name = \"CLEAR_50k_4_inst_1024_win_50_overlap_extractor_parallel_3_block_64_proj_40_epoch_67557_extractor\"\n",
    "experiment_date = \"2020-05-14_20h35\"\n",
    "#experiment_date = \"latest\"\n",
    "experiment_output_path = f\"{root_output_path}/{experiment_name}/{experiment_date}\"\n",
    "epoch_id = \"best\"\n",
    "\n",
    "data_name = \"CLEAR_50k_4_inst_1024_win_50_overlap\"\n",
    "data_path = f\"{root_data_path}/{data_name}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from files\n",
    "answer_to_family_map = get_answer_to_family_map(f'{data_path}/attributes.json', to_lowercase=True, reduced_text=True)\n",
    "answer_families = list(set(answer_to_family_map.values()))\n",
    "\n",
    "processed_predictions = {\n",
    "    'train': load_experiment_predictions(experiment_output_path, epoch_id, set_type='train', reduced_text=True),\n",
    "    'val': load_experiment_predictions(experiment_output_path, epoch_id, set_type='val', reduced_text=True),\n",
    "    'test': load_experiment_predictions(experiment_output_path, epoch_id, set_type='test', reduced_text=True)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "epoch_stats = chain_load_experiment_stats(experiment_output_path, cast_to_float=True)\n",
    "train_epoch_stats, val_epoch_stats = separate_stats_by_set(epoch_stats, set_types=['train', 'val'])\n",
    "batches_metrics = chain_load_batch_metrics(experiment_output_path, continue_training=True)\n",
    "import pandas as pd\n",
    "batches_metrics = pd.DataFrame(batches_metrics)\n",
    "\n",
    "# Sort correct & Incorrect predictions (Distinction between correct/incorrect question family when incorrect prediction)\n",
    "train_processed_predictions_sorted = sort_correct_incorrect_predictions(train_processed_predictions)\n",
    "val_processed_predictions_sorted = sort_correct_incorrect_predictions(val_processed_predictions)\n",
    "\n",
    "train_predictions, train_ground_truths = separate_preds_ground_truth(train_processed_predictions, attribute=\"ground_truth_answer_family\")\n",
    "val_predictions, val_ground_truths = separate_preds_ground_truth(val_processed_predictions, attribute=\"ground_truth_answer_family\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_loss_by_epoch({'train': train_epoch_stats, 'val': val_epoch_stats})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_acc_loss_lr_by_batch(batches_metrics, smoothing_window=50, set_types=['train','val'], show_fig=False, fig_ax=None):\n",
    "    if fig_ax:\n",
    "        fig, axs = fig_ax\n",
    "    else:\n",
    "        fig, axs = plt.subplots(3,1)\n",
    "        \n",
    "    axs[0].set_title(\"Accuracy by batches\")\n",
    "    axs[1].set_title(\"Loss by batches\")\n",
    "    axs[2].set_title(\"Learning Rate by batches\")\n",
    "    \n",
    "    for set_type in set_types:\n",
    "        axs[0].plot(batches_metrics[f'{set_type}_acc'].rolling(smoothing_window).mean(), label=f\"{set_type.capitalize()} Accuracy\")\n",
    "        axs[1].plot(batches_metrics[f'{set_type}_loss'].rolling(smoothing_window).mean(), label=f\"{set_type.capitalize()} Loss\")\n",
    "        axs[2].plot(batches_metrics[f'{set_type}_lr'], label=f\"{set_type.capitalize()} LR\")\n",
    "        \n",
    "    for ax in axs:\n",
    "        ax.legend()\n",
    "    \n",
    "\n",
    "plot_acc_loss_lr_by_batch(batches_metrics, set_types=['train', 'val'], smoothing_window=500)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_predictions_families = [answer_to_family_map[p] for p in train_predictions['all']]\n",
    "train_ground_truths_families = [answer_to_family_map[p] for p in train_ground_truths['all']]\n",
    "val_predictions_families = [answer_to_family_map[p] for p in val_predictions['all']]\n",
    "val_ground_truths_families = [answer_to_family_map[p] for p in val_ground_truths['all']]\n",
    "\n",
    "plot_confusion_matrix(train_predictions_families, train_ground_truths_families, title=\"Train confusion matrix by answer Families\", normalize=normalize_confusion_matrices)\n",
    "fig, ax = plot_confusion_matrix(val_predictions_families, val_ground_truths_families, title=\"Val confusion matrix by answer Families\", normalize=normalize_confusion_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Might need to big_fig.tight_layout() after resizing the plot\n",
    "big_fig_train, ax = plot_confusion_matrix(train_predictions['all'], train_ground_truths['all'], title=\"Train confusion matrix\", normalize=normalize_confusion_matrices)\n",
    "big_fig_val, ax = plot_confusion_matrix(val_predictions['all'], val_ground_truths['all'], title=\"Val confusion matrix\", normalize=normalize_confusion_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for family in train_predictions.keys():\n",
    "    if family == 'all':\n",
    "        # All answer already plotted to make sure its the first\n",
    "        continue\n",
    "    \n",
    "    fig, ax = plot_confusion_matrix(train_predictions[family], train_ground_truths[family], title=f\"[{family.capitalize()}]Train confusion matrix\", normalize=normalize_confusion_matrices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for family in val_predictions.keys():\n",
    "    if family == 'all':\n",
    "        # All answer already plotted to make sure its the first\n",
    "        continue\n",
    "    \n",
    "    fig, ax = plot_confusion_matrix(val_predictions[family], val_ground_truths[family], title=f\"[{family.capitalize()}]Val confusion matrix\", normalize=normalize_confusion_matrices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.file import read_json\n",
    "def load_scenes(data_path, set_type):\n",
    "    \n",
    "    scenes = read_json(f\"{data_path}/scenes/CLEAR_{set_type}_scenes.json\")['scenes']\n",
    "    \n",
    "    for scene in scenes:\n",
    "        scene['total_duration'] = scene['silence_before'] + sum(o['duration'] + o['silence_after'] for o in scene['objects'])\n",
    "        \n",
    "    return scenes\n",
    "\n",
    "train_scenes = load_scenes(data_path, 'train')\n",
    "val_scenes = load_scenes(data_path, 'val')\n",
    "test_scenes = load_scenes(data_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_scenes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Plot accuracy based on duration -- We could simply create an histogram with durations separated into bins and average the value for a given bin\n",
    "#                                        -- We could also count how many questions are incorrect based on the duration <- I think this is better\n",
    "#                                        -- We could also refer to the answer confidence\n",
    "\n",
    "def get_prediction_scene_durations(scenes, predictions, key='correct')\n",
    "    key_true = []\n",
    "    key_false = []\n",
    "    for prediction in predictions:\n",
    "\n",
    "        scene_duration = scenes[prediction['scene_id']]['total_duration']\n",
    "        if prediction[key]:\n",
    "            key_true.append(scene_duration)\n",
    "        else:\n",
    "            key_false.append(scene_duration)\n",
    "            \n",
    "    return key_true, key_false\n",
    "\n",
    "correct_pred_durations, incorrect_pred_durations = get_prediction_scene_durations(test_scenes,)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.hist(correct_pred_durations, bins=10)\n",
    "ax.hist(incorrect_pred_durations, bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Correct/Incorrect predictions per family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_predictions_distribution_per_question_family(train_processed_predictions_sorted, val_processed_predictions_sorted, norm_hist=normalize_histograms, all_x_labels=answer_families)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse confidence in predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_predictions_confidence_gap(train_processed_predictions_sorted, val_processed_predictions_sorted, norm_hist=normalize_histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_predictions_confidence(train_processed_predictions_sorted, val_processed_predictions_sorted, norm_hist=normalize_histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for family in answer_families:\n",
    "    plot_predictions_confidence(train_processed_predictions_sorted, val_processed_predictions_sorted, question_family=family, norm_hist=normalize_histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_confidence_gap(train_processed_predictions_sorted, val_processed_predictions_sorted, norm_hist=normalize_histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for family in answer_families:\n",
    "    plot_predictions_confidence_gap(train_processed_predictions_sorted, val_processed_predictions_sorted, question_family=family, norm_hist=normalize_histograms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "film-aqa-torch-1.3",
   "language": "python",
   "name": "film-aqa-torch-1.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
