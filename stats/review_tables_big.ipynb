{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic functions -- Run Once\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "if os.getcwd().split('/')[-1] != \"film-aqa\":\n",
    "    # Move up one folder to reach the repo root\n",
    "    %cd ..\n",
    "\n",
    "from utils.notebook.generic import full_width_notebook\n",
    "\n",
    "full_width_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Paths, Imports & Configs\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "from utils.notebook.experiment_explorer import get_experiments, get_format_dicts\n",
    "from utils.notebook.pandas import color_by_multi_attribute\n",
    "from utils.notebook.pandas import sub_cols_with_cond_and_create_new_col, grouped_scatter, groupby_mean, convert_cols_to_int\n",
    "from utils.notebook.result_analysis import show_table\n",
    "\n",
    "root_data_path = \"data\"\n",
    "root_output_path = \"output_synced/training\"\n",
    "experiment_start_date = '2021-10-21'\n",
    "experiment_start_date = '2022-01-01'\n",
    "#experiment_start_date = None\n",
    "\n",
    "data_folder=\"data/CLEAR_50k_4_inst_audio\"\n",
    "data_folder=\"data/CLEAR_FINAL_50k_4_inst_audio\"\n",
    "# Retrieve all experiments infos\n",
    "experiments = get_experiments(root_output_path, data_folder=data_folder, min_date=experiment_start_date, question_type_analysis=True, cogent_analysis=True)\n",
    "\n",
    "all_random_seeds = {189369, 876944, 682421, 175326, 427438}\n",
    "\n",
    "# Per family columns\n",
    "family_order = ['instrument', 'note', 'brightness', 'loudness', 'boolean', 'exist', 'position', 'position_global', 'position_rel', 'count', 'count_compare', 'count_diff']\n",
    "reg = r'(_(?:with_rel_)?(?:no_rel_)?(?:no_or_)?(?:with_or_)?(?:with_.*_)?)test_acc'\n",
    "\n",
    "global_test_acc_cols = [c for c in experiments.columns if 'all' in c and 'train' not in c and 'val' not in c or c == 'test_acc']\n",
    "all_families_test_acc_cols = [c for c in experiments.columns if 'test_acc' in c and c != 'test_acc' and 'all' not in c and 'cogent' not in c]\n",
    "no_rel_family_test_acc_cols = sorted([c for c in all_families_test_acc_cols if 'no_rel_test_acc' in c], key=lambda x: family_order.index(re.sub(reg, '', x)))\n",
    "no_rel_with_filter_family_test_acc_cols = sorted([c for c in all_families_test_acc_cols if 'no_rel_with' in c], key=lambda x: family_order.index(re.sub(reg, '', x)))\n",
    "with_rel_family_test_acc_cols = sorted([c for c in all_families_test_acc_cols if 'with_rel' in c], key=lambda x: family_order.index(re.sub(reg, '', x)))\n",
    "no_or_family_test_acc_cols = sorted([c for c in all_families_test_acc_cols if 'no_or' in c], key=lambda x: family_order.index(re.sub(reg, '', x)))\n",
    "with_or_family_test_acc_cols = sorted([c for c in all_families_test_acc_cols if 'with_or' in c], key=lambda x: family_order.index(re.sub(reg, '', x)))\n",
    "family_test_acc_cols = set(all_families_test_acc_cols) - set(no_rel_family_test_acc_cols) - set(with_rel_family_test_acc_cols) - set(no_rel_with_filter_family_test_acc_cols) - set(no_or_family_test_acc_cols) - set(with_or_family_test_acc_cols)\n",
    "family_test_acc_cols = sorted(family_test_acc_cols, key=lambda x: family_order.index(re.sub(reg, '', x)))\n",
    "\n",
    "# Pretty printing\n",
    "format_dict, latex_format_dict = get_format_dicts()\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "sorted(experiments.columns.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic table parameters\n",
    "display_all_exp = False\n",
    "nb_results_to_keep = None\n",
    "remove_outliers = False\n",
    "show_missing_seeds = True\n",
    "show_count_col = True\n",
    "show_std = True and nb_results_to_keep is not None and nb_results_to_keep > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['train_acc', 'test_acc', 'random_seed']\n",
    "cols = ['prefix', 'malimo', 'hop_length', 'extractor_type', 'config', 'random_seed', 'test_acc', 'cogent_test_acc', 'n_mels', 'nb_trainable_param', 'date', 'train_time', 'mean_epoch_time', 'nb_epoch_trained', 'gpu_name', 'device', 'folder_dated']\n",
    "cols = ['prefix', 'malimo', 'hop_length', 'extractor_type', 'cogent_test_acc', 'nb_trainable_param', 'config', 'date']\n",
    "exp = experiments.sort_values('date', ascending=False)\n",
    "#exp = exp[exp['config'].str.contains('config_fix')]\n",
    "#exp.sort_values('config')[['config'] + cols]\n",
    "#exp.groupby('config').mean()[cols]\n",
    "exp[cols].style.format(format_dict)\n",
    "\n",
    "#exp['folder_dated'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colss = ['config', 'extractor_type', 'input_type', 'cogent_test_acc', 'date']\n",
    "\n",
    "exp[(exp['prefix'].str.contains('CLEAR_FINAL')) & (exp['extractor_type'].str.contains('Conv_2d')) & (exp['date'] >=experiment_start_date)][colss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = experiments\n",
    "\n",
    "t[(t['prefix'].str.contains('CLEAR_FINAL')) & (t['config'].str.contains(\"table_4\"))].sort_values('date', ascending=False)[['config', 'n_mels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "family_test_acc_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Table 3 - Extractor types - Per question type analysis\n",
    "\n",
    "def get_experiments_filters(df, start_date, dataset=\"CLEAR_FINAL\", g=256, j=4, m=128, malimo=False, n_mels=64, extractors=None, config_filter=None):\n",
    "    # Table 3 - Extractor types - Per question type analysis\n",
    "    # Static parameters :\n",
    "        # G = 4096\n",
    "        # J = 3\n",
    "        # M = 64\n",
    "        # ClassifierTopology = FCNisin\n",
    "        # C = 512\n",
    "        # H = 1024\n",
    "\n",
    "    # Variable parameters :\n",
    "        # Extractors Type = {Parallel, Interleaved, Resnet}\n",
    "    # -- Input parameters\n",
    "    \n",
    "    if extractors is None:\n",
    "        extractors = []\n",
    "    \n",
    "    filters = (df['prefix'].str.contains(dataset))\n",
    "    filters &= (df['date'] >= start_date)\n",
    "    filters &= (df['n_mels'] == n_mels)\n",
    "\n",
    "    # -- Text Processing\n",
    "    filters &= (df['rnn_state_size'] == g)              # G\n",
    "\n",
    "    # -- Coordconv\n",
    "    filters &= (df['extractor_spatial_location'] == 'None')\n",
    "    filters &= (df['stem_spatial_location'] == 'Both')\n",
    "    filters &= (df['resblock_spatial_location'] == 'Both')\n",
    "    filters &= (df['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "    # -- Resblocks\n",
    "    filters &= (df['nb_resblock'] == j)                    # J\n",
    "    filters &= (df['resblocks_out_chan'] == m)           # M\n",
    "\n",
    "    # -- Classifier\n",
    "    filters &= (df['classifier_conv_out'] == 512)          # C\n",
    "    filters &= (df['classifier_projection_out'] == 1024)    # H\n",
    "    \n",
    "    # -- Other\n",
    "    filters &= (df['reduce_lr_on_plateau'] == True)\n",
    "    filters &= (df['malimo'] == malimo)\n",
    "\n",
    "    # Variable Parameters (Input_type & Extractor)\n",
    "\n",
    "    input_1d_filter = (df['input_type'].str.contains('1D'))\n",
    "    input_1d_filter &= (df['n_fft'] == 512)\n",
    "    input_1d_filter &= (df['hop_length'] == 2048)\n",
    "    \n",
    "    resnet_extractor_filter = ( (df['extractor_type'].str.contains('Resnet')) &(df['spectrogram_repeat_channels'] == True) )\n",
    "    parallel_extractor_filters = ( (df['extractor_type'].str.contains('Parallel')) & input_1d_filter)\n",
    "    interleaved_extractor_filters = ( (df['extractor_type'].str.contains('Interleaved')) & input_1d_filter)\n",
    "    conv_2d_extractor_filters = ( df['extractor_type'].str.contains('Conv_2d') & input_1d_filter & ~df['config'].str.contains('resnet'))\n",
    "    \n",
    "    extractors = [e.lower() for e in extractors]\n",
    "    \n",
    "    extractors_filter = None\n",
    "    \n",
    "    if 'parallel' in extractors and 'interleaved' in extractors and 'conv_2d' in extractors and 'resnet' in extractors:\n",
    "        extractors_filter = ( parallel_extractor_filters | interleaved_extractor_filters | resnet_extractor_filter | conv_2d_extractor_filters)\n",
    "    elif 'parallel' in extractors and 'interleaved' in extractors and 'conv_2d' in extractors:\n",
    "        extractors_filter = ( parallel_extractor_filters | interleaved_extractor_filters | conv_2d_extractor_filters)\n",
    "    elif 'parallel' in extractors and 'interleaved' in extractors:\n",
    "        extractors_filter = ( parallel_extractor_filters | interleaved_extractor_filters)\n",
    "    elif 'parallel' in extractors and 'conv_2d' in extractors:\n",
    "        extractors_filter = ( parallel_extractor_filters | conv_2d_extractor_filters)\n",
    "    elif 'interleaved' in extractors and 'conv_2d' in extractors:\n",
    "        extractors_filter = ( interleaved_extractor_filters | conv_2d_extractor_filters)\n",
    "    elif 'conv_2d' in extractors:\n",
    "        extractors_filter = ( conv_2d_extractor_filters)\n",
    "    elif 'parallel' in extractors:\n",
    "        extractors_filter = ( parallel_extractor_filters)\n",
    "    elif 'interleaved' in extractors:\n",
    "        extractors_filter = ( interleaved_extractor_filters)\n",
    "    elif 'resnet' in extractors:\n",
    "        extractors_filter = ( resnet_extractor_filter )\n",
    "        \n",
    "    if extractors_filter is not None:                 \n",
    "        filters &= extractors_filter\n",
    "        \n",
    "    if config_filter is not None:\n",
    "        filters &= (df[config_filter['key']].str.contains(config_filter['value']))\n",
    "    \n",
    "    return filters\n",
    "\n",
    "\n",
    "extractors_results_filters = get_experiments_filters(experiments, experiment_start_date, g=4096, j=4, m=128, malimo=False, n_mels=64, extractors=None)\n",
    "\n",
    "\n",
    "\n",
    "#table_3_filters = get_table_extractor_type_mask(experiments, experiment_start_date)\n",
    "\n",
    "hardcoded_columns = {'extractor': {\n",
    "    'type': 'replace_groupby',\n",
    "    'values': [\n",
    "        'Parallel (Fig \\ref{fig:parallel_extractor})', \n",
    "        'Interleaved Time (Fig \\ref{fig:interlaced_extractor})',\n",
    "        '2D Conv',\n",
    "        'Interleaved Freq (Fig \\ref{fig:interlaced_extractor})',\n",
    "        'Resnet101 (Baseline)'\n",
    "    ]\n",
    "}}\n",
    "\n",
    "grouped_df = show_table(df=experiments,\n",
    "           filters=extractors_results_filters,\n",
    "           groupby_columns = ['extractor_type'],\n",
    "           acc_columns = ['cogent_test_acc'],# *family_test_acc_cols],\n",
    "           extra_columns = ['nb_trainable_param', 'malimo', 'config', 'queue', 'random_seed', 'date', 'gpu_name'],\n",
    "           #attribute_by_color = {c: 'CMRmap' for c in family_test_acc_cols},\n",
    "           hardcoded_cols= hardcoded_columns,\n",
    "           display_all=display_all_exp or True,\n",
    "           show_count_col=show_count_col,\n",
    "           format_dict=latex_format_dict,\n",
    "           inplace_std=show_std or True,\n",
    "           remove_outliers=remove_outliers,\n",
    "           #nb_to_keep=100,#nb_results_to_keep,\n",
    "           all_seeds=all_random_seeds if show_missing_seeds else None\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 3 -- Malimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Table 3 - Extractor types - Per question type analysis\n",
    "\n",
    "def get_table_extractor_type_malimo_mask(df, start_date, n_mels=64):\n",
    "    # Table 3 - Extractor types - Per question type analysis\n",
    "    # Static parameters :\n",
    "        # G = 4096\n",
    "        # J = 3\n",
    "        # M = 64\n",
    "        # ClassifierTopology = FCNisin\n",
    "        # C = 512\n",
    "        # H = 1024\n",
    "\n",
    "    # Variable parameters :\n",
    "        # Extractors Type = {Parallel, Interleaved, Resnet}\n",
    "    # -- Input parameters\n",
    "    filters = (df['prefix'].str.contains('CLEAR_FINAL'))\n",
    "    filters &= (df['date'] >= start_date)\n",
    "    filters &= (df['n_mels'] == n_mels)\n",
    "    filters &= (df['resized_width'].isnull())\n",
    "    filters &= (~df['normalisation'].str.contains(\"imagenet_stats\", na=False))\n",
    "\n",
    "    # -- Text Processing\n",
    "    filters &= (df['rnn_state_size'] == 4096)              # G\n",
    "\n",
    "    # -- Coordconv\n",
    "    filters &= (df['extractor_spatial_location'] == 'None')\n",
    "    filters &= (df['stem_spatial_location'] == 'Both')\n",
    "    filters &= (df['resblock_spatial_location'] == 'Both')\n",
    "    filters &= (df['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "    # -- Resblocks\n",
    "    filters &= (df['nb_resblock'] == 4)                    # J\n",
    "    filters &= (df['resblocks_out_chan'] == 128)           # M\n",
    "\n",
    "    # -- Classifier\n",
    "    filters &= (df['classifier_conv_out'] == 512)          # C\n",
    "    filters &= (df['classifier_projection_out'] == 1024)    # H\n",
    "    \n",
    "    # -- Other\n",
    "    filters &= (df['reduce_lr_on_plateau'] == True)\n",
    "    filters &= (df['malimo'] == True)\n",
    "\n",
    "    # Variable Parameters (Input_type & Extractor)\n",
    "    filters &= (~df['RGB_colormap'].str.contains('Blues', na=False))\n",
    "\n",
    "    input_1d_filter = (df['input_type'].str.contains('1D'))\n",
    "    input_1d_filter &= (df['n_fft'] == 512)\n",
    "    input_1d_filter &= (df['hop_length'] == 2048)\n",
    "    \n",
    "    resnet_extractor_filter = ( (df['extractor_type'].str.contains('Resnet')) & (df['spectrogram_repeat_channels'] == True) )\n",
    "    parallel_extractor_filters = ( (df['extractor_type'].str.contains('Parallel')) & input_1d_filter)# & df['config'].str.contains('table_2_parallel_extractor') )\n",
    "    interleaved_extractor_filters = ( (df['extractor_type'].str.contains('Interleaved')) & input_1d_filter)# & df['config'].str.contains('table_2_interleaved_extractor') )\n",
    "    \n",
    "    conv_2d_extractor_filters = ( df['extractor_type'].str.contains('Conv_2d') & input_1d_filter & df['prefix'].str.contains(\"CLEAR_FINAL\") & ~df['config'].str.contains('resnet'))\n",
    "    \n",
    "    extractors = ( parallel_extractor_filters | interleaved_extractor_filters | resnet_extractor_filter | conv_2d_extractor_filters)\n",
    "                               \n",
    "    filters &= extractors\n",
    "    \n",
    "    return filters\n",
    "\n",
    "filters = get_table_extractor_type_malimo_mask(experiments, experiment_start_date)\n",
    "\n",
    "hardcoded_columns = {'extractor': {\n",
    "    'type': 'replace_groupby',\n",
    "    'values': [\n",
    "        'Parallel (Fig \\ref{fig:parallel_extractor})', \n",
    "        'Interleaved Time (Fig \\ref{fig:interlaced_extractor})',\n",
    "        'Resnet101 (Baseline)', \n",
    "        'Interleaved Freq (Fig \\ref{fig:interlaced_extractor})',\n",
    "        '2D Conv'\n",
    "    ]\n",
    "}}\n",
    "\n",
    "grouped_df = show_table(df=experiments,\n",
    "           filters=filters,\n",
    "           groupby_columns = ['extractor_type'],\n",
    "           acc_columns = ['cogent_test_acc'],# *family_test_acc_cols],\n",
    "           extra_columns = ['nb_trainable_param'],\n",
    "           #attribute_by_color = {c: 'CMRmap' for c in family_test_acc_cols},\n",
    "           #hardcoded_cols= hardcoded_columns,\n",
    "           #display_all=display_all_exp or True,\n",
    "           show_count_col=show_count_col,\n",
    "           format_dict=latex_format_dict,\n",
    "           inplace_std=show_std,\n",
    "           remove_outliers=remove_outliers,\n",
    "           #nb_to_keep=100,#nb_results_to_keep,\n",
    "           all_seeds=all_random_seeds if show_missing_seeds else None\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Table 4 - Coordinate maps placement - Interleaved\n",
    "\n",
    "def get_table_coordconv_placement_filters(df, start_date, allow_multi_both=False, only_final=True, n_mels=64):\n",
    "    prefixes = ['CLEAR', 'CLEAR_FINAL']\n",
    "    if only_final:\n",
    "        prefixes = prefixes[1:]\n",
    "        \n",
    "    filters = (df['prefix'].isin(prefixes))\n",
    "    #filters &= (df['date'] >= start_date)\n",
    "    \n",
    "    # -- Input parameters\n",
    "    filters &= (df['input_type'].str.contains('1D'))\n",
    "    filters &= (df['n_fft'] == 512)\n",
    "    filters &= (df['hop_length'] == 2048)\n",
    "    filters &= (df['resized_width'].isnull())\n",
    "    filters &= (df['n_mels'] == n_mels)\n",
    "\n",
    "    # -- Text Processing\n",
    "    filters &= (df['rnn_state_size'] == 4096)              # G\n",
    "\n",
    "    # -- Extractor\n",
    "    #filters &= (df['extractor_type'].str.contains('Interleaved_Time_First'))\n",
    "    filters &= (df['extractor_type'].str.contains('Parallel'))\n",
    "    #filters &= (df['extractor_nb_block'] == 3)             # K\n",
    "    #filters &= (df['extractor_filters'] == [8, 16, 32])   # N\n",
    "    #filters &= (df['extractor_projection_size'] == 64)     # P\n",
    "\n",
    "    # -- Resblocks\n",
    "    filters &= (df['nb_resblock'] == 4)                   # J       <---- FIXME: Make sure this is the good values\n",
    "    filters &= (df['resblocks_out_chan'] == 128)           # M       <---- FIXME: Make sure this is the good values\n",
    "\n",
    "    # -- Classifier\n",
    "    filters &= (df['classifier_conv_out'] == 512)          # C      <---- FIXME: Make sure this is the good values\n",
    "    filters &= (df['classifier_projection_out'] == 1024)    # H      <---- FIXME: Make sure this is the good values\n",
    "\n",
    "    # Variable Parameters (CoordConv)\n",
    "    filters &= (df['extractor_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "    filters &= (df['stem_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "    filters &= (df['resblock_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "    filters &= (df['classifier_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "    \n",
    "    if not allow_multi_both:\n",
    "        filters &= ~(df['resblock_spatial_location'].str.contains('Both') & df['classifier_spatial_location'].str.contains('Both'))\n",
    "\n",
    "    # -- Other\n",
    "    filters &= (df['reduce_lr_on_plateau'] == True)\n",
    "    filters &= (df['malimo'] != True)\n",
    "    \n",
    "    return filters\n",
    "\n",
    "# Table 7 - CoordConv placement\n",
    "    # K = 3\n",
    "    # N_0 = 8\n",
    "    # P = 64\n",
    "    # G = 1024\n",
    "    # J = 3\n",
    "    # M = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "    \n",
    "filters = get_table_coordconv_placement_filters(experiments, experiment_start_date, allow_multi_both=False)\n",
    "\n",
    "grouped_df = show_table(df=experiments,\n",
    "           filters=filters,\n",
    "           groupby_columns = ['extractor_spatial_location', 'stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location'],\n",
    "           acc_columns = ['train_acc', 'best_val_acc', 'cogent_test_acc'],\n",
    "           sort_by_col = 'cogent_test_acc',\n",
    "           extra_columns = ['config', 'date'],\n",
    "           #display_all=display_all_exp or True,\n",
    "           show_count_col=show_count_col,\n",
    "           format_dict=latex_format_dict,\n",
    "           inplace_std=show_std or True,\n",
    "           remove_outliers=remove_outliers,\n",
    "           nb_to_keep=nb_results_to_keep,\n",
    "           all_seeds=all_random_seeds if show_missing_seeds else None\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 5 - Coordinate maps type - Interleaved -> Resblock\n",
    "\n",
    "def get_per_q_type_coordconv_mask(df, coordconv_placement_mask, position):\n",
    "    # Variable Parameters (CoordConv)\n",
    "    coordconv_placement_mask &= df['extractor_spatial_location'].str.contains('None')\n",
    "    \n",
    "    if position == \"Resblock\":\n",
    "        specific_configs = ((df['stem_spatial_location'].str.contains('None')) & (df['resblock_spatial_location'].str.contains('Time')) & (df['classifier_spatial_location'].str.contains('None')))\n",
    "        specific_configs |= ((df['stem_spatial_location'].str.contains('None')) & (df['resblock_spatial_location'].str.contains('Freq')) & (df['classifier_spatial_location'].str.contains('None')))\n",
    "        specific_configs |= ((df['stem_spatial_location'].str.contains('None')) & (df['resblock_spatial_location'].str.contains('Both')) & (df['classifier_spatial_location'].str.contains('None')))\n",
    "        specific_configs |= ((df['stem_spatial_location'].str.contains('None')) & (df['resblock_spatial_location'].str.contains('None')) & (df['classifier_spatial_location'].str.contains('None')))\n",
    "    elif position == \"Stem\":\n",
    "        specific_configs = ((df['stem_spatial_location'].str.contains('Time')) & (df['resblock_spatial_location'].str.contains('None')) & (df['classifier_spatial_location'].str.contains('None')))\n",
    "        specific_configs |= ((df['stem_spatial_location'].str.contains('Freq')) & (df['resblock_spatial_location'].str.contains('None')) & (df['classifier_spatial_location'].str.contains('None')))\n",
    "        specific_configs |= ((df['stem_spatial_location'].str.contains('Both')) & (df['resblock_spatial_location'].str.contains('None')) & (df['classifier_spatial_location'].str.contains('None')))\n",
    "        specific_configs |= ((df['stem_spatial_location'].str.contains('None')) & (df['resblock_spatial_location'].str.contains('None')) & (df['classifier_spatial_location'].str.contains('None')))\n",
    "    elif position == \"Classifier\":\n",
    "        specific_configs = ((df['stem_spatial_location'].str.contains('None')) & (df['resblock_spatial_location'].str.contains('None')) & (df['classifier_spatial_location'].str.contains('Time')))\n",
    "        specific_configs |= ((df['stem_spatial_location'].str.contains('None')) & (df['resblock_spatial_location'].str.contains('None')) & (df['classifier_spatial_location'].str.contains('Freq')))\n",
    "        specific_configs |= ((df['stem_spatial_location'].str.contains('None')) & (df['resblock_spatial_location'].str.contains('None')) & (df['classifier_spatial_location'].str.contains('Both')))\n",
    "        specific_configs |= ((df['stem_spatial_location'].str.contains('None')) & (df['resblock_spatial_location'].str.contains('None')) & (df['classifier_spatial_location'].str.contains('None')))\n",
    "    else:\n",
    "        assert False, \"Invalid position\"\n",
    "        \n",
    "    coordconv_placement_mask &= specific_configs\n",
    "    \n",
    "    return coordconv_placement_mask\n",
    "\n",
    "\n",
    "filters = get_table_coordconv_placement_filters(experiments, experiment_start_date, allow_multi_both=True)\n",
    "filters = get_per_q_type_coordconv_mask(experiments, filters, position=\"Stem\")\n",
    "\n",
    "hardcoded_columns={'configuration':{\n",
    "                   'type': 'replace_groupby',\n",
    "                   'values': [\"Time only\", \"Time \\& Freq\", \"None\", \"Freq only\"]\n",
    "               }\n",
    "           }\n",
    "\n",
    "grouped_df = show_table(df=experiments,\n",
    "           filters=filters,\n",
    "           groupby_columns = ['extractor_spatial_location', 'stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location'],\n",
    "           acc_columns = ['test_acc', *family_test_acc_cols],\n",
    "           attribute_by_color = {c: 'CMRmap' for c in family_test_acc_cols},\n",
    "           hardcoded_cols= hardcoded_columns,\n",
    "           display_all=display_all_exp,\n",
    "           #show_count_col=show_count_col,\n",
    "           format_dict=latex_format_dict,\n",
    "           inplace_std=show_std or True,\n",
    "           remove_outliers=remove_outliers,\n",
    "           nb_to_keep=nb_results_to_keep,\n",
    "           all_seeds=all_random_seeds if show_missing_seeds else None\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Table 6 - GRU Reduction - Interleaved\n",
    "\n",
    "def get_gru_reduction_df_mask(df, start_date, extractor_type=\"interleaved\", only_final=True, n_mels=64):\n",
    "    # Table 6 - GRU Reduction\n",
    "    # Static Parameters :\n",
    "        # Extractor = {extractor_type}\n",
    "        # J = 4\n",
    "        # M = 128\n",
    "        # ClassifierTopology = FCN\n",
    "        # C = 512\n",
    "        # H = 1024\n",
    "        # K = 3\n",
    "        # N = [8, 16, 32]\n",
    "        # P = 64\n",
    "    # Variable Parameters: \n",
    "        # G={4096,2048, 1024, 512, 256}\n",
    "    prefixes = ['CLEAR', 'CLEAR_FINAL']\n",
    "    if only_final:\n",
    "        prefixes = prefixes[1:]\n",
    "        \n",
    "    filters = (df['prefix'].isin(prefixes))\n",
    "    filters &= (df['date'] >= start_date)\n",
    "\n",
    "    # -- Input parameters\n",
    "    filters &= (df['input_type'].str.contains('1D'))\n",
    "    filters &= (df['n_fft'] == 512)\n",
    "    filters &= (df['hop_length'] == 2048)\n",
    "    filters &= (df['resized_width'].isnull())\n",
    "    filters &= (df['n_mels'] == n_mels)\n",
    "\n",
    "    # -- Coordconv\n",
    "    filters &= (df['extractor_spatial_location'] == 'None')\n",
    "    filters &= (df['stem_spatial_location'] == 'Both')\n",
    "    filters &= (df['resblock_spatial_location'] == 'Both')\n",
    "    filters &= (df['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "    # -- Extractor\n",
    "    extractor_type = 'Interleaved_Time_First' if extractor_type == \"interleaved\" else 'Parallel'\n",
    "        \n",
    "    #filters &= (df['extractor_type'].str.contains('Interleaved_Time_First'))\n",
    "    filters &= (df['extractor_type'].str.contains(extractor_type))\n",
    "    filters &= (experiments['extractor_nb_block'] == 3)             # K\n",
    "    #filters &= (experiments['extractor_filters'] == [8, 16, 32])   # N\n",
    "    filters &= (experiments['extractor_projection_size'] == 64)     # P      <---- FIXME : Might want to try with 32\n",
    "\n",
    "    # -- Resblocks\n",
    "    filters &= (df['nb_resblock'] == 4)                    # J\n",
    "    filters &= (df['resblocks_out_chan'] == 128)           # M\n",
    "\n",
    "    # -- Classifier\n",
    "    filters &= (df['classifier_conv_out'] == 512)           # C \n",
    "    filters &= (df['classifier_projection_out'] == 1024)    # H\n",
    "\n",
    "    # Variable Parameters (Text-Processing GRU units)\n",
    "    filters &= (df['rnn_state_size'].isin([4096, 2048, 1024, 512, 256])) # G\n",
    "    \n",
    "    # -- Other\n",
    "    filters &= (df['reduce_lr_on_plateau'] == True)\n",
    "    filters &= ((df['config'].str.contains('table_6')) | (df['config'].str.contains('table_3')))\n",
    "    filters &= (df['malimo'] != True)\n",
    "    \n",
    "    return filters\n",
    "\n",
    "\n",
    "extractor_type = \"interleaved\"\n",
    "extractor_type = \"parallel\"\n",
    "filters = get_gru_reduction_df_mask(experiments, experiment_start_date, extractor_type=extractor_type)\n",
    "\n",
    "grouped_df = show_table(df=experiments,\n",
    "           filters=filters,\n",
    "           groupby_columns = ['rnn_state_size'],\n",
    "           acc_columns = ['train_acc', 'best_val_acc', 'cogent_test_acc'],\n",
    "           extra_columns = ['nb_trainable_param_million'],#, 'reduce_lr_on_plateau'],\n",
    "           sort_by_col= 'cogent_test_acc',\n",
    "           display_all=display_all_exp or True,\n",
    "           #show_count_col=show_count_col,\n",
    "           format_dict=latex_format_dict,\n",
    "           inplace_std=show_std or True,\n",
    "           remove_outliers=remove_outliers,\n",
    "           nb_to_keep=2,#nb_results_to_keep,\n",
    "           all_seeds=all_random_seeds if show_missing_seeds else None\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Table 7 - Classifier Reduction - Interleaved\n",
    "\n",
    "def get_classifier_reduction_df_mask(df, start_date, nb_gru=512, extractor_type='interleaved', only_final=True, n_mels=64):\n",
    "    # Table 7 - Classifier Topologies\n",
    "    # Static Parameters :\n",
    "        # Extractor = {extractor_type}\n",
    "        # G = 1024\n",
    "        # J = 4\n",
    "        # M = 128\n",
    "        # K = 3\n",
    "        # N = [8, 16, 32]\n",
    "        # P = 64\n",
    "    # Variable Parameters :\n",
    "        # Classifier Topology = {Fcn, Conv}\n",
    "        # C = {512, 256, 128, None}\n",
    "        # H = {1024, 512, 256, None}\n",
    "        \n",
    "    prefixes = ['CLEAR', 'CLEAR_FINAL']\n",
    "    if only_final:\n",
    "        prefixes = prefixes[1:]\n",
    "    filters = (df['prefix'].isin(prefixes))\n",
    "    filters &= (df['date'] >= start_date)\n",
    "\n",
    "    # -- Input parameters\n",
    "    filters &= (df['input_type'].str.contains('1D'))\n",
    "    filters &= (df['n_fft'] == 512)\n",
    "    filters &= (df['hop_length'] == 2048)\n",
    "    filters &= (df['resized_width'].isnull())\n",
    "    filters &= (df['n_mels'] == n_mels)\n",
    "\n",
    "    # -- Text Processing\n",
    "    filters &= (df['rnn_state_size'] == nb_gru)              # G\n",
    "\n",
    "    # -- Coordconv\n",
    "    filters &= (df['extractor_spatial_location'] == 'None')\n",
    "    filters &= (df['stem_spatial_location'] == 'Both')\n",
    "    filters &= (df['resblock_spatial_location'] == 'Both')\n",
    "    filters &= (df['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "    # -- Extractor\n",
    "    extractor_type = 'Interleaved_Time_First' if extractor_type == \"interleaved\" else 'Parallel'\n",
    "        \n",
    "    filters &= (df['extractor_type'].str.contains(extractor_type))\n",
    "    #filters &= (experiments['extractor_nb_block'] == 3)             # K\n",
    "    #filters &= (experiments['extractor_filters'] == [8, 16, 32])   # N\n",
    "    #filters &= (experiments['extractor_projection_size'] == 64)     # P      <---- FIXME : Might want to try with 32\n",
    "\n",
    "    # -- Resblocks\n",
    "    filters &= (df['nb_resblock'] == 4)                    # J\n",
    "    filters &= (df['resblocks_out_chan'] == 128)           # M\n",
    "\n",
    "    # Variable Parameters (Classifier Topologies)\n",
    "    filters &= (df['classifier_type'].str.contains('fcn'))\n",
    "    filters &= (df['classifier_conv_out'].isin([512, 256, 128]))          # C\n",
    "    filters &= (df['classifier_projection_out'].isin([1024, 512, 256]))   # H\n",
    "    \n",
    "    # -- Other\n",
    "    filters &= (df['reduce_lr_on_plateau'] == True)\n",
    "    \n",
    "    return filters\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "extractor_type = \"interleaved\"\n",
    "extractor_type = \"parallel\"\n",
    "filters = get_classifier_reduction_df_mask(experiments, experiment_start_date, nb_gru=512, extractor_type=extractor_type)\n",
    "grouped_df = show_table(df=experiments,\n",
    "           filters=filters,\n",
    "           groupby_columns = ['rnn_state_size', 'classifier_conv_out', 'classifier_projection_out'],\n",
    "           acc_columns = ['train_acc', 'best_val_acc', 'cogent_test_acc'],\n",
    "           extra_columns = ['nb_trainable_param_million', 'queue'],#, 'reduce_lr_on_plateau'],\n",
    "           sort_by_col='cogent_test_acc',\n",
    "           display_all=display_all_exp,\n",
    "           show_count_col=show_count_col,\n",
    "           format_dict=latex_format_dict,\n",
    "           inplace_std=show_std or True,\n",
    "           remove_outliers=remove_outliers,\n",
    "           nb_to_keep=nb_results_to_keep,\n",
    "           all_seeds=all_random_seeds if show_missing_seeds else None\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Table 8 - Resblock Reduction - Interleaved\n",
    "def get_resblock_reduction_df_mask(df, start_date, extractor_type, nb_gru=1024, c=256, h=512, only_final=True, n_mels=64):\n",
    "    # Table 8 - Resblocks\n",
    "    # Static parameters\n",
    "        # Extractor = {extractor_type}\n",
    "        # K = 3\n",
    "        # N = [8, 16, 32]\n",
    "        # P = 64\n",
    "        # ClassifierTopology = FCN\n",
    "        # C = 256\n",
    "        # H = 512\n",
    "    # Variable Parameters\n",
    "        # J = {4, 3, 2, 1}\n",
    "        # M = {128, 64, 32}\n",
    "\n",
    "    prefixes = ['CLEAR', 'CLEAR_FINAL']\n",
    "    if only_final:\n",
    "        prefixes = prefixes[1:]\n",
    "    filters = (df['prefix'].isin(prefixes))\n",
    "    filters &= (df['date'] >= start_date)\n",
    "\n",
    "    # -- Input parameters\n",
    "    filters &= (df['input_type'].str.contains('1D'))\n",
    "    filters &= (df['n_fft'] == 512)\n",
    "    filters &= (df['hop_length'] == 2048)\n",
    "    filters &= (df['resized_width'].isnull())\n",
    "    filters &= (df['n_mels'] == n_mels)\n",
    "\n",
    "    # -- Text Processing\n",
    "    filters &= (experiments['rnn_state_size'] == nb_gru)              # G\n",
    "\n",
    "    # -- Coordconv\n",
    "    filters &= (df['extractor_spatial_location'] == 'None')\n",
    "    filters &= (df['stem_spatial_location'] == 'Both')\n",
    "    filters &= (df['resblock_spatial_location'] == 'Both')\n",
    "    filters &= (df['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "    # -- Extractor\n",
    "    filters &= experiments['extractor_type'].str.contains(extractor_type)\n",
    "    \n",
    "    if 'Parallel' in extractor_type or 'Interleaved' in extractor_type:\n",
    "        filters &= (df['extractor_nb_block'] == 3)             # K\n",
    "        #filters &= (df['extractor_filters'] == [8, 16, 32])   # N\n",
    "        filters &= (df['extractor_projection_size'] == 64)     # P      <---- FIXME : Might want to try with 32\n",
    "\n",
    "    # -- Classifier\n",
    "    filters &= (df['classifier_conv_out'] == c)          # C      <---- FIXME: Make sure this is the good values\n",
    "    filters &= (df['classifier_projection_out'] == h)    # H      <---- FIXME: Make sure this is the good values\n",
    "\n",
    "    # Variable Parameters (Resblocks)\n",
    "    filters &= (df['nb_resblock'] <= 4)                    # J\n",
    "    filters &= (df['resblocks_out_chan'].isin([128, 64, 32]))           # M\n",
    "\n",
    "    # -- Other\n",
    "    filters &= (df['reduce_lr_on_plateau'] == True)\n",
    "    filters &= (~df['config'].str.contains('last_review_table_6_256_gru'))\n",
    "    \n",
    "    return filters\n",
    "\n",
    "filters = get_resblock_reduction_df_mask(experiments, experiment_start_date, 'Parallel', nb_gru=512, c=512, h=1024)\n",
    "\n",
    "grouped_df = show_table(df=experiments,\n",
    "           filters=filters,\n",
    "           groupby_columns = ['nb_resblock', 'resblocks_out_chan'],\n",
    "           acc_columns = ['train_acc', 'best_val_acc', 'test_acc'],\n",
    "           sort_by_col='test_acc',\n",
    "           extra_columns = ['nb_trainable_param_million'],\n",
    "           #display_all=display_all_exp or True,\n",
    "           #show_count_col=show_count_col,\n",
    "           format_dict=latex_format_dict,\n",
    "           inplace_std=show_std or True,\n",
    "           remove_outliers=remove_outliers,\n",
    "           #nb_to_keep=2,#nb_results_to_keep,\n",
    "           all_seeds=all_random_seeds if show_missing_seeds else None\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Table 9 - Interleaved reduction\n",
    "def get_interleaved_reduction_df_mask(df, start_date, nb_resblocks=4, m=128, only_final=True, n_mels=64):\n",
    "    # Table 9 - Interleaved reduction\n",
    "    # Static parameters\n",
    "        # Extractor = Interleaved\n",
    "        # N = [8, 16, 32]\n",
    "        # J = 4\n",
    "        # M = \n",
    "        # G = 512\n",
    "        # ClassifierTopology = FCN\n",
    "        # C = 256\n",
    "        # H = 1024\n",
    "    # Variable Parameters\n",
    "        # K = {4, 3, 2}\n",
    "        # P = {128, 64, 32, --}\n",
    "\n",
    "    prefixes = ['CLEAR', 'CLEAR_FINAL']\n",
    "    if only_final:\n",
    "        prefixes = prefixes[1:]\n",
    "    filters = (df['prefix'].isin(prefixes))\n",
    "    filters &= (df['date'] >= start_date)\n",
    "\n",
    "    # -- Input parameters\n",
    "    filters &= (df['input_type'].str.contains('1D'))\n",
    "    filters &= (df['n_fft'] == 512)\n",
    "    filters &= (df['hop_length'] == 2048)\n",
    "    filters &= (df['resized_width'].isnull())\n",
    "    filters &= (df['n_mels'] == n_mels)\n",
    "\n",
    "    # -- Text Processing\n",
    "    filters &= (df['rnn_state_size'] == 512)              # G\n",
    "\n",
    "    # -- Coordconv\n",
    "    filters &= (df['extractor_spatial_location'] == 'None')\n",
    "    filters &= (df['stem_spatial_location'] == 'Both')\n",
    "    filters &= (df['resblock_spatial_location'] == 'Both')\n",
    "    filters &= (df['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "    # -- Extractor\n",
    "    #filters &= df['extractor_type'].str.contains('Parallel')\n",
    "\n",
    "    # Resblocks\n",
    "    filters &= (df['nb_resblock'] == nb_resblocks)        # J\n",
    "    filters &= (df['resblocks_out_chan'] == m)           # M\n",
    "        \n",
    "    # -- Classifier\n",
    "    #filters &= (df['classifier_conv_out'] == 256)          # C      <---- FIXME: Make sure this is the good values\n",
    "    #filters &= (df['classifier_projection_out'] == 1024)    # H      <---- FIXME: Make sure this is the good values\n",
    "\n",
    "    # Variable Parameters (Extractor)\n",
    "    #filters &= (df['extractor_nb_block'].isin([4,3,2]))   # K \n",
    "    #filters &= (df['extractor_projection_size'].isin([128, 64, 32, None]))   # P\n",
    "\n",
    "    # -- Other\n",
    "    filters &= (df['reduce_lr_on_plateau'] == True)\n",
    "    #filters &= (df['queue'].str.contains('reduction_mel'))\n",
    "    \n",
    "    return filters\n",
    "\n",
    "filters = get_interleaved_reduction_df_mask(experiments, experiment_start_date, nb_resblocks=4, m=128)\n",
    "\n",
    "grouped_df = show_table(df=experiments,\n",
    "           filters=filters,\n",
    "           groupby_columns = ['extractor_nb_block', 'extractor_projection_size'],\n",
    "           acc_columns = ['train_acc', 'best_val_acc', 'test_acc'],\n",
    "           extra_columns = ['nb_trainable_param_million', 'date', 'random_seed', 'config', 'queue'],\n",
    "           display_all=display_all_exp or True,\n",
    "           show_count_col=show_count_col,\n",
    "           format_dict=latex_format_dict,\n",
    "           inplace_std=show_std,\n",
    "           remove_outliers=remove_outliers,\n",
    "           #nb_to_keep=2,#nb_results_to_keep,\n",
    "           all_seeds=all_random_seeds if show_missing_seeds else None\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['prefix','malimo', 'config', 'extractor_projection_size']\n",
    "exp = experiments[(experiments[\"config\"].str.contains(\"table_9\")) & experiments['config'].str.contains(\"P_0\")]\n",
    "exp[cols].style.format(format_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use best config from resblock reduction\n",
    "filters = get_resblock_reduction_df_mask(experiments, 'Interleaved_Time', nb_gru=512, c=256, h=1024) & (experiments['nb_resblock'] == 4) & (experiments['resblocks_out_chan'] == 64)\n",
    "\n",
    "grouped_overall_df = show_table(df=experiments,\n",
    "           filters=filters,\n",
    "           groupby_columns = ['nb_resblock', 'resblocks_out_chan'],\n",
    "           acc_columns = ['test_acc', *family_test_acc_cols],\n",
    "           attribute_by_color = {c: 'CMRmap' for c in family_test_acc_cols},\n",
    "           #extra_columns = ['nb_trainable_param_million'],\n",
    "           #hardcoded_cols=hardcoded_columns,\n",
    "           display_all=display_all_exp,\n",
    "           show_count_col=show_count_col,\n",
    "           format_dict=latex_format_dict,\n",
    "           inplace_std=False,\n",
    "           remove_outliers=remove_outliers,\n",
    "           nb_to_keep=nb_results_to_keep,\n",
    "           all_seeds=all_random_seeds if show_missing_seeds else None,\n",
    "           print_latex=False\n",
    "          )\n",
    "\n",
    "\n",
    "grouped_df = show_table(df=experiments,\n",
    "           filters=filters,\n",
    "           groupby_columns = ['nb_resblock', 'resblocks_out_chan'],\n",
    "           acc_columns = ['test_acc', *no_rel_family_test_acc_cols, *with_rel_family_test_acc_cols],\n",
    "           #extra_columns = ['nb_trainable_param_million'],\n",
    "           #hardcoded_cols=hardcoded_columns,\n",
    "           display_all=display_all_exp | True,\n",
    "           show_count_col=show_count_col,\n",
    "           format_dict=latex_format_dict,\n",
    "           inplace_std=False,\n",
    "           remove_outliers=remove_outliers,\n",
    "           nb_to_keep=nb_results_to_keep,\n",
    "           all_seeds=all_random_seeds if show_missing_seeds else None,\n",
    "           print_latex=False\n",
    "          )\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "def show_values_on_bars(axs):\n",
    "    def _show_on_single_plot(ax):        \n",
    "        for p in ax.patches:\n",
    "            _x = p.get_x() + p.get_width() / 2\n",
    "            _y = p.get_y() + p.get_height() + 0.5\n",
    "            value = p.get_height()\n",
    "            if value == 0:\n",
    "                ax.text(_x, _y, \"N/A\", ha=\"center\", size='x-small')\n",
    "            else:\n",
    "                value = '{:.0f}'.format(value)\n",
    "                ax.text(_x, _y, value, ha=\"center\")\n",
    "            \n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)\n",
    "\n",
    "cols = {\n",
    "    'instrument_with_rel_test_acc' : \"Instrument\",\n",
    "    'note_with_rel_test_acc': 'Note',\n",
    "    'brightness_with_rel_test_acc': 'Brightness',\n",
    "    'loudness_with_rel_test_acc': 'Loudness',\n",
    "    'exist_with_rel_test_acc': 'Exist',\n",
    "    'position_with_rel_test_acc': 'Absolute Pos',\n",
    "    'position_global_with_rel_test_acc': 'Global Pos',\n",
    "    'position_rel_with_rel_test_acc':'Relative Pos',\n",
    "    'count_with_rel_test_acc':'Count',\n",
    "    'count_compare_with_rel_test_acc':'Count compare',\n",
    "    'count_diff_with_rel_test_acc': 'Count Instrument'\n",
    "}\n",
    "\n",
    "with_relation_df = grouped_df[with_rel_family_test_acc_cols].rename({0:'acc'}).rename(cols,axis=1)\n",
    "#no_relation_df[list(no_relation_df.T.sort_values('acc', ascending=False).index)]\n",
    "\n",
    "#.T.assign(nb_relation=0)\n",
    "\n",
    "\n",
    "#with_relation_df.columns = no_relation_df.columns\n",
    "\n",
    "no_relation_df = grouped_df[no_rel_family_test_acc_cols].rename({0:'acc'})\n",
    "no_relation_df.columns = with_relation_df.columns\n",
    "\n",
    "no_relation_df = no_relation_df.T.assign(nb_relation=0)\n",
    "with_relation_df = with_relation_df.T.assign(nb_relation=1)\n",
    "\n",
    "merged = pd.concat([no_relation_df, with_relation_df]).reset_index().replace(-1,0).rename({'nb_relation':\"Nb Relation\"}, axis=1)\n",
    "merged['acc'] = merged.apply(lambda x: x['acc'] * 100, axis=1)\n",
    "\n",
    "bar_order = list(with_relation_df.sort_values('acc', ascending=False).index)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = sns.barplot(x='index', hue='Nb Relation', y='acc', data=merged, order=bar_order, palette=['dodgerblue','forestgreen'])\n",
    "for item in ax.get_xticklabels():\n",
    "    item.set_rotation(90)\n",
    "    \n",
    "show_values_on_bars(ax)\n",
    "\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_xlabel('Question Type')\n",
    "legend_texts = ax.legend().get_texts()\n",
    "legend_texts[0].set_text('No relation')\n",
    "legend_texts[1].set_text('With relation')\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(f\"stats/q_family_acc_by_relation.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_overall_df.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5 - With 3rd col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best config from resblock reduction\n",
    "filters = get_resblock_reduction_df_mask(experiments, 'Interleaved_Time', nb_gru=512, c=256, h=1024) & (experiments['nb_resblock'] == 4) & (experiments['resblocks_out_chan'] == 64)\n",
    "\n",
    "grouped_df = show_table(df=experiments,\n",
    "           filters=filters,\n",
    "           groupby_columns = ['nb_resblock', 'resblocks_out_chan'],\n",
    "           acc_columns = ['test_acc', *family_test_acc_cols],\n",
    "           attribute_by_color = {c: 'CMRmap' for c in family_test_acc_cols},\n",
    "           #extra_columns = ['nb_trainable_param_million'],\n",
    "           #hardcoded_cols=hardcoded_columns,\n",
    "           display_all=display_all_exp,\n",
    "           show_count_col=show_count_col,\n",
    "           format_dict=latex_format_dict,\n",
    "           inplace_std=False,\n",
    "           remove_outliers=remove_outliers,\n",
    "           nb_to_keep=1,#nb_results_to_keep,\n",
    "           all_seeds=all_random_seeds if show_missing_seeds else None,\n",
    "           print_latex=False\n",
    "          )\n",
    "\n",
    "\n",
    "grouped_df = show_table(df=experiments,\n",
    "           filters=filters,\n",
    "           groupby_columns = ['nb_resblock', 'resblocks_out_chan'],\n",
    "           acc_columns = ['test_acc', *family_test_acc_cols, *no_rel_family_test_acc_cols, *with_rel_family_test_acc_cols],\n",
    "           #extra_columns = ['nb_trainable_param_million'],\n",
    "           #hardcoded_cols=hardcoded_columns,\n",
    "           display_all=display_all_exp,\n",
    "           show_count_col=show_count_col,\n",
    "           format_dict=latex_format_dict,\n",
    "           inplace_std=False,\n",
    "           remove_outliers=remove_outliers,\n",
    "           nb_to_keep=1,#nb_results_to_keep,\n",
    "           all_seeds=all_random_seeds if show_missing_seeds else None,\n",
    "           print_latex=False\n",
    "          )\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "def show_values_on_bars(axs):\n",
    "    def _show_on_single_plot(ax):        \n",
    "        for p in ax.patches:\n",
    "            _x = p.get_x() + p.get_width() / 2\n",
    "            _y = p.get_y() + p.get_height() + 0.5\n",
    "            value = p.get_height()\n",
    "            if value == 0:\n",
    "                ax.text(_x, _y, \"N/A\", ha=\"center\", size='x-small')\n",
    "            else:\n",
    "                value = '{:.0f}'.format(value)\n",
    "                ax.text(_x, _y, value, ha=\"center\", size='small')\n",
    "            \n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)\n",
    "\n",
    "cols = {\n",
    "    'instrument_with_rel_test_acc' : \"Instrument\",\n",
    "    'note_with_rel_test_acc': 'Note',\n",
    "    'brightness_with_rel_test_acc': 'Brightness',\n",
    "    'loudness_with_rel_test_acc': 'Loudness',\n",
    "    'exist_with_rel_test_acc': 'Exist',\n",
    "    'position_with_rel_test_acc': 'Absolute Pos',\n",
    "    'position_global_with_rel_test_acc': 'Global Pos',\n",
    "    'position_rel_with_rel_test_acc':'Relative Pos',\n",
    "    'count_with_rel_test_acc':'Count',\n",
    "    'count_compare_with_rel_test_acc':'Count compare',\n",
    "    'count_diff_with_rel_test_acc': 'Count Instrument'\n",
    "}\n",
    "\n",
    "with_relation_df = grouped_df[with_rel_family_test_acc_cols].rename({0:'acc'}).rename(cols,axis=1)\n",
    "#no_relation_df[list(no_relation_df.T.sort_values('acc', ascending=False).index)]\n",
    "\n",
    "#.T.assign(nb_relation=0)\n",
    "\n",
    "\n",
    "#with_relation_df.columns = no_relation_df.columns\n",
    "\n",
    "overall_df = grouped_df[family_test_acc_cols].rename({0: 'acc'})\n",
    "overall_df.columns = with_relation_df.columns\n",
    "\n",
    "no_relation_df = grouped_df[no_rel_family_test_acc_cols].rename({0:'acc'})\n",
    "no_relation_df.columns = with_relation_df.columns\n",
    "\n",
    "no_relation_df = no_relation_df.T.assign(nb_relation=\"None\")\n",
    "with_relation_df = with_relation_df.T.assign(nb_relation=\"One\")\n",
    "overall_df = overall_df.T.assign(nb_relation='Overall')\n",
    "\n",
    "merged = pd.concat([overall_df, no_relation_df, with_relation_df]).reset_index().replace(-1,0).rename({'nb_relation':\"Nb Relation\"}, axis=1)\n",
    "merged['acc'] = merged.apply(lambda x: x['acc'] * 100, axis=1)\n",
    "\n",
    "bar_order = list(with_relation_df.sort_values('acc', ascending=False).index)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = sns.barplot(x='index', hue='Nb Relation', y='acc', data=merged, order=bar_order, palette=['gold', 'forestgreen', 'dodgerblue'])\n",
    "for item in ax.get_xticklabels():\n",
    "    item.set_rotation(90)\n",
    "    \n",
    "show_values_on_bars(ax)\n",
    "\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_xlabel('Question Type')\n",
    "ax.legend(title=\"Nb relation\", bbox_to_anchor=(1,1), labelspacing=0.3)\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(f\"stats/q_family_acc_by_relation_with_overall.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resized to 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best config with input resized to 224x224\n",
    "def get_best_df_mask(df, m=64, resized=False):\n",
    "    # Static parameters\n",
    "        # Extractor = Interleaved\n",
    "        # N = [8, 16, 32]\n",
    "        # J = 4\n",
    "        # M = 64 OR 128\n",
    "        # G = 512\n",
    "        # ClassifierTopology = FCN\n",
    "        # C = 256\n",
    "        # H = 1024\n",
    "        # K = 3\n",
    "        # P = 32 OR 64\n",
    "\n",
    "    # -- Input parameters\n",
    "    filters = (experiments['input_type'].str.contains('1D'))\n",
    "    filters &= (experiments['n_fft'] == 512)\n",
    "    filters &= (experiments['keep_freq_point'] == 256)\n",
    "    filters &= (experiments['hop_length'] == 2048)\n",
    "    if resized:\n",
    "        filters &= (experiments['resized_width'].notna())\n",
    "    else:\n",
    "        filters &= (experiments['resized_width'].isnull())\n",
    "\n",
    "    # -- Text Processing\n",
    "    filters &= (experiments['rnn_state_size'] == 512)              # G\n",
    "\n",
    "    # -- Coordconv\n",
    "    filters &= (experiments['extractor_spatial_location'] == 'None')\n",
    "    filters &= (experiments['stem_spatial_location'] == 'Both')\n",
    "    filters &= (experiments['resblock_spatial_location'] == 'Both')\n",
    "    filters &= (experiments['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "    # -- Extractor\n",
    "    filters &= experiments['extractor_type'].str.contains('Interleaved_Time')\n",
    "\n",
    "    # Resblocks\n",
    "    filters &= (experiments['nb_resblock'] == 4)        # J\n",
    "    filters &= (experiments['resblocks_out_chan'] == m)           # M\n",
    "        \n",
    "    # -- Classifier\n",
    "    filters &= (experiments['classifier_conv_out'] == 256)          # C      <---- FIXME: Make sure this is the good values\n",
    "    filters &= (experiments['classifier_projection_out'] == 1024)    # H      <---- FIXME: Make sure this is the good values\n",
    "\n",
    "    # Variable Parameters (Extractor)\n",
    "    filters &= (experiments['extractor_nb_block'] == 3)   # K \n",
    "    if m == 64:\n",
    "        p = 32\n",
    "        p = 64\n",
    "    else:\n",
    "        p = 64\n",
    "        \n",
    "    filters &= (experiments['extractor_projection_size'] == p)   # P\n",
    "\n",
    "    # -- Other\n",
    "    #filters &= (~experiments['config'].str.contains('extractor_slim'))\n",
    "    #filters &= (experiments['note'].str.contains('table_5_final|table_4.*1_worker'))    # Table 4 result for comparison\n",
    "    #filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "    #filters &= (experiments['reduce_lr_on_plateau'] == False)\n",
    "\n",
    "    # -- Comparison\n",
    "    #filters |= ( (experiments['nb_resblock'] == 4) & (experiments['resblocks_out_chan'] == 128) & (experiments['note'].str.contains('table_4.*1_worker')) & experiments['extractor_type'].str.contains('Parallel') & (experiments['classifier_conv_out'] == 128) & (experiments['classifier_projection_out'] == 512) )\n",
    "\n",
    "    #filters = get_table_extractor_type_filters(experiments)\n",
    "    \n",
    "    return filters\n",
    "\n",
    "filters = get_best_df_mask(experiments, m=64, resized=False)\n",
    "\n",
    "grouped_df = show_table(df=experiments,\n",
    "           filters=filters,\n",
    "           groupby_columns = ['resblocks_out_chan'],\n",
    "           acc_columns = ['train_acc', 'best_val_acc', 'test_acc'],\n",
    "           extra_columns = ['nb_trainable_param_million'],\n",
    "           display_all=display_all_exp | True,\n",
    "           show_count_col=show_count_col,\n",
    "           format_dict=latex_format_dict,\n",
    "           inplace_std=show_std,\n",
    "           remove_outliers=remove_outliers,\n",
    "           nb_to_keep=nb_results_to_keep,\n",
    "           all_seeds=all_random_seeds if show_missing_seeds else None\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = get_best_df_mask(experiments, m=64, resized=True)\n",
    "\n",
    "grouped_df = show_table(df=experiments,\n",
    "           filters=filters,\n",
    "           groupby_columns = ['resblocks_out_chan'],\n",
    "           acc_columns = ['train_acc', 'best_val_acc', 'test_acc'],\n",
    "           extra_columns = ['resized_width', 'random_seed', 'nb_trainable_param_million'],\n",
    "           display_all=display_all_exp | True,\n",
    "           show_count_col=show_count_col,\n",
    "           format_dict=latex_format_dict,\n",
    "           inplace_std=show_std,\n",
    "           remove_outliers=remove_outliers,\n",
    "           nb_to_keep=nb_results_to_keep,\n",
    "           all_seeds=all_random_seeds if show_missing_seeds else None\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments[(experiments['note'].str.contains('new_resize'))].sort_values(\"date\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_relation_df = grouped_df[with_rel_family_test_acc_cols].rename({0:'acc'}).rename(cols,axis=1)\n",
    "#no_relation_df[list(no_relation_df.T.sort_values('acc', ascending=False).index)]\n",
    "\n",
    "#.T.assign(nb_relation=0)\n",
    "\n",
    "\n",
    "#with_relation_df.columns = no_relation_df.columns\n",
    "\n",
    "no_relation_df = grouped_df[no_rel_family_test_acc_cols].rename({0:'acc'})\n",
    "#no_relation_df.columns = with_relation_df.columns\n",
    "\n",
    "no_relation_df = no_relation_df.T.assign(nb_relation=0)\n",
    "#with_relation_df = with_relation_df.T.assign(nb_relation=1)\n",
    "\n",
    "overall_df = grouped_df[family_test_acc_cols].rename({0: 'acc'})\n",
    "overall_df.columns = with_relation_df.columns\n",
    "#overall_df = overall_df.T.assign(nb_relation='All')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_relation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Table X - Extractor types - Per question type analysis\n",
    "# Static parameters :\n",
    "    # G = 4096\n",
    "    # J = 3\n",
    "    # M = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "    \n",
    "# Variable parameters :\n",
    "    # Extractors Type = {Parallel, Interleaved, Resnet}\n",
    "\n",
    "filters = get_table_extractor_type_filters(experiments)\n",
    "\n",
    "hardcoded_columns = {'extractor': {\n",
    "    'type': 'replace_groupby',\n",
    "    'values': [\n",
    "        'Interleaved Time 1st (Fig \\ref{fig:interlaced_extractor})',\n",
    "        'Parallel (Fig \\ref{fig:parallel_extractor})', \n",
    "        '2D Conv',\n",
    "        'Resnet101 (Baseline)', \n",
    "        'Interleaved Freq 1st (Fig \\ref{fig:interlaced_extractor})'\n",
    "    ]\n",
    "}}\n",
    "\n",
    "grouped_df = show_table(df=experiments,\n",
    "           filters=filters,\n",
    "           groupby_columns = ['extractor_type'],\n",
    "           acc_columns = ['test_acc', *family_test_acc_cols],\n",
    "           extra_columns = ['random_seed', 'note', 'extractor_out_chan', 'extractor_nb_block','config'],\n",
    "           attribute_by_color = {c: 'CMRmap' for c in family_test_acc_cols},\n",
    "           hardcoded_cols= hardcoded_columns,\n",
    "           display_all=True,\n",
    "           show_count_col=False,\n",
    "           format_dict=latex_format_dict,\n",
    "           inplace_std=False,\n",
    "           remove_outliers=False,\n",
    "           nb_to_keep=None\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filters = get_table_extractor_type_filters(experiments) & (experiments['extractor_type'].str.contains('Parallel'))\n",
    "\n",
    "grouped_df = show_table(df=experiments,\n",
    "           filters=filters,\n",
    "           groupby_columns = ['extractor_type'],\n",
    "           acc_columns = ['test_acc', *family_test_acc_cols, *with_rel_family_test_acc_cols],\n",
    "           #extra_columns = ['train_acc', 'best_val_acc','nb_epoch_trained', 'train_time'],\n",
    "           attribute_by_color = {c: 'CMRmap' for c in family_test_acc_cols},\n",
    "           display_all=False,\n",
    "           show_count_col=False,\n",
    "           format_dict=latex_format_dict,\n",
    "           inplace_std=False,\n",
    "           remove_outliers=True,\n",
    "           print_latex=False\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {'instrument_test_acc' : \"Instrument\",\n",
    " 'note_test_acc': 'Note',\n",
    " 'brightness_test_acc': 'Brightness',\n",
    " 'loudness_test_acc': 'Loudness',\n",
    " 'exist_test_acc': 'Exist',\n",
    " 'position_test_acc': 'Abs Pos',\n",
    " 'position_global_test_acc': 'Global Pos',\n",
    " 'position_rel_test_acc':'Rel Pos',\n",
    " 'count_test_acc':'Count',\n",
    " 'count_compare_test_acc':'Count compare',\n",
    " 'count_diff_test_acc': 'Count Instr'}\n",
    "\n",
    "plt.figure()\n",
    "grouped_df.loc[0][list(cols.keys())].rename(cols).plot.bar(rot=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(experiments.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed = grouped_df.loc[0,list(cols.keys())].rename(cols)\n",
    "\n",
    "renamed = grouped_df.loc[0, list(cols.keys())].rename(cols).T.reset_index().rename({0:'acc'}, axis=1)\n",
    "\n",
    "#grouped_df.T\n",
    "\n",
    "#idx = pd.MultiIndex.from_tuples([('instrument_test_acc', 'instrument_with_rel_test_acc'), ('brightness_test_acc', 'brightness_with_rel_test_acc')])\n",
    "\n",
    "#grouped_df[['instrument_test_acc', 'instrument_with_rel_test_acc']].reindex(idx)\n",
    "\n",
    "df1 = grouped_df[['instrument_test_acc', 'brightness_test_acc']].assign(nb_relation=0)\n",
    "df2 = grouped_df[['instrument_with_rel_test_acc', 'brightness_with_rel_test_acc']].assign(nb_relation=1)\n",
    "df2.columns = df1.columns\n",
    "\n",
    "#plt.figure()\n",
    "#ax = sns.barplot(x='index', y='acc',data=renamed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_values_on_bars(axs):\n",
    "    def _show_on_single_plot(ax):        \n",
    "        for p in ax.patches:\n",
    "            _x = p.get_x() + p.get_width() / 2\n",
    "            _y = p.get_y() + p.get_height() + 0.5\n",
    "            value = p.get_height()\n",
    "            if value == 0:\n",
    "                ax.text(_x, _y, \"N/A\", ha=\"center\", size='x-small')\n",
    "            else:\n",
    "                value = '{:.0f}'.format(value)\n",
    "                ax.text(_x, _y, value, ha=\"center\")\n",
    "            \n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def show_values_on_bars(axs):\n",
    "    def _show_on_single_plot(ax):        \n",
    "        for p in ax.patches:\n",
    "            _x = p.get_x() + p.get_width() / 2\n",
    "            _y = p.get_y() + p.get_height() + 0.5\n",
    "            value = p.get_height()\n",
    "            if value == 0:\n",
    "                ax.text(_x, _y, \"N/A\", ha=\"center\", size='x-small')\n",
    "            else:\n",
    "                value = '{:.0f}'.format(value)\n",
    "                ax.text(_x, _y, value, ha=\"center\")\n",
    "            \n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)\n",
    "\n",
    "cols = {'instrument_test_acc' : \"Instrument\",\n",
    " 'note_test_acc': 'Note',\n",
    " 'brightness_test_acc': 'Brightness',\n",
    " 'loudness_test_acc': 'Loudness',\n",
    " 'exist_test_acc': 'Exist',\n",
    " 'position_test_acc': 'Abs Pos',\n",
    " 'position_global_test_acc': 'Global Pos',\n",
    " 'position_rel_test_acc':'Rel Pos',\n",
    " 'count_test_acc':'Count',\n",
    " 'count_compare_test_acc':'Count compare',\n",
    " 'count_diff_test_acc': 'Count Instr'}\n",
    "\n",
    "\n",
    "no_relation_df = grouped_df[family_test_acc_cols].rename({0:'acc'}).rename(cols,axis=1)\n",
    "#no_relation_df[list(no_relation_df.T.sort_values('acc', ascending=False).index)]\n",
    "\n",
    "#.T.assign(nb_relation=0)\n",
    "\n",
    "with_relation_df = grouped_df[with_rel_family_test_acc_cols].rename({0:'acc'})\n",
    "with_relation_df.columns = no_relation_df.columns\n",
    "\n",
    "no_relation_df = no_relation_df.T.assign(nb_relation=0)\n",
    "with_relation_df = with_relation_df.T.assign(nb_relation=1)\n",
    "\n",
    "merged = pd.concat([no_relation_df, with_relation_df]).reset_index().replace(-1,0).rename({'nb_relation':\"Nb Relation\"}, axis=1)\n",
    "merged['acc'] = merged.apply(lambda x: x['acc'] * 100, axis=1)\n",
    "\n",
    "bar_order = list(no_relation_df.sort_values('acc', ascending=False).index)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = sns.barplot(x='index', hue='Nb Relation', y='acc', data=merged, order=bar_order, palette=['dodgerblue','mediumseagreen'])\n",
    "for item in ax.get_xticklabels():\n",
    "    item.set_rotation(90)\n",
    "    \n",
    "show_values_on_bars(ax)\n",
    "\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_xlabel('Question Type')\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(f\"stats/q_family_acc_by_relation.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.barplot(x='nb_relation', hue='index', y='acc', data=merged, hue_order=list(no_relation_df.sort_values('acc', ascending=False).index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(no_relation_df.sort_values('acc', ascending=False).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = grouped_df[['instrument_test_acc', 'brightness_test_acc']]\n",
    "df3_r = df3.rename({0:'acc'}).T.assign(nb_relation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = grouped_df[['instrument_with_rel_test_acc', 'brightness_with_rel_test_acc']]\n",
    "df4.columns = df3.columns\n",
    "df4_r = df4.rename({0:'acc'}).T.assign(nb_relation=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([df3_r, df4_r]).reset_index()\n",
    "\n",
    "plt.figure()\n",
    "sns.barplot(x='index', hue='nb_relation', y='acc', data=merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df1.rename({0:\"no_relate\"})\n",
    "#df1.assign(nb_relation=0)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2['nb_relation'] = 1\n",
    "#df2.columns = df1.columns\n",
    "df2\n",
    "#df2 = df2.rename({0:\"with_relate\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([df1,df2])\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.barplot(hue='nb_relation', x='index', data=merged.T.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure()\n",
    "ax = sns.barplot(data=grouped_df.loc[0][list(cols.keys())].rename(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table X - Per question analysis - COORDCONV\n",
    "    # K = 3\n",
    "    # N_0 = 8\n",
    "    # P = 64\n",
    "    # G = 1024\n",
    "    # J = 3\n",
    "    # M = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "\n",
    "filters = get_table_coordconv_per_q_type_filters(experiments)\n",
    "\n",
    "grouped_df = show_table(df=experiments,\n",
    "                       filters=filters,\n",
    "                       groupby_columns = ['extractor_spatial_location', 'stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location'],\n",
    "                       acc_columns = ['test_acc', *family_test_acc_cols],\n",
    "                       extra_columns = [],\n",
    "                       attribute_by_color = {c: 'CMRmap' for c in family_test_acc_cols},\n",
    "                       display_all=True,\n",
    "                       format_dict=latex_format_dict,\n",
    "                       hardcoded_cols={\n",
    "                           'configuration':{\n",
    "                               'type': 'replace_groupby',\n",
    "                               'values': [\"NAAQA\", \"Time only\", \"Freq only\", \"None\"]\n",
    "                           }\n",
    "                       }\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Table 7 - CoordConv placement\n",
    "    # K = 3\n",
    "    # N_0 = 8\n",
    "    # P = 64\n",
    "    # G = 1024\n",
    "    # J = 3\n",
    "    # M = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "    \n",
    "filters = get_table_coordconv_placement_filters(experiments)\n",
    "\n",
    "show_table(df=experiments,\n",
    "           filters=filters,\n",
    "           groupby_columns = ['extractor_spatial_location', 'stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location'],\n",
    "           acc_columns = ['train_acc', 'best_val_acc', 'test_acc'],\n",
    "           extra_columns = ['note'],\n",
    "           attribute_by_color = None,\n",
    "           display_all=True,\n",
    "           format_dict=latex_format_dict,\n",
    "           all_seeds=all_random_seeds\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Table 7 - CoordConv placement - BIGGER\n",
    "    # K = 3\n",
    "    # N_0 = 8\n",
    "    # P = 64\n",
    "    # G = 1024\n",
    "    # J = 3\n",
    "    # M = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "    \n",
    "# TODO : Update\n",
    "filters = get_table_coordconv_bigger_placement_filters(experiments)\n",
    "\n",
    "filters = (experiments['note'].str.contains('table_7_bigger'))\n",
    "\n",
    "show_table(df=experiments,\n",
    "           filters=filters,\n",
    "           groupby_columns = ['extractor_spatial_location', 'stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location', 'extractor_type'],\n",
    "           acc_columns = ['train_acc', 'best_val_acc', 'test_acc'],\n",
    "           extra_columns = ['random_seed', 'train_time'],\n",
    "           attribute_by_color = None,\n",
    "           display_all=True,\n",
    "           format_dict=latex_format_dict,\n",
    "           show_count_col=True,\n",
    "           all_seeds=all_random_seeds\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 4 - Resblocks\n",
    "# Static parameters\n",
    "    # Extractor = Parallel\n",
    "    # K = 3\n",
    "    # N = [8, 16, 32]\n",
    "    # P = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "# Variable Parameters\n",
    "    # J = {4, 3, 2, 1}\n",
    "    # M = {128, 64, 32}\n",
    "\n",
    "filters = (experiments['date'] >= '2020-11-20')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['input_type'].str.contains('1D'))\n",
    "filters &= (experiments['n_fft'] == 512)\n",
    "filters &= (experiments['keep_freq_point'] == 256)\n",
    "filters &= (experiments['hop_length'] == 2048)\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "\n",
    "# -- Text Processing\n",
    "filters &= (experiments['rnn_state_size'] == 1024)              # G\n",
    "\n",
    "# -- Coordconv\n",
    "filters &= (experiments['extractor_spatial_location'] == 'None')\n",
    "filters &= (experiments['stem_spatial_location'] == 'Both')\n",
    "filters &= (experiments['resblock_spatial_location'] == 'Both')\n",
    "filters &= (experiments['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "# -- Extractor\n",
    "filters &= experiments['extractor_type'].str.contains('Parallel')\n",
    "filters &= (experiments['extractor_nb_block'] == 3)             # K\n",
    "#filters &= (experiments['extractor_filters'] == [8, 16, 32])   # N\n",
    "filters &= (experiments['extractor_projection_size'] == 64)     # P      <---- FIXME : Might want to try with 32\n",
    "\n",
    "# -- Classifier\n",
    "filters &= (experiments['classifier_conv_out'] == 128)          # C      <---- FIXME: Make sure this is the good values\n",
    "filters &= (experiments['classifier_projection_out'] == 512)    # H      <---- FIXME: Make sure this is the good values\n",
    "\n",
    "# Variable Parameters (Resblocks)\n",
    "filters &= (experiments['nb_resblock'] <= 4)                    # J\n",
    "filters &= (experiments['resblocks_out_chan'].isin([128, 64, 32]))           # M\n",
    "\n",
    "# -- Other\n",
    "#filters &= (experiments['note'].str.contains('table_5_final|table_4.*1_worker'))    # Table 4 result for comparison\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -- Comparison\n",
    "#filters |= ( (experiments['nb_resblock'] == 4) & (experiments['resblocks_out_chan'] == 128) & (experiments['note'].str.contains('table_4.*1_worker')) & experiments['extractor_type'].str.contains('Parallel') & (experiments['classifier_conv_out'] == 128) & (experiments['classifier_projection_out'] == 512) )\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "# Display\n",
    "groupby_columns = ['nb_resblock', 'resblocks_out_chan']\n",
    "acc_columns = ['train_acc', 'best_val_acc', 'test_acc']\n",
    "extra_columns = ['nb_trainable_param_million']\n",
    "\n",
    "exp[['train_time']].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 7 - CoordConv placement\n",
    "    # K = 3\n",
    "    # N_0 = 8\n",
    "    # P = 64\n",
    "    # G = 1024\n",
    "    # J = 3\n",
    "    # M = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "columns = ['extractor_spatial_location', 'stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location' , 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained']\n",
    "#columns = ['extractor_filters', 'classifier_conv_out', 'classifier_projection_out',  'keep_freq_point', 'hop_length', 'extractor_type', 'nb_resblock', 'resblocks_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained', 'folder_dated']\n",
    "\n",
    "\n",
    "filters = (experiments['date'] >= '2020-11-20')\n",
    "#filters = (experiments['date'] >= '2020-09-20')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['input_type'].str.contains('1D'))\n",
    "filters &= (experiments['n_fft'] == 512)\n",
    "filters &= (experiments['keep_freq_point'] == 256)\n",
    "filters &= (experiments['hop_length'] == 2048)\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "\n",
    "# -- Text Processing\n",
    "filters &= (experiments['rnn_state_size'] == 1024)              # G\n",
    "\n",
    "# -- Extractor\n",
    "filters &= (experiments['extractor_nb_block'] == 3)             # K\n",
    "#filters &= (experiments['extractor_filters'] == [8, 16, 32])   # N\n",
    "filters &= (experiments['extractor_projection_size'] == 64)     # P\n",
    "\n",
    "# -- Resblocks\n",
    "filters &= (experiments['nb_resblock'] == 3)                   # J       <---- FIXME: Make sure this is the good values\n",
    "filters &= (experiments['resblocks_out_chan'] == 64)           # M       <---- FIXME: Make sure this is the good values\n",
    "\n",
    "# -- Classifier\n",
    "filters &= (experiments['classifier_conv_out'] == 128)          # C      <---- FIXME: Make sure this is the good values\n",
    "filters &= (experiments['classifier_projection_out'] == 512)    # H      <---- FIXME: Make sure this is the good values\n",
    "\n",
    "# Variable Parameters (CoordConv)\n",
    "filters &= (experiments['extractor_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "filters &= (experiments['stem_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "filters &= (experiments['resblock_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "filters &= (experiments['classifier_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "\n",
    "# -- Other\n",
    "filters &= (experiments['note'].str.contains('table_7|table_5_final'))\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "# Display\n",
    "groupby_columns = ['extractor_spatial_location', 'stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location']\n",
    "acc_columns = ['train_acc', 'best_val_acc', 'test_acc']\n",
    "extra_columns = ['nb_trainable_param_million']#, 'folder_dated']\n",
    "\n",
    "# Drop duplicates (Same experiment ran multiple time)\n",
    "exp = exp.drop_duplicates(groupby_columns + ['random_seed'],keep='first')\n",
    "\n",
    "# Grouping - Mean & Std calc\n",
    "acc_std_columns = [f\"{c}_std\" for c in acc_columns]\n",
    "columns = groupby_columns + acc_columns + extra_columns\n",
    "\n",
    "exp_grouped = groupby_mean(exp, groupby_columns, acc_columns, columns, add_count_col=True, add_std_str=True)\n",
    "train_std_mean, val_std_mean, test_std_mean = exp_grouped['train_acc_std'].mean() * 100, exp_grouped['best_val_acc_std'].mean() * 100, exp_grouped['test_acc_std'].mean() * 100\n",
    "accuracy_std_mean = np.mean([train_std_mean, val_std_mean, test_std_mean])\n",
    "\n",
    "exp_grouped = exp_grouped.sort_values('test_acc', ascending=False)[columns]\n",
    "\n",
    "#display(color_by_multi_attribute(exp[columns + ['random_seed', 'note']].sort_values(groupby_columns + ['random_seed'], ascending=False), main_attribute='test_acc', attributes=groupby_columns))\n",
    "\n",
    "# Color display\n",
    "display(color_by_multi_attribute(exp_grouped, main_attribute='test_acc', \n",
    "                                 attributes=['extractor_spatial_location', 'stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location', 'test_acc', 'test_acc_std'],\n",
    "                                 cmaps=['Blues', 'YlOrRd', 'YlOrRd', 'YlOrRd', 'YlOrRd'], \n",
    "                                 format_dict=latex_format_dict))\n",
    "\n",
    "# Latex code\n",
    "latex = exp_grouped.to_latex(index=False, formatters=latex_format_dict).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "\n",
    "print(\"\\n\",latex)\n",
    "print(f\"STD Means -- Global means : ± {accuracy_std_mean} Train : ± {train_std_mean} Val : ± {val_std_mean} - Test : ± {test_std_mean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_table(df=experiments,\n",
    "           filters=get_table1_filters(experiments),\n",
    "           groupby_columns = ['extractor_type'],\n",
    "           acc_columns = ['train_acc', 'best_val_acc', 'test_acc'],\n",
    "           extra_columns = ['train_time', 'random_seed'],#, 'folder_dated'],\n",
    "           attribute_by_color = {'best_val_acc':None},\n",
    "           display_all=True\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table X - Per question type analysis\n",
    "# Static parameters :\n",
    "    # G = 4096\n",
    "    # J = 3\n",
    "    # M = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "    \n",
    "# Variable parameters :\n",
    "    # Extractors Type = {Parallel, Interleaved, Resnet}\n",
    "\n",
    "filters = get_table1_filters(experiments)\n",
    "\n",
    "show_table(df=experiments,\n",
    "           filters=filters,\n",
    "           groupby_columns = ['extractor_type'],\n",
    "           acc_columns = ['test_acc', *family_test_acc_cols],\n",
    "           extra_columns = ['nb_trainable'],#, 'folder_dated'],\n",
    "           attribute_by_color = {c: 'CMRmap' for c in family_test_acc_cols},\n",
    "           display_all=False,\n",
    "           format_dict=latex_format_dict\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table X - Per question type analysis\n",
    "# Static parameters :\n",
    "    # G = 4096\n",
    "    # J = 3\n",
    "    # M = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "    \n",
    "# Variable parameters :\n",
    "    # Extractors Type = {Parallel, Interleaved, Resnet}\n",
    "\n",
    "filters = (experiments['date'] >= '2020-09-15')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "filters &= (~experiments['normalisation'].str.contains(\"imagenet_stats\", na=False))\n",
    "\n",
    "# -- Text Processing\n",
    "filters &= (experiments['rnn_state_size'] == 4096)              # G\n",
    "\n",
    "# -- Coordconv\n",
    "filters &= (experiments['extractor_spatial_location'] == 'None')\n",
    "filters &= (experiments['stem_spatial_location'] == 'Both')\n",
    "filters &= (experiments['resblock_spatial_location'] == 'Both')\n",
    "filters &= (experiments['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "# -- Resblocks\n",
    "filters &= (experiments['nb_resblock'] == 4)                    # J\n",
    "filters &= (experiments['resblocks_out_chan'] == 128)           # M\n",
    "\n",
    "# -- Classifier\n",
    "filters &= (experiments['classifier_conv_out'] == 512)          # C\n",
    "filters &= (experiments['classifier_projection_out'] == 1024)    # H\n",
    "\n",
    "# Variable Parameters (Input_type & Extractor)\n",
    "filters &= (~experiments['RGB_colormap'].str.contains('Blues', na=False))\n",
    "\n",
    "input_1d_filter = (experiments['input_type'].str.contains('1D'))\n",
    "input_1d_filter &= (experiments['n_fft'] == 512)\n",
    "input_1d_filter &= (experiments['keep_freq_point'] == 256) \n",
    "input_1d_filter &= (experiments['hop_length'] == 2048)\n",
    "\n",
    "filters &= ((experiments['input_type'].str.contains('RGB') & (experiments['extractor_type'].str.contains('Resnet'))) | input_1d_filter )\n",
    "\n",
    "#filters &= (experiments['extractor_type'].str.contains('Resnet|Parallel'))# | (experiments['extractor_type'].str.startswith('Interleaved')))\n",
    "#filters &= (experiments['extractor_type'].str.contains('Baseline') | (experiments['extractor_type'].str.contains('Resnet')))\n",
    "\n",
    "filters &= (experiments['extractor_type'].str.contains('Parallel|Interleaved|Resnet'))\n",
    "\n",
    "# -- Other\n",
    "filters &= (experiments['note'].str.contains('table_1_final_final|table_2_final_final'))\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "# Display\n",
    "groupby_columns = ['extractor_type']\n",
    "#acc_columns = ['train_acc', 'best_val_acc', 'test_acc']\n",
    "acc_columns = ['test_acc', *family_test_acc_cols]\n",
    "extra_columns = []#'nb_trainable_param_million']#, 'folder_dated']\n",
    "\n",
    "# Drop duplicates (Same experiment ran multiple time)\n",
    "exp = exp.sort_values('date', ascending=False).drop_duplicates([*groupby_columns, 'random_seed'],keep='first')\n",
    "\n",
    "# Grouping - Mean & Std calc\n",
    "acc_std_columns = [f\"{c}_std\" for c in acc_columns]\n",
    "columns = groupby_columns + acc_columns + extra_columns\n",
    "columns_to_show = [*groupby_columns, *acc_columns, 'mean_std', *extra_columns]\n",
    "\n",
    "exp_grouped = groupby_mean(exp, groupby_columns, acc_columns, columns, add_count_col=True, add_std_str=True, inplace_std_str=False)\n",
    "exp_grouped['mean_std'] = exp_grouped[acc_std_cols].mean(axis=1)\n",
    "exp_grouped['mean_acc'] = exp_grouped[acc_columns].mean(axis=1)\n",
    "#train_std_mean, val_std_mean, test_std_mean = exp_grouped['train_acc_std'].mean() * 100, exp_grouped['best_val_acc_std'].mean() * 100, exp_grouped['test_acc_std'].mean() * 100\n",
    "#accuracy_std_mean = np.mean([train_std_mean, val_std_mean, test_std_mean])\n",
    "\n",
    "exp_grouped = exp_grouped.sort_values('test_acc', ascending=False)[columns_to_show]\n",
    "\n",
    "# All experiments\n",
    "#display(color_by_multi_attribute(exp[columns + ['random_seed', 'note']].sort_values(groupby_columns + ['random_seed'], ascending=False), main_attribute='extractor_type', attributes=groupby_columns))\n",
    "\n",
    "# Color display      \n",
    "display(color_by_multi_attribute(exp_grouped, main_attribute=\"extractor_type\", \n",
    "                                 attributes=acc_columns, \n",
    "                                 cmaps=['Blues'] + ['CMRmap'] * len(acc_columns),\n",
    "                                 format_dict=latex_format_dict))\n",
    "\n",
    "# Latex code\n",
    "latex = exp_grouped[columns_to_show].to_latex(index=False, formatters=latex_format_dict).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "latex = re.sub(r'&\\s*', '& ', latex)\n",
    "\n",
    "print(\"\\n\",latex)\n",
    "#print(f\"STD Means -- Global means : ± {accuracy_std_mean} Train : ± {train_std_mean} Val : ± {val_std_mean} - Test : ± {test_std_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_std_columns == std_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1 - Extractor Types\n",
    "# Static parameters :\n",
    "    # G = 4096\n",
    "    # J = 3\n",
    "    # M = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "    \n",
    "# Variable parameters :\n",
    "    # Extractors Type = {Parallel, Interleaved, Resnet}\n",
    "\n",
    "filters = get_table1_filters(experiments)\n",
    "exp = experiments[filters]\n",
    "\n",
    "# Display\n",
    "groupby_columns = ['extractor_type']\n",
    "acc_columns = ['train_acc', 'best_val_acc', 'test_acc']\n",
    "extra_columns = ['nb_trainable_param_million']#, 'folder_dated']\n",
    "\n",
    "# Drop duplicates (Same experiment ran multiple time)\n",
    "#exp = exp.sort_values('date', ascending=False).drop_duplicates(groupby_columns + ['random_seed', 'input_type'],keep='first')\n",
    "\n",
    "# Grouping - Mean & Std calc\n",
    "acc_std_columns = [f\"{c}_std\" for c in acc_columns]\n",
    "columns = groupby_columns + acc_columns + extra_columns\n",
    "#columns_to_show = groupby_columns + acc_std_columns + extra_columns\n",
    "columns_to_show = [*groupby_columns, 'train_acc', 'best_val_acc', 'test_acc_std', *extra_columns]\n",
    "\n",
    "exp_grouped = groupby_mean(exp, groupby_columns, acc_columns, columns, add_count_col=True, add_std_str=True, inplace_std_str=True)\n",
    "#train_std_mean, val_std_mean, test_std_mean = exp_grouped['train_acc_std'].mean() * 100, exp_grouped['best_val_acc_std'].mean() * 100, exp_grouped['test_acc_std'].mean() * 100\n",
    "#accuracy_std_mean = np.mean([train_std_mean, val_std_mean, test_std_mean])\n",
    "\n",
    "exp_grouped = exp_grouped.sort_values('test_acc', ascending=False)[columns_to_show]\n",
    "\n",
    "# All experiments\n",
    "#display(color_by_multi_attribute(exp[columns + ['random_seed', 'input_type', 'train_time', 'nb_epoch_trained', 'nb_epoch_runned', 'date']].sort_values(groupby_columns + ['random_seed'], ascending=False), main_attribute='test_acc', attributes=groupby_columns))\n",
    "\n",
    "# Color display      \n",
    "display(color_by_multi_attribute(exp_grouped, main_attribute=\"extractor_type\", \n",
    "                                 attributes=[], \n",
    "                                 cmaps=['Blues'],\n",
    "                                 format_dict=latex_format_dict))\n",
    "\n",
    "# Latex code\n",
    "latex = exp_grouped[columns_to_show].to_latex(index=False, formatters=latex_format_dict).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "latex = re.sub(r'&\\s*', '& ', latex)\n",
    "\n",
    "print(\"\\n\",latex)\n",
    "#print(f\"STD Means -- Global means : ± {accuracy_std_mean} Train : ± {train_std_mean} Val : ± {val_std_mean} - Test : ± {test_std_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1 - Extractor Types\n",
    "# Static parameters :\n",
    "    # G = 4096\n",
    "    # J = 3\n",
    "    # M = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "    \n",
    "# Variable parameters :\n",
    "    # Extractors Type = {Parallel, Interleaved, Resnet}\n",
    "\n",
    "filters = (experiments['date'] >= '2020-09-15')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "filters &= (~experiments['normalisation'].str.contains(\"imagenet_stats\", na=False))\n",
    "\n",
    "# -- Text Processing\n",
    "filters &= (experiments['rnn_state_size'] == 4096)              # G\n",
    "\n",
    "# -- Coordconv\n",
    "filters &= (experiments['extractor_spatial_location'] == 'None')\n",
    "filters &= (experiments['stem_spatial_location'] == 'Both')\n",
    "filters &= (experiments['resblock_spatial_location'] == 'Both')\n",
    "filters &= (experiments['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "# -- Resblocks\n",
    "filters &= (experiments['nb_resblock'] == 4)                    # J\n",
    "filters &= (experiments['resblocks_out_chan'] == 128)           # M\n",
    "\n",
    "# -- Classifier\n",
    "filters &= (experiments['classifier_conv_out'] == 512)          # C\n",
    "filters &= (experiments['classifier_projection_out'] == 1024)    # H\n",
    "\n",
    "# Variable Parameters (Input_type & Extractor)\n",
    "filters &= (~experiments['RGB_colormap'].str.contains('Blues', na=False))\n",
    "\n",
    "input_1d_filter = (experiments['input_type'].str.contains('1D'))\n",
    "input_1d_filter &= (experiments['n_fft'] == 512)\n",
    "input_1d_filter &= (experiments['keep_freq_point'] == 256) \n",
    "input_1d_filter &= (experiments['hop_length'] == 2048)\n",
    "\n",
    "filters &= ((experiments['input_type'].str.contains('RGB') & (experiments['extractor_type'].str.contains('Resnet'))) | input_1d_filter )\n",
    "\n",
    "#filters &= (experiments['extractor_type'].str.contains('Resnet|Parallel') | (experiments['extractor_type'].str.startswith('Interleaved')))\n",
    "#filters &= (experiments['extractor_type'].str.contains('Baseline') | (experiments['extractor_type'].str.contains('Resnet')))\n",
    "\n",
    "# -- Other\n",
    "filters &= (experiments['note'].str.contains('table_1_final_final|table_2_final_final'))\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "# Display\n",
    "groupby_columns = ['extractor_type']\n",
    "acc_columns = ['train_acc', 'best_val_acc', 'test_acc']\n",
    "extra_columns = ['nb_trainable_param_million']#, 'folder_dated']\n",
    "\n",
    "# Drop duplicates (Same experiment ran multiple time)\n",
    "exp = exp.sort_values('date', ascending=False).drop_duplicates(groupby_columns + ['random_seed', 'input_type'],keep='first')\n",
    "\n",
    "# Grouping - Mean & Std calc\n",
    "acc_std_columns = [f\"{c}_std\" for c in acc_columns]\n",
    "columns = groupby_columns + acc_columns + extra_columns\n",
    "#columns_to_show = groupby_columns + acc_std_columns + extra_columns\n",
    "columns_to_show = [*groupby_columns, 'train_acc', 'best_val_acc', 'test_acc_std', *extra_columns]\n",
    "\n",
    "exp_grouped = groupby_mean(exp, groupby_columns, acc_columns, columns, add_count_col=True, add_std_str=True, inplace_std_str=True)\n",
    "#train_std_mean, val_std_mean, test_std_mean = exp_grouped['train_acc_std'].mean() * 100, exp_grouped['best_val_acc_std'].mean() * 100, exp_grouped['test_acc_std'].mean() * 100\n",
    "#accuracy_std_mean = np.mean([train_std_mean, val_std_mean, test_std_mean])\n",
    "\n",
    "exp_grouped = exp_grouped.sort_values('test_acc', ascending=False)[columns_to_show]\n",
    "\n",
    "# All experiments\n",
    "#display(color_by_multi_attribute(exp[columns + ['random_seed', 'input_type', 'train_time', 'nb_epoch_trained', 'nb_epoch_runned', 'date']].sort_values(groupby_columns + ['random_seed'], ascending=False), main_attribute='test_acc', attributes=groupby_columns))\n",
    "\n",
    "# Color display      \n",
    "display(color_by_multi_attribute(exp_grouped, main_attribute=\"extractor_type\", \n",
    "                                 attributes=[], \n",
    "                                 cmaps=['Blues'],\n",
    "                                 format_dict=latex_format_dict))\n",
    "\n",
    "# Latex code\n",
    "latex = exp_grouped[columns_to_show].to_latex(index=False, formatters=latex_format_dict).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "latex = re.sub(r'&\\s*', '& ', latex)\n",
    "\n",
    "print(\"\\n\",latex)\n",
    "#print(f\"STD Means -- Global means : ± {accuracy_std_mean} Train : ± {train_std_mean} Val : ± {val_std_mean} - Test : ± {test_std_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table X - Per question type analysis\n",
    "# Static parameters :\n",
    "    # G = 4096\n",
    "    # J = 3\n",
    "    # M = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "    \n",
    "# Variable parameters :\n",
    "    # Extractors Type = {Parallel, Interleaved, Resnet}\n",
    "\n",
    "filters = (experiments['date'] >= '2020-09-15')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "filters &= (~experiments['normalisation'].str.contains(\"imagenet_stats\", na=False))\n",
    "\n",
    "# -- Text Processing\n",
    "filters &= (experiments['rnn_state_size'] == 4096)              # G\n",
    "\n",
    "# -- Coordconv\n",
    "filters &= (experiments['extractor_spatial_location'] == 'None')\n",
    "filters &= (experiments['stem_spatial_location'] == 'Both')\n",
    "filters &= (experiments['resblock_spatial_location'] == 'Both')\n",
    "filters &= (experiments['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "# -- Resblocks\n",
    "filters &= (experiments['nb_resblock'] == 4)                    # J\n",
    "filters &= (experiments['resblocks_out_chan'] == 128)           # M\n",
    "\n",
    "# -- Classifier\n",
    "filters &= (experiments['classifier_conv_out'] == 512)          # C\n",
    "filters &= (experiments['classifier_projection_out'] == 1024)    # H\n",
    "\n",
    "# Variable Parameters (Input_type & Extractor)\n",
    "filters &= (~experiments['RGB_colormap'].str.contains('Blues', na=False))\n",
    "\n",
    "input_1d_filter = (experiments['input_type'].str.contains('1D'))\n",
    "input_1d_filter &= (experiments['n_fft'] == 512)\n",
    "input_1d_filter &= (experiments['keep_freq_point'] == 256) \n",
    "input_1d_filter &= (experiments['hop_length'] == 2048)\n",
    "\n",
    "filters &= ((experiments['input_type'].str.contains('RGB') & (experiments['extractor_type'].str.contains('Resnet'))) | input_1d_filter )\n",
    "\n",
    "#filters &= (experiments['extractor_type'].str.contains('Resnet|Parallel'))# | (experiments['extractor_type'].str.startswith('Interleaved')))\n",
    "#filters &= (experiments['extractor_type'].str.contains('Baseline') | (experiments['extractor_type'].str.contains('Resnet')))\n",
    "\n",
    "filters &= (experiments['extractor_type'].str.contains('Parallel|Interleaved|Resnet'))\n",
    "\n",
    "# -- Other\n",
    "filters &= (experiments['note'].str.contains('table_1_final_final|table_2_final_final'))\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "# Display\n",
    "groupby_columns = ['extractor_type']\n",
    "#acc_columns = ['train_acc', 'best_val_acc', 'test_acc']\n",
    "acc_columns = ['test_acc', *family_test_acc_cols]\n",
    "extra_columns = []#'nb_trainable_param_million']#, 'folder_dated']\n",
    "\n",
    "# Drop duplicates (Same experiment ran multiple time)\n",
    "exp = exp.sort_values('date', ascending=False).drop_duplicates([*groupby_columns, 'random_seed'],keep='first')\n",
    "\n",
    "# Grouping - Mean & Std calc\n",
    "acc_std_columns = [f\"{c}_std\" for c in acc_columns]\n",
    "columns = groupby_columns + acc_columns + extra_columns\n",
    "#columns_to_show = groupby_columns + acc_std_columns + extra_columns\n",
    "columns_to_show = [*groupby_columns, *acc_columns, 'mean_std', *extra_columns]\n",
    "\n",
    "exp_grouped = groupby_mean(exp, groupby_columns, acc_columns, columns, add_count_col=True, add_std_str=True, inplace_std_str=False)\n",
    "std_cols = [c for c in exp_grouped.columns if 'std' in c]\n",
    "exp_grouped['mean_std'] = exp_grouped[std_cols].mean(axis=1)\n",
    "exp_grouped['mean_acc'] = exp_grouped[acc_columns].mean(axis=1)\n",
    "#train_std_mean, val_std_mean, test_std_mean = exp_grouped['train_acc_std'].mean() * 100, exp_grouped['best_val_acc_std'].mean() * 100, exp_grouped['test_acc_std'].mean() * 100\n",
    "#accuracy_std_mean = np.mean([train_std_mean, val_std_mean, test_std_mean])\n",
    "\n",
    "exp_grouped = exp_grouped.sort_values('test_acc', ascending=False)[columns_to_show]\n",
    "\n",
    "# All experiments\n",
    "display(color_by_multi_attribute(exp[columns + ['random_seed', 'note']].sort_values(groupby_columns + ['random_seed'], ascending=False), main_attribute='extractor_type', attributes=groupby_columns))\n",
    "\n",
    "# Color display      \n",
    "display(color_by_multi_attribute(exp_grouped, main_attribute=\"extractor_type\", \n",
    "                                 attributes=acc_columns, \n",
    "                                 cmaps=['Blues'] + ['CMRmap'] * len(acc_columns),\n",
    "                                 format_dict=latex_format_dict))\n",
    "\n",
    "# Latex code\n",
    "latex = exp_grouped[columns_to_show].to_latex(index=False, formatters=latex_format_dict).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "latex = re.sub(r'&\\s*', '& ', latex)\n",
    "\n",
    "print(\"\\n\",latex)\n",
    "#print(f\"STD Means -- Global means : ± {accuracy_std_mean} Train : ± {train_std_mean} Val : ± {val_std_mean} - Test : ± {test_std_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table X - Per question analysis - COORDCONV\n",
    "    # K = 3\n",
    "    # N_0 = 8\n",
    "    # P = 64\n",
    "    # G = 1024\n",
    "    # J = 3\n",
    "    # M = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "\n",
    "filters = get_table_coordconv_per_q_type_filters(experiments)\n",
    "\n",
    "grouped_df = show_table(df=experiments,\n",
    "                       filters=filters,\n",
    "                       groupby_columns = ['extractor_spatial_location', 'stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location'],\n",
    "                       acc_columns = ['test_acc', *family_test_acc_cols],\n",
    "                       extra_columns = [],\n",
    "                       attribute_by_color = {c: 'CMRmap' for c in family_test_acc_cols},\n",
    "                       display_all=False,\n",
    "                       format_dict=latex_format_dict,\n",
    "                       hardcoded_cols={\n",
    "                           'configuration':{\n",
    "                               'type': 'replace_groupby',\n",
    "                               'values': [\"NAAQA\", \"Freq only\", \"None\", \"Time only\"]\n",
    "                           }\n",
    "                       }\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table X - Per question analysis - COORDCONV\n",
    "    # K = 3\n",
    "    # N_0 = 8\n",
    "    # P = 64\n",
    "    # G = 1024\n",
    "    # J = 3\n",
    "    # M = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "columns = ['extractor_spatial_location', 'stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location' , 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained']\n",
    "#columns = ['extractor_filters', 'classifier_conv_out', 'classifier_projection_out',  'keep_freq_point', 'hop_length', 'extractor_type', 'nb_resblock', 'resblocks_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained', 'folder_dated']\n",
    "\n",
    "\n",
    "filters = (experiments['date'] >= '2020-11-20')\n",
    "#filters = (experiments['date'] >= '2020-09-20')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['input_type'].str.contains('1D'))\n",
    "filters &= (experiments['n_fft'] == 512)\n",
    "filters &= (experiments['keep_freq_point'] == 256)\n",
    "filters &= (experiments['hop_length'] == 2048)\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "\n",
    "# -- Text Processing\n",
    "filters &= (experiments['rnn_state_size'] == 1024)              # G\n",
    "\n",
    "# -- Extractor\n",
    "filters &= (experiments['extractor_nb_block'] == 3)             # K\n",
    "#filters &= (experiments['extractor_filters'] == [8, 16, 32])   # N\n",
    "filters &= (experiments['extractor_projection_size'] == 64)     # P\n",
    "\n",
    "# -- Resblocks\n",
    "filters &= (experiments['nb_resblock'] == 3)                   # J       <---- FIXME: Make sure this is the good values\n",
    "filters &= (experiments['resblocks_out_chan'] == 64)           # M       <---- FIXME: Make sure this is the good values\n",
    "\n",
    "# -- Classifier\n",
    "filters &= (experiments['classifier_conv_out'] == 128)          # C      <---- FIXME: Make sure this is the good values\n",
    "filters &= (experiments['classifier_projection_out'] == 512)    # H      <---- FIXME: Make sure this is the good values\n",
    "\n",
    "# Variable Parameters (CoordConv)\n",
    "filters &= experiments['extractor_spatial_location'].str.contains('None')\n",
    "specific_configs = ((experiments['stem_spatial_location'].str.contains('Both')) & (experiments['resblock_spatial_location'].str.contains('Both')) & (experiments['classifier_spatial_location'].str.contains('Both')))\n",
    "specific_configs |= ((experiments['stem_spatial_location'].str.contains('None')) & (experiments['resblock_spatial_location'].str.contains('Time')) & (experiments['classifier_spatial_location'].str.contains('None')))\n",
    "specific_configs |= ((experiments['stem_spatial_location'].str.contains('Freq')) & (experiments['resblock_spatial_location'].str.contains('None')) & (experiments['classifier_spatial_location'].str.contains('None')))\n",
    "specific_configs |= ((experiments['stem_spatial_location'].str.contains('None')) & (experiments['resblock_spatial_location'].str.contains('None')) & (experiments['classifier_spatial_location'].str.contains('None')))\n",
    "\n",
    "filters &= specific_configs\n",
    "\n",
    "# -- Other\n",
    "filters &= (experiments['note'].str.contains('table_7|table_5_final'))\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "# Display\n",
    "groupby_columns = ['extractor_spatial_location', 'stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location']\n",
    "#acc_columns = ['train_acc', 'best_val_acc', 'test_acc']\n",
    "acc_columns = ['test_acc', *family_test_acc_cols]\n",
    "extra_columns = []#'configuration']#'nb_trainable_param_million']#, 'folder_dated']\n",
    "\n",
    "# Drop duplicates (Same experiment ran multiple time)\n",
    "exp = exp.drop_duplicates(groupby_columns + ['random_seed'],keep='first')\n",
    "\n",
    "# Grouping - Mean & Std calc\n",
    "acc_std_columns = [f\"{c}_std\" for c in acc_columns]\n",
    "columns = groupby_columns + acc_columns + extra_columns\n",
    "#columns_to_show = groupby_columns + acc_std_columns + extra_columns\n",
    "columns_to_show = ['configuration', *acc_columns, 'mean_std', *extra_columns]\n",
    "\n",
    "exp_grouped = groupby_mean(exp, groupby_columns, acc_columns, columns, add_count_col=True, add_std_str=True, inplace_std_str=False)\n",
    "std_cols = [c for c in exp_grouped.columns if 'std' in c]\n",
    "exp_grouped['mean_std'] = exp_grouped[std_cols].mean(axis=1)\n",
    "#train_std_mean, val_std_mean, test_std_mean = exp_grouped['train_acc_std'].mean() * 100, exp_grouped['best_val_acc_std'].mean() * 100, exp_grouped['test_acc_std'].mean() * 100\n",
    "#accuracy_std_mean = np.mean([train_std_mean, val_std_mean, test_std_mean])\n",
    "\n",
    "exp_grouped = exp_grouped.sort_values('test_acc', ascending=False)\n",
    "\n",
    "# Add configuration column\n",
    "exp_grouped['configuration'] = [\"NAAQA\", \"Time only\", \"Freq only\", \"None\"]\n",
    "\n",
    "exp_grouped = exp_grouped[columns_to_show]\n",
    "\n",
    "# All experiments\n",
    "#display(color_by_multi_attribute(exp[columns + ['random_seed', 'note']].sort_values(groupby_columns + ['random_seed'], ascending=False), main_attribute='test_acc', attributes=groupby_columns))\n",
    "\n",
    "# Color display      \n",
    "display(color_by_multi_attribute(exp_grouped, main_attribute=None, \n",
    "                                 attributes=acc_columns, \n",
    "                                 cmaps=['Blues','CMRmap','CMRmap','CMRmap','CMRmap','CMRmap','CMRmap','CMRmap','CMRmap','CMRmap','CMRmap'],\n",
    "                                 format_dict=latex_format_dict))\n",
    "\n",
    "# Latex code\n",
    "latex = exp_grouped[columns_to_show].to_latex(index=False, formatters=latex_format_dict).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "latex = re.sub(r'&\\s*', '& ', latex)\n",
    "print(\"\\n\",latex)\n",
    "#print(f\"STD Means -- Global means : ± {accuracy_std_mean} Train : ± {train_std_mean} Val : ± {val_std_mean} - Test : ± {test_std_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Table X - Filter analysis\n",
    "    # K = 3\n",
    "    # N_0 = 8\n",
    "    # P = 64\n",
    "    # G = 1024\n",
    "    # J = 3\n",
    "    # M = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "columns = ['extractor_spatial_location', 'stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location' , 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained']\n",
    "#columns = ['extractor_filters', 'classifier_conv_out', 'classifier_projection_out',  'keep_freq_point', 'hop_length', 'extractor_type', 'nb_resblock', 'resblocks_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained', 'folder_dated']\n",
    "\n",
    "\n",
    "filters = (experiments['date'] >= '2020-11-20')\n",
    "#filters = (experiments['date'] >= '2020-09-20')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['input_type'].str.contains('1D'))\n",
    "filters &= (experiments['n_fft'] == 512)\n",
    "filters &= (experiments['keep_freq_point'] == 256)\n",
    "filters &= (experiments['hop_length'] == 2048)\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "\n",
    "# -- Text Processing\n",
    "filters &= (experiments['rnn_state_size'] == 1024)              # G\n",
    "\n",
    "# -- Extractor\n",
    "filters &= (experiments['extractor_nb_block'] == 3)             # K\n",
    "#filters &= (experiments['extractor_filters'] == [8, 16, 32])   # N\n",
    "filters &= (experiments['extractor_projection_size'] == 64)     # P\n",
    "\n",
    "# -- Resblocks\n",
    "filters &= (experiments['nb_resblock'] == 3)                   # J       <---- FIXME: Make sure this is the good values\n",
    "filters &= (experiments['resblocks_out_chan'] == 64)           # M       <---- FIXME: Make sure this is the good values\n",
    "\n",
    "# -- Classifier\n",
    "filters &= (experiments['classifier_conv_out'] == 128)          # C      <---- FIXME: Make sure this is the good values\n",
    "filters &= (experiments['classifier_projection_out'] == 512)    # H      <---- FIXME: Make sure this is the good values\n",
    "\n",
    "# Variable Parameters (CoordConv)\n",
    "filters &= ((experiments['extractor_spatial_location'].str.contains('None')) & (experiments['stem_spatial_location'].str.contains('Both')) & (experiments['resblock_spatial_location'].str.contains('Both')) & (experiments['classifier_spatial_location'].str.contains('Both')))\n",
    "\n",
    "# -- Other\n",
    "filters &= (experiments['note'].str.contains('table_7|table_5_final'))\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "# Display\n",
    "groupby_columns = ['extractor_spatial_location', 'stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location']\n",
    "#acc_columns = ['train_acc', 'best_val_acc', 'test_acc']\n",
    "#acc_columns = ['test_acc', *family_test_acc_cols]\n",
    "acc_columns = family_test_acc_cols\n",
    "#acc_columns = global_test_acc_cols\n",
    "extra_columns = []#'configuration']#'nb_trainable_param_million']#, 'folder_dated']\n",
    "\n",
    "# Drop duplicates (Same experiment ran multiple time)\n",
    "exp = exp.drop_duplicates(groupby_columns + ['random_seed'],keep='first')\n",
    "\n",
    "# Grouping - Mean & Std calc\n",
    "acc_std_columns = [f\"{c}_std\" for c in acc_columns]\n",
    "columns = groupby_columns + acc_columns + extra_columns\n",
    "#columns_to_show = groupby_columns + acc_std_columns + extra_columns\n",
    "columns_to_show = ['configuration', *acc_columns]#, 'mean_std', *extra_columns]\n",
    "\n",
    "exp_grouped = groupby_mean(exp, groupby_columns, acc_columns, columns, add_count_col=True, add_std_str=True, inplace_std_str=False)\n",
    "std_cols = [c for c in exp_grouped.columns if 'std' in c]\n",
    "#exp_grouped['mean_std'] = exp_grouped[std_cols].mean(axis=1)\n",
    "#train_std_mean, val_std_mean, test_std_mean = exp_grouped['train_acc_std'].mean() * 100, exp_grouped['best_val_acc_std'].mean() * 100, exp_grouped['test_acc_std'].mean() * 100\n",
    "#accuracy_std_mean = np.mean([train_std_mean, val_std_mean, test_std_mean])\n",
    "\n",
    "#exp_grouped = exp_grouped.sort_values('test_acc', ascending=False)\n",
    "\n",
    "# Add configuration column\n",
    "exp_grouped['configuration'] = [\"NAAQA\"]\n",
    "\n",
    "exp_grouped = exp_grouped[columns_to_show]\n",
    "\n",
    "# All experiments\n",
    "#display(color_by_multi_attribute(exp[columns + ['random_seed', 'note']].sort_values(groupby_columns + ['random_seed'], ascending=False), main_attribute='test_acc', attributes=groupby_columns))\n",
    "\n",
    "# Color display      \n",
    "display(color_by_multi_attribute(exp_grouped, main_attribute=None, \n",
    "                                 attributes=acc_columns, \n",
    "                                 cmaps=['Blues','CMRmap','CMRmap','CMRmap','CMRmap','CMRmap','CMRmap','CMRmap','CMRmap','CMRmap','CMRmap'],\n",
    "                                 format_dict=latex_format_dict))\n",
    "\n",
    "# Latex code\n",
    "latex = exp_grouped[columns_to_show].to_latex(index=False, formatters=latex_format_dict).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "latex = re.sub(r'&\\s*', '& ', latex)\n",
    "print(\"\\n\",latex)\n",
    "#print(f\"STD Means -- Global means : ± {accuracy_std_mean} Train : ± {train_std_mean} Val : ± {val_std_mean} - Test : ± {test_std_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_grouped.style.background_gradient(axis=1, cmap='CMRmap_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = exp_grouped.plot.bar()\n",
    "ax.legend([\"Instrument\", 'Note', 'Brightness', 'Loudness', 'Exist', 'Abs Pos', 'Global Pos', 'Rel Pos', 'Count', 'Count compare', 'Count diff'],bbox_to_anchor=(0.75, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 2 - GRU Reduction\n",
    "# Static Parameters :\n",
    "    # Extractor = Parallel\n",
    "    # J = 4\n",
    "    # M = 128\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "    # K = 3\n",
    "    # N = [8, 16, 32]\n",
    "    # P = 64\n",
    "# Variable Parameters: \n",
    "    # G={4096,2048, 1024, 512, 256}\n",
    "    \n",
    "columns = ['extractor_type', 'nb_resblock', 'resblocks_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained']\n",
    "columns = ['extractor_filters', 'classifier_conv_out', 'classifier_projection_out',  'keep_freq_point', 'hop_length', 'extractor_type', 'nb_resblock', 'resblocks_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained', 'folder_dated']\n",
    "\n",
    "filters = (experiments['date'] >= '2020-11-20')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['input_type'].str.contains('1D'))\n",
    "filters &= (experiments['n_fft'] == 512)\n",
    "filters &= (experiments['keep_freq_point'] == 256)\n",
    "filters &= (experiments['hop_length'] == 2048)\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "\n",
    "# -- Coordconv\n",
    "filters &= (experiments['extractor_spatial_location'] == 'None')\n",
    "filters &= (experiments['stem_spatial_location'] == 'Both')\n",
    "filters &= (experiments['resblock_spatial_location'] == 'Both')\n",
    "filters &= (experiments['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "# -- Extractor\n",
    "filters &= experiments['extractor_type'].str.contains('Parallel')\n",
    "filters &= (experiments['extractor_nb_block'] == 3)             # K\n",
    "#filters &= (experiments['extractor_filters'] == [8, 16, 32])   # N\n",
    "filters &= (experiments['extractor_projection_size'] == 64)     # P      <---- FIXME : Might want to try with 32\n",
    "\n",
    "# -- Resblocks\n",
    "filters &= (experiments['nb_resblock'] == 4)                    # J\n",
    "filters &= (experiments['resblocks_out_chan'] == 128)           # M\n",
    "\n",
    "# -- Classifier\n",
    "#filters &= (experiments['classifier_conv_out'] == 512)           # C \n",
    "#filters &= (experiments['classifier_projection_out'] == 1024)    # H\n",
    "\n",
    "# Variable Parameters (Text-Processing GRU units)\n",
    "filters &= (experiments['rnn_state_size'].isin([4096, 2048, 1024, 512, 256])) # G\n",
    "\n",
    "# -- Other\n",
    "filters &= (experiments['note'].str.contains('table_3|table_2_final_final'))\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "# Display\n",
    "groupby_columns = ['rnn_state_size']\n",
    "acc_columns = ['train_acc', 'best_val_acc', 'test_acc']\n",
    "extra_columns = ['nb_trainable_param_million', 'train_time']\n",
    "\n",
    "# Drop duplicates (Same experiment ran multiple time)\n",
    "exp = exp.drop_duplicates(groupby_columns + ['random_seed'],keep='first')\n",
    "\n",
    "# Grouping - Mean & Std calc\n",
    "acc_std_columns = [f\"{c}_std\" for c in acc_columns]\n",
    "columns = groupby_columns + acc_columns + extra_columns\n",
    "\n",
    "exp_grouped = groupby_mean(exp, groupby_columns, acc_columns, columns, add_count_col=True, add_std_str=True)\n",
    "train_std_mean, val_std_mean, test_std_mean = exp_grouped['train_acc_std'].mean() * 100, exp_grouped['best_val_acc_std'].mean() * 100, exp_grouped['test_acc_std'].mean() * 100\n",
    "accuracy_std_mean = np.mean([train_std_mean, val_std_mean, test_std_mean])\n",
    "\n",
    "exp_grouped = exp_grouped.sort_values('test_acc', ascending=False)#[columns]\n",
    "\n",
    "# All experiments\n",
    "display(color_by_multi_attribute(exp[columns + ['random_seed', 'note']].sort_values(groupby_columns + ['random_seed', 'train_time'], ascending=False), main_attribute='test_acc', attributes=groupby_columns))\n",
    "\n",
    "# Color display\n",
    "display(color_by_multi_attribute(exp_grouped, main_attribute='test_acc', \n",
    "                                 attributes=['rnn_state_size'],\n",
    "                                 #attributes=['stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location', 'test_acc'],\n",
    "                                 cmaps=['Blues', 'YlOrRd', 'YlOrRd', 'YlOrRd', 'YlOrRd'], \n",
    "                                 format_dict=latex_format_dict))\n",
    "\n",
    "# Latex code\n",
    "latex = exp_grouped.to_latex(index=False, formatters=latex_format_dict).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "print(\"\\n\",latex)\n",
    "\n",
    "print(f\"STD Means -- Global means : ± {accuracy_std_mean} Train : ± {train_std_mean} Val : ± {val_std_mean} - Test : ± {test_std_mean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 3 - Classifier Topologies\n",
    "# Static Parameters :\n",
    "    # Extractor = Parallel\n",
    "    # J = 4\n",
    "    # M = 128\n",
    "    # K = 3\n",
    "    # N = [8, 16, 32]\n",
    "    # P = 64\n",
    "# Variable Parameters :\n",
    "    # Classifier Topology = {Fcn, Conv}\n",
    "    # C = {512, 256, 128, None}\n",
    "    # H = {1024, 512, 256, None}\n",
    "\n",
    "filters = (experiments['date'] >= '2020-11-20')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['input_type'].str.contains('1D'))\n",
    "filters &= (experiments['n_fft'] == 512)\n",
    "filters &= (experiments['keep_freq_point'] == 256)\n",
    "filters &= (experiments['hop_length'] == 2048)\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "\n",
    "# -- Text Processing\n",
    "filters &= (experiments['rnn_state_size'] == 1024)              # G\n",
    "\n",
    "# -- Coordconv\n",
    "filters &= (experiments['extractor_spatial_location'] == 'None')\n",
    "filters &= (experiments['stem_spatial_location'] == 'Both')\n",
    "filters &= (experiments['resblock_spatial_location'] == 'Both')\n",
    "filters &= (experiments['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "# -- Extractor\n",
    "filters &= experiments['extractor_type'].str.contains('Parallel')\n",
    "filters &= (experiments['extractor_nb_block'] == 3)             # K\n",
    "#filters &= (experiments['extractor_filters'] == [8, 16, 32])   # N\n",
    "filters &= (experiments['extractor_projection_size'] == 64)     # P      <---- FIXME : Might want to try with 32\n",
    "\n",
    "# -- Resblocks\n",
    "filters &= (experiments['nb_resblock'] == 4)                    # J\n",
    "filters &= (experiments['resblocks_out_chan'] == 128)           # M\n",
    "\n",
    "# Variable Parameters (Classifier Topologies)\n",
    "filters &= (experiments['classifier_type'].str.contains('fcn|conv'))\n",
    "filters &= (experiments['classifier_conv_out'].isin([512, 256, 128, None]))          # C\n",
    "filters &= (experiments['classifier_projection_out'].isin([1024, 512, 256, None]))   # H\n",
    "\n",
    "# Other\n",
    "filters &= (experiments['note'].str.contains('1_worker|table_3_table_3'))\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "# Display\n",
    "groupby_columns = ['classifier_type', 'classifier_conv_out', 'classifier_projection_out']\n",
    "acc_columns = ['train_acc', 'best_val_acc', 'test_acc']\n",
    "extra_columns = ['nb_trainable_param_million', 'note']\n",
    "\n",
    "# Drop duplicates (Same experiment ran multiple time)\n",
    "exp = exp.drop_duplicates(groupby_columns + ['random_seed'],keep='first')\n",
    "\n",
    "# Grouping - Mean & Std calc\n",
    "acc_std_columns = [f\"{c}_std\" for c in acc_columns]\n",
    "columns = groupby_columns + acc_columns + extra_columns\n",
    "\n",
    "exp_grouped = groupby_mean(exp, groupby_columns, acc_columns, columns, add_count_col=True, add_std_str=True)\n",
    "train_std_mean, val_std_mean, test_std_mean = exp_grouped['train_acc_std'].mean() * 100, exp_grouped['best_val_acc_std'].mean() * 100, exp_grouped['test_acc_std'].mean() * 100\n",
    "accuracy_std_mean = np.mean([train_std_mean, val_std_mean, test_std_mean])\n",
    "\n",
    "exp_grouped = exp_grouped.sort_values('test_acc', ascending=False)#[columns]\n",
    "\n",
    "# All experiments\n",
    "#display(color_by_multi_attribute(exp[columns + ['random_seed', 'note']].sort_values(groupby_columns + ['random_seed'], ascending=False), main_attribute='test_acc', attributes=groupby_columns))\n",
    "\n",
    "# Color display\n",
    "display(color_by_multi_attribute(exp_grouped, main_attribute='test_acc', \n",
    "                                 attributes=['classifier_type'],# 'classifier_conv_out', 'classifier_projection_out'],\n",
    "                                 cmaps=['Blues'], \n",
    "                                 format_dict=latex_format_dict))\n",
    "\n",
    "# Latex code\n",
    "latex = exp_grouped.to_latex(index=False, formatters=latex_format_dict).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "\n",
    "print(\"\\n\",latex)\n",
    "print(f\"STD Means -- Global means : ± {accuracy_std_mean} Train : ± {train_std_mean} Val : ± {val_std_mean} - Test : ± {test_std_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Table 4 - Resblocks\n",
    "# Static parameters\n",
    "    # Extractor = Parallel\n",
    "    # K = 3\n",
    "    # N = [8, 16, 32]\n",
    "    # P = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "# Variable Parameters\n",
    "    # J = {4, 3, 2, 1}\n",
    "    # M = {128, 64, 32}\n",
    "\n",
    "filters = (experiments['date'] >= '2020-11-20')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['input_type'].str.contains('1D'))\n",
    "filters &= (experiments['n_fft'] == 512)\n",
    "filters &= (experiments['keep_freq_point'] == 256)\n",
    "filters &= (experiments['hop_length'] == 2048)\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "\n",
    "# -- Text Processing\n",
    "filters &= (experiments['rnn_state_size'] == 1024)              # G\n",
    "\n",
    "# -- Coordconv\n",
    "filters &= (experiments['extractor_spatial_location'] == 'None')\n",
    "filters &= (experiments['stem_spatial_location'] == 'Both')\n",
    "filters &= (experiments['resblock_spatial_location'] == 'Both')\n",
    "filters &= (experiments['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "# -- Extractor\n",
    "filters &= experiments['extractor_type'].str.contains('Parallel')\n",
    "filters &= (experiments['extractor_nb_block'] == 3)             # K\n",
    "#filters &= (experiments['extractor_filters'] == [8, 16, 32])   # N\n",
    "filters &= (experiments['extractor_projection_size'] == 64)     # P      <---- FIXME : Might want to try with 32\n",
    "\n",
    "# -- Classifier\n",
    "filters &= (experiments['classifier_conv_out'] == 128)          # C      <---- FIXME: Make sure this is the good values\n",
    "filters &= (experiments['classifier_projection_out'] == 512)    # H      <---- FIXME: Make sure this is the good values\n",
    "\n",
    "# Variable Parameters (Resblocks)\n",
    "filters &= (experiments['nb_resblock'] <= 4)                    # J\n",
    "filters &= (experiments['resblocks_out_chan'].isin([128, 64, 32]))           # M\n",
    "\n",
    "# -- Other\n",
    "filters &= (experiments['note'].str.contains('table_5_final|table_4.*1_worker'))    # Table 4 result for comparison\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -- Comparison\n",
    "#filters |= ( (experiments['nb_resblock'] == 4) & (experiments['resblocks_out_chan'] == 128) & (experiments['note'].str.contains('table_4.*1_worker')) & experiments['extractor_type'].str.contains('Parallel') & (experiments['classifier_conv_out'] == 128) & (experiments['classifier_projection_out'] == 512) )\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "# Display\n",
    "groupby_columns = ['nb_resblock', 'resblocks_out_chan']\n",
    "acc_columns = ['train_acc', 'best_val_acc', 'test_acc']\n",
    "extra_columns = ['nb_trainable_param_million']\n",
    "\n",
    "# Drop duplicates (Same experiment ran multiple time)\n",
    "exp = exp.drop_duplicates(groupby_columns + ['random_seed'],keep='first')\n",
    "\n",
    "# Grouping - Mean & Std calc\n",
    "acc_std_columns = [f\"{c}_std\" for c in acc_columns]\n",
    "columns = groupby_columns + acc_columns + extra_columns\n",
    "\n",
    "exp_grouped = groupby_mean(exp, groupby_columns, acc_columns, columns, add_count_col=True, add_std_str=True)\n",
    "train_std_mean, val_std_mean, test_std_mean = exp_grouped['train_acc_std'].mean() * 100, exp_grouped['best_val_acc_std'].mean() * 100, exp_grouped['test_acc_std'].mean() * 100\n",
    "accuracy_std_mean = np.mean([train_std_mean, val_std_mean, test_std_mean])\n",
    "\n",
    "exp_grouped = exp_grouped.sort_values('test_acc', ascending=False)#[columns]\n",
    "\n",
    "# All experiments\n",
    "display(color_by_multi_attribute(exp[columns + ['random_seed', 'note']].sort_values(groupby_columns + ['random_seed'], ascending=False), main_attribute='test_acc', attributes=groupby_columns))\n",
    "\n",
    "# Color display\n",
    "display(color_by_multi_attribute(exp_grouped, main_attribute='test_acc', \n",
    "                                 attributes=[],\n",
    "                                 #attributes=['stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location', 'test_acc'],\n",
    "                                 cmaps=['Blues', 'YlOrRd', 'YlOrRd', 'YlOrRd', 'YlOrRd'], \n",
    "                                 format_dict=latex_format_dict))\n",
    "\n",
    "# Latex code\n",
    "latex = exp_grouped.to_latex(index=False, formatters=latex_format_dict).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "\n",
    "print(\"\\n\",latex)\n",
    "print(f\"STD Means -- Global means : ± {accuracy_std_mean} Train : ± {train_std_mean} Val : ± {val_std_mean} - Test : ± {test_std_mean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 4 - Resblocks\n",
    "# Static parameters\n",
    "    # Extractor = Parallel\n",
    "    # K = 3\n",
    "    # N = [8, 16, 32]\n",
    "    # P = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "# Variable Parameters\n",
    "    # J = {4, 3, 2, 1}\n",
    "    # M = {128, 64, 32}\n",
    "\n",
    "filters = (experiments['date'] >= '2020-11-20')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['input_type'].str.contains('1D'))\n",
    "filters &= (experiments['n_fft'] == 512)\n",
    "filters &= (experiments['keep_freq_point'] == 256)\n",
    "filters &= (experiments['hop_length'] == 2048)\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "\n",
    "# -- Text Processing\n",
    "filters &= (experiments['rnn_state_size'] == 1024)              # G\n",
    "\n",
    "# -- Coordconv\n",
    "filters &= (experiments['extractor_spatial_location'] == 'None')\n",
    "filters &= (experiments['stem_spatial_location'] == 'Both')\n",
    "filters &= (experiments['resblock_spatial_location'] == 'Both')\n",
    "filters &= (experiments['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "# -- Extractor\n",
    "#filters &= experiments['extractor_type'].str.contains('Parallel')\n",
    "#filters &= (experiments['extractor_nb_block'] == 3)             # K\n",
    "#filters &= (experiments['extractor_filters'] == [8, 16, 32])   # N\n",
    "#filters &= (experiments['extractor_projection_size'] == 64)     # P      <---- FIXME : Might want to try with 32\n",
    "\n",
    "# -- Classifier\n",
    "filters &= (experiments['classifier_conv_out'] == 128)          # C      <---- FIXME: Make sure this is the good values\n",
    "filters &= (experiments['classifier_projection_out'] == 512)    # H      <---- FIXME: Make sure this is the good values\n",
    "\n",
    "# Variable Parameters (Resblocks)\n",
    "filters &= (experiments['nb_resblock'] <= 4)                    # J\n",
    "filters &= (experiments['resblocks_out_chan'].isin([128, 64, 32]))           # M\n",
    "\n",
    "# -- Other\n",
    "filters &= (experiments['note'].str.contains('table_5_baseline_extractor'))\n",
    "#filters &= (experiments['note'].str.contains('table_5_final|table_4.*1_worker'))    # Table 4 result for comparison\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -- Comparison\n",
    "#filters |= ( (experiments['nb_resblock'] == 4) & (experiments['resblocks_out_chan'] == 128) & (experiments['note'].str.contains('table_4.*1_worker')) & experiments['extractor_type'].str.contains('Parallel') & (experiments['classifier_conv_out'] == 128) & (experiments['classifier_projection_out'] == 512) )\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "# Display\n",
    "groupby_columns = ['nb_resblock', 'resblocks_out_chan']\n",
    "acc_columns = ['train_acc', 'best_val_acc', 'test_acc']\n",
    "extra_columns = ['nb_trainable_param_million']\n",
    "\n",
    "# Drop duplicates (Same experiment ran multiple time)\n",
    "exp = exp.drop_duplicates(groupby_columns + ['random_seed'],keep='first')\n",
    "\n",
    "# Grouping - Mean & Std calc\n",
    "acc_std_columns = [f\"{c}_std\" for c in acc_columns]\n",
    "columns = groupby_columns + acc_columns + extra_columns\n",
    "\n",
    "exp_grouped = groupby_mean(exp, groupby_columns, acc_columns, columns, add_count_col=True, add_std_str=True)\n",
    "train_std_mean, val_std_mean, test_std_mean = exp_grouped['train_acc_std'].mean() * 100, exp_grouped['best_val_acc_std'].mean() * 100, exp_grouped['test_acc_std'].mean() * 100\n",
    "accuracy_std_mean = np.mean([train_std_mean, val_std_mean, test_std_mean])\n",
    "\n",
    "exp_grouped = exp_grouped.sort_values('test_acc', ascending=False)#[columns]\n",
    "\n",
    "# All experiments\n",
    "display(color_by_multi_attribute(exp[columns + ['random_seed', 'note']].sort_values(groupby_columns + ['random_seed'], ascending=False), main_attribute='test_acc', attributes=groupby_columns))\n",
    "\n",
    "# Color display\n",
    "display(color_by_multi_attribute(exp_grouped, main_attribute='test_acc', \n",
    "                                 attributes=[],\n",
    "                                 #attributes=['stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location', 'test_acc'],\n",
    "                                 cmaps=['Blues', 'YlOrRd', 'YlOrRd', 'YlOrRd', 'YlOrRd'], \n",
    "                                 format_dict=latex_format_dict))\n",
    "\n",
    "# Latex code\n",
    "latex = exp_grouped.to_latex(index=False, formatters=latex_format_dict).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "\n",
    "print(\"\\n\",latex)\n",
    "print(f\"STD Means -- Global means : ± {accuracy_std_mean} Train : ± {train_std_mean} Val : ± {val_std_mean} - Test : ± {test_std_mean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 5 - Extractor filter reduction\n",
    "# Static parameters :\n",
    "    # G = 1024\n",
    "    # J = 3\n",
    "    # M = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "# Variable parameters :\n",
    "    # k = {4,3,2,1}\n",
    "    # P = {128, 64, 32, None}\n",
    "\n",
    "filters = (experiments['date'] >= '2020-11-20')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['input_type'].str.contains('1D'))\n",
    "filters &= (experiments['n_fft'] == 512)\n",
    "filters &= (experiments['keep_freq_point'] == 256)\n",
    "filters &= (experiments['hop_length'] == 2048)\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "\n",
    "# -- Text Processing\n",
    "filters &= (experiments['rnn_state_size'] == 1024)              # G\n",
    "\n",
    "# -- Coordconv\n",
    "filters &= (experiments['extractor_spatial_location'] == 'None')\n",
    "filters &= (experiments['stem_spatial_location'] == 'Both')\n",
    "filters &= (experiments['resblock_spatial_location'] == 'Both')\n",
    "filters &= (experiments['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "# -- Resblocks\n",
    "filters &= (experiments['nb_resblock'] == 3)                   # J       <---- FIXME: Make sure this is the good values\n",
    "filters &= (experiments['resblocks_out_chan'] == 64)           # M       <---- FIXME: Make sure this is the good values\n",
    "\n",
    "# -- Classifier\n",
    "filters &= (experiments['classifier_conv_out'] == 128)          # C      <---- FIXME: Make sure this is the good values\n",
    "filters &= (experiments['classifier_projection_out'] == 512)    # H      <---- FIXME: Make sure this is the good values\n",
    "\n",
    "# Variable Parameters (Extractor configuration)\n",
    "#filters &= experiments['extractor_type'].str.contains('Parallel|Interleaved')\n",
    "filters &= experiments['extractor_type'].str.contains('Parallel')\n",
    "filters &= (experiments['extractor_nb_block'] <= 4)             # K\n",
    "#filters &= (experiments['extractor_filters'] == [8, 16, 32])   # N\n",
    "filters &= (experiments['extractor_projection_size'].isin([128, 64, 32, None]))     # P\n",
    "\n",
    "# -- Other\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "# Display\n",
    "groupby_columns = ['extractor_nb_block', 'extractor_projection_size']\n",
    "acc_columns = ['train_acc', 'best_val_acc', 'test_acc']\n",
    "extra_columns = ['nb_trainable_param_million']\n",
    "\n",
    "# Drop duplicates (Same experiment ran multiple time)\n",
    "exp = exp.drop_duplicates(groupby_columns + ['random_seed'],keep='first')\n",
    "\n",
    "# Grouping - Mean & Std calc\n",
    "acc_std_columns = [f\"{c}_std\" for c in acc_columns]\n",
    "columns = groupby_columns + acc_columns + extra_columns\n",
    "\n",
    "exp_grouped = groupby_mean(exp, groupby_columns, acc_columns, columns, add_count_col=True, add_std_str=True)\n",
    "train_std_mean, val_std_mean, test_std_mean = exp_grouped['train_acc_std'].mean() * 100, exp_grouped['best_val_acc_std'].mean() * 100, exp_grouped['test_acc_std'].mean() * 100\n",
    "accuracy_std_mean = np.mean([train_std_mean, val_std_mean, test_std_mean])\n",
    "\n",
    "exp_grouped = exp_grouped.sort_values('test_acc', ascending=False)#[columns]\n",
    "\n",
    "# All experiments\n",
    "#display(color_by_multi_attribute(exp[columns + ['random_seed', 'note']].sort_values(groupby_columns + ['random_seed'], ascending=False), main_attribute='test_acc', attributes=groupby_columns))\n",
    "\n",
    "# Color display\n",
    "display(color_by_multi_attribute(exp_grouped, main_attribute='test_acc', \n",
    "                                 attributes=['extractor_nb_block', 'extractor_projection_size'],\n",
    "                                 #attributes=['stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location', 'test_acc'],\n",
    "                                 cmaps=['Blues'], \n",
    "                                 format_dict=latex_format_dict))\n",
    "\n",
    "# Latex code\n",
    "latex = exp_grouped.to_latex(index=False, formatters=latex_format_dict).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "\n",
    "print(\"\\n\",latex)\n",
    "print(f\"STD Means -- Global means : ± {accuracy_std_mean} Train : ± {train_std_mean} Val : ± {val_std_mean} - Test : ± {test_std_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Table 7 - CoordConv\n",
    "    # K = 3\n",
    "    # N_0 = 8\n",
    "    # P = 64\n",
    "    # G = 1024\n",
    "    # J = 3\n",
    "    # M = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "columns = ['extractor_spatial_location', 'stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location' , 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained']\n",
    "#columns = ['extractor_filters', 'classifier_conv_out', 'classifier_projection_out',  'keep_freq_point', 'hop_length', 'extractor_type', 'nb_resblock', 'resblocks_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained', 'folder_dated']\n",
    "\n",
    "\n",
    "filters = (experiments['date'] >= '2020-11-20')\n",
    "#filters = (experiments['date'] >= '2020-09-20')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['input_type'].str.contains('1D'))\n",
    "filters &= (experiments['n_fft'] == 512)\n",
    "filters &= (experiments['keep_freq_point'] == 256)\n",
    "filters &= (experiments['hop_length'] == 2048)\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "\n",
    "# -- Text Processing\n",
    "filters &= (experiments['rnn_state_size'] == 1024)              # G\n",
    "\n",
    "# -- Extractor\n",
    "filters &= (experiments['extractor_nb_block'] == 3)             # K\n",
    "#filters &= (experiments['extractor_filters'] == [8, 16, 32])   # N\n",
    "filters &= (experiments['extractor_projection_size'] == 64)     # P\n",
    "\n",
    "# -- Resblocks\n",
    "filters &= (experiments['nb_resblock'] == 3)                   # J       <---- FIXME: Make sure this is the good values\n",
    "filters &= (experiments['resblocks_out_chan'] == 64)           # M       <---- FIXME: Make sure this is the good values\n",
    "\n",
    "# -- Classifier\n",
    "filters &= (experiments['classifier_conv_out'] == 128)          # C      <---- FIXME: Make sure this is the good values\n",
    "filters &= (experiments['classifier_projection_out'] == 512)    # H      <---- FIXME: Make sure this is the good values\n",
    "\n",
    "# Variable Parameters (CoordConv)\n",
    "filters &= (experiments['extractor_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "filters &= (experiments['stem_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "filters &= (experiments['resblock_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "filters &= (experiments['classifier_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "\n",
    "# -- Other\n",
    "filters &= (experiments['note'].str.contains('table_7|table_5_final'))\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "# Display\n",
    "groupby_columns = ['extractor_spatial_location', 'stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location']\n",
    "acc_columns = ['train_acc', 'best_val_acc', 'test_acc']\n",
    "extra_columns = ['nb_trainable_param_million']#, 'folder_dated']\n",
    "\n",
    "# Drop duplicates (Same experiment ran multiple time)\n",
    "exp = exp.drop_duplicates(groupby_columns + ['random_seed'],keep='first')\n",
    "\n",
    "# Grouping - Mean & Std calc\n",
    "acc_std_columns = [f\"{c}_std\" for c in acc_columns]\n",
    "columns = groupby_columns + acc_columns + extra_columns\n",
    "\n",
    "exp_grouped = groupby_mean(exp, groupby_columns, acc_columns, columns, add_count_col=True, add_std_str=True)\n",
    "train_std_mean, val_std_mean, test_std_mean = exp_grouped['train_acc_std'].mean() * 100, exp_grouped['best_val_acc_std'].mean() * 100, exp_grouped['test_acc_std'].mean() * 100\n",
    "accuracy_std_mean = np.mean([train_std_mean, val_std_mean, test_std_mean])\n",
    "\n",
    "exp_grouped = exp_grouped.sort_values('test_acc', ascending=False)[columns]\n",
    "\n",
    "#display(color_by_multi_attribute(exp[columns + ['random_seed', 'note']].sort_values(groupby_columns + ['random_seed'], ascending=False), main_attribute='test_acc', attributes=groupby_columns))\n",
    "\n",
    "# Color display\n",
    "display(color_by_multi_attribute(exp_grouped, main_attribute='test_acc', \n",
    "                                 attributes=['extractor_spatial_location', 'stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location', 'test_acc', 'test_acc_std'],\n",
    "                                 cmaps=['Blues', 'YlOrRd', 'YlOrRd', 'YlOrRd', 'YlOrRd'], \n",
    "                                 format_dict=latex_format_dict))\n",
    "\n",
    "# Latex code\n",
    "latex = exp_grouped.to_latex(index=False, formatters=latex_format_dict).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "\n",
    "print(\"\\n\",latex)\n",
    "print(f\"STD Means -- Global means : ± {accuracy_std_mean} Train : ± {train_std_mean} Val : ± {val_std_mean} - Test : ± {test_std_mean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_outliers(df, groupby_columns, outlier_col='nb_epoch_trained'):\n",
    "    # hacky code... \n",
    "    # Return a dataframe mask where each df['nb_epoch_trained'] > mean(df['nb_epoch_trained')] - std(df['nb_epoch_trained'])\n",
    "    columns_of_interest = [*groupby_columns, outlier_col]\n",
    "    \n",
    "    if not isinstance(groupby_columns, list):\n",
    "        groupby_columns = [groupby_columns]\n",
    "        \n",
    "    nb_groupby_cols = len(groupby_columns)\n",
    "    \n",
    "    grouped = df[columns_of_interest].groupby(groupby_columns).agg({outlier_col: lambda x: int(np.mean(x) - np.std(x))})\n",
    "    \n",
    "    new_filters = None\n",
    "    for grouped_cols, row in grouped.iterrows():\n",
    "        if nb_groupby_cols == 1:\n",
    "            grouped_cols = (grouped_cols, )\n",
    "   \n",
    "        new_filter = (df[outlier_col] > row[outlier_col])\n",
    "        \n",
    "        for col_name, col_val in zip(groupby_columns, grouped_cols):\n",
    "            new_filter &= (df[col_name] == col_val)\n",
    "\n",
    "        if new_filters is None:\n",
    "            new_filters = new_filter\n",
    "        else:\n",
    "            new_filters |= new_filter\n",
    "            \n",
    "    return df[new_filters]\n",
    "\n",
    "\n",
    "def keep_x_best(filtered_df, groupby_columns, nb_to_keep, discriminative_attribute='test_acc'):\n",
    "    return filtered_df.sort_values([*groupby_columns, discriminative_attribute], ascending=False).groupby(groupby_columns, as_index=False).apply(lambda x: x.iloc[:nb_to_keep])\n",
    "\n",
    "\n",
    "def print_missing_seeds(df, groupby_cols, all_seeds):\n",
    "    if not isinstance(all_seeds, set):\n",
    "        all_seeds = set(all_seeds)\n",
    "    \n",
    "    def print_by_group(x):\n",
    "        missing_seeds = all_seeds - set(x['random_seed'])\n",
    "        if len(missing_seeds) > 0:\n",
    "            print(x.name, \"  Missing : \", missing_seeds)\n",
    "            \n",
    "    df.sort_values(groupby_cols, ascending=False).groupby(groupby_cols).apply(print_by_group)\n",
    "\n",
    "\n",
    "def show_table2(df, filters, groupby_columns, acc_columns, extra_columns=None, format_dict=None, attribute_by_color=None, mean_std_col=False, display_all=False, hardcoded_cols=None, \n",
    "               show_count_col=False, inplace_std=False, remove_outliers=False, print_latex=True, nb_to_keep=None, all_seeds=None):\n",
    "    \n",
    "    exp = df[filters]\n",
    "    \n",
    "    if extra_columns is None:\n",
    "        extra_columns = []\n",
    "    \n",
    "    if attribute_by_color is None:\n",
    "        attribute_by_color = {}\n",
    "        \n",
    "    if all_seeds is not None:\n",
    "        print_missing_seeds(exp, groupby_columns, all_seeds)\n",
    "\n",
    "    # Drop duplicates (Same experiment ran multiple time)\n",
    "    exp = exp.sort_values('date', ascending=False).drop_duplicates([*groupby_columns, 'random_seed', 'input_type', 'config'],keep='first')\n",
    "        \n",
    "    if remove_outliers:\n",
    "        exp = filter_outliers(exp, groupby_columns)\n",
    "    \n",
    "    if nb_to_keep is not None:\n",
    "        exp = keep_x_best(exp, groupby_columns, nb_to_keep, 'test_acc')\n",
    "\n",
    "    # Grouping - Mean & Std calc\n",
    "    acc_std_columns = [f\"{c}_std\" for c in acc_columns]\n",
    "    columns = groupby_columns + acc_columns + extra_columns\n",
    "    columns_to_show = [*groupby_columns, *acc_columns, *extra_columns]\n",
    "    \n",
    "    # All experiments\n",
    "    if display_all:\n",
    "        all_exp = exp.sort_values([*groupby_columns, 'random_seed'], ascending=False)[columns_to_show]\n",
    "        display(color_by_multi_attribute(all_exp, \n",
    "                                         main_attribute='test_acc', \n",
    "                                         attributes=groupby_columns,\n",
    "                                         format_dict=format_dict))\n",
    "\n",
    "    exp_grouped = groupby_mean(exp, groupby_columns, acc_columns, columns, add_count_col=show_count_col, add_std_str=True, inplace_std_str=inplace_std).sort_values('test_acc', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    if hardcoded_cols is not None:\n",
    "        for col_name, col_conf in hardcoded_cols.items():\n",
    "            \n",
    "            if col_conf['type'] == \"replace_groupby\":\n",
    "                columns_to_show = [c for c in columns_to_show if c not in groupby_columns]\n",
    "            \n",
    "            exp_grouped[col_name] = col_conf['values']\n",
    "            columns_to_show = [col_name, *columns_to_show]\n",
    "            \n",
    "    if inplace_std:\n",
    "        mean_std_col = False\n",
    "        columns_to_show = [c if c not in acc_columns else f'{c}_std' for c in columns_to_show]\n",
    "        attribute_by_color = {(name if name not in acc_columns else f\"{name}_std\"):color for name, color in attribute_by_color.items()}\n",
    "    \n",
    "    if mean_std_col:\n",
    "        exp_grouped['mean_std'] = exp_grouped[acc_std_columns].mean(axis=1)\n",
    "        \n",
    "        if len(extra_columns) == 0:\n",
    "            up_to_extra_col = columns_to_show\n",
    "        else:\n",
    "            up_to_extra_col = columns_to_show[:columns_to_show.index(extra_columns[0])]\n",
    "            \n",
    "        columns_to_show = [*up_to_extra_col, 'mean_std', *extra_columns]\n",
    "\n",
    "    if show_count_col:\n",
    "        columns_to_show.append('count')\n",
    "        \n",
    "    exp_grouped = exp_grouped[columns_to_show]\n",
    "    \n",
    "    main_attribute_to_color = 'test_acc' if not inplace_std else 'test_acc_std'\n",
    "\n",
    "    # Color display      \n",
    "    display(color_by_multi_attribute(exp_grouped, main_attribute=main_attribute_to_color,\n",
    "                                     attributes=list(attribute_by_color.keys()), \n",
    "                                     cmaps=['Blues', *list([v for v in attribute_by_color.values() if v is not None])],\n",
    "                                     format_dict=format_dict))\n",
    "\n",
    "    # Latex code\n",
    "    if print_latex:\n",
    "        latex = exp_grouped[columns_to_show].to_latex(index=False, formatters=format_dict, escape=False).replace(\"\\\\textasciitilde\", \"$\\\\approx$\").replace(\" ± \", \" ±\")\n",
    "        latex = re.sub(r'&\\s*', '& ', latex)\n",
    "\n",
    "        print(\"\\n\",latex)\n",
    "    \n",
    "    return exp_grouped\n",
    "\n",
    "\n",
    "def get_table_extractor_type_filters(df):\n",
    "    filters = (df['date'] >= '2020-09-15')\n",
    "\n",
    "    # -- Input parameters\n",
    "    filters &= (df['resized_width'].isnull())\n",
    "    filters &= (~df['normalisation'].str.contains(\"imagenet_stats\", na=False))\n",
    "\n",
    "    # -- Text Processing\n",
    "    filters &= (df['rnn_state_size'] == 4096)              # G\n",
    "\n",
    "    # -- Coordconv\n",
    "    filters &= (df['extractor_spatial_location'] == 'None')\n",
    "    filters &= (df['stem_spatial_location'] == 'Both')\n",
    "    filters &= (df['resblock_spatial_location'] == 'Both')\n",
    "    filters &= (df['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "    # -- Resblocks\n",
    "    filters &= (df['nb_resblock'] == 4)                    # J\n",
    "    filters &= (df['resblocks_out_chan'] == 128)           # M\n",
    "\n",
    "    # -- Classifier\n",
    "    filters &= (df['classifier_conv_out'] == 512)          # C\n",
    "    filters &= (df['classifier_projection_out'] == 1024)    # H\n",
    "\n",
    "    # Variable Parameters (Input_type & Extractor)\n",
    "    filters &= (~df['RGB_colormap'].str.contains('Blues', na=False))\n",
    "\n",
    "    input_1d_filter = (df['input_type'].str.contains('1D'))\n",
    "    input_1d_filter &= (df['n_fft'] == 512)\n",
    "    input_1d_filter &= (df['keep_freq_point'] == 256) \n",
    "    input_1d_filter &= (df['hop_length'] == 2048)\n",
    "\n",
    "    filters &= ((df['input_type'].str.contains('RGB') & (df['extractor_type'].str.contains('Resnet'))) | input_1d_filter )\n",
    "\n",
    "    #filters &= (df['extractor_type'].str.contains('Resnet|Parallel') | (df['extractor_type'].str.startswith('Interleaved')))\n",
    "    #filters &= (df['extractor_type'].str.contains('Baseline') | (df['extractor_type'].str.contains('Resnet')))\n",
    "    \n",
    "    #filters &= (experiments['extractor_type'].str.contains('Parallel|Interleaved|Resnet|Baseline'))\n",
    "    filters &= (experiments['extractor_type'].str.contains('Parallel|Interleaved|Resnet'))\n",
    "\n",
    "    # -- Other\n",
    "    filters &= (df['note'].str.contains('table_1|table_2_final_final'))\n",
    "    #filters &= (df['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "    \n",
    "    filters |= (df['note'].str.contains('fix_size'))\n",
    "    \n",
    "    filters |= (df['config'].str.contains('table_1_conv_2d_extractor_32_smaller_filters'))\n",
    "    \n",
    "    return filters\n",
    "\n",
    "\n",
    "def get_table_coordconv_per_q_type_filters(df):\n",
    "    filters = (df['date'] >= '2020-11-20')\n",
    "    #filters = (df['date'] >= '2020-09-20')\n",
    "\n",
    "    # -- Input parameters\n",
    "    filters &= (df['input_type'].str.contains('1D'))\n",
    "    filters &= (df['n_fft'] == 512)\n",
    "    filters &= (df['keep_freq_point'] == 256)\n",
    "    filters &= (df['hop_length'] == 2048)\n",
    "    filters &= (df['resized_width'].isnull())\n",
    "\n",
    "    # -- Text Processing\n",
    "    filters &= (df['rnn_state_size'] == 1024)              # G\n",
    "\n",
    "    # -- Extractor\n",
    "    filters &= (df['extractor_nb_block'] == 3)             # K\n",
    "    #filters &= (df['extractor_filters'] == [8, 16, 32])   # N\n",
    "    filters &= (df['extractor_projection_size'] == 64)     # P\n",
    "\n",
    "    # -- Resblocks\n",
    "    filters &= (df['nb_resblock'] == 3)                   # J       <---- FIXME: Make sure this is the good values\n",
    "    filters &= (df['resblocks_out_chan'] == 64)           # M       <---- FIXME: Make sure this is the good values\n",
    "\n",
    "    # -- Classifier\n",
    "    filters &= (df['classifier_conv_out'] == 128)          # C      <---- FIXME: Make sure this is the good values\n",
    "    filters &= (df['classifier_projection_out'] == 512)    # H      <---- FIXME: Make sure this is the good values\n",
    "\n",
    "    # Variable Parameters (CoordConv)\n",
    "    filters &= df['extractor_spatial_location'].str.contains('None')\n",
    "    specific_configs = ((df['stem_spatial_location'].str.contains('Both')) & (df['resblock_spatial_location'].str.contains('Both')) & (df['classifier_spatial_location'].str.contains('Both')))\n",
    "    specific_configs |= ((df['stem_spatial_location'].str.contains('None')) & (df['resblock_spatial_location'].str.contains('Time')) & (df['classifier_spatial_location'].str.contains('None')))\n",
    "    specific_configs |= ((df['stem_spatial_location'].str.contains('Freq')) & (df['resblock_spatial_location'].str.contains('None')) & (df['classifier_spatial_location'].str.contains('None')))\n",
    "    specific_configs |= ((df['stem_spatial_location'].str.contains('None')) & (df['resblock_spatial_location'].str.contains('None')) & (df['classifier_spatial_location'].str.contains('None')))\n",
    "\n",
    "    filters &= specific_configs\n",
    "\n",
    "    # -- Other\n",
    "    filters &= (df['note'].str.contains('table_7|table_5_final'))\n",
    "    \n",
    "    return filters\n",
    "\n",
    "\n",
    "def get_table_coordconv_placement_filters(df):\n",
    "    filters = (df['date'] >= '2020-11-20')\n",
    "    #filters = (df['date'] >= '2020-09-20')\n",
    "\n",
    "    # -- Input parameters\n",
    "    filters &= (df['input_type'].str.contains('1D'))\n",
    "    filters &= (df['n_fft'] == 512)\n",
    "    filters &= (df['keep_freq_point'] == 256)\n",
    "    filters &= (df['hop_length'] == 2048)\n",
    "    filters &= (df['resized_width'].isnull())\n",
    "\n",
    "    # -- Text Processing\n",
    "    filters &= (df['rnn_state_size'] == 1024)              # G\n",
    "\n",
    "    # -- Extractor\n",
    "    filters &= (df['extractor_nb_block'] == 3)             # K\n",
    "    #filters &= (df['extractor_filters'] == [8, 16, 32])   # N\n",
    "    filters &= (df['extractor_projection_size'] == 64)     # P\n",
    "\n",
    "    # -- Resblocks\n",
    "    filters &= (df['nb_resblock'] == 3)                   # J       <---- FIXME: Make sure this is the good values\n",
    "    filters &= (df['resblocks_out_chan'] == 64)           # M       <---- FIXME: Make sure this is the good values\n",
    "\n",
    "    # -- Classifier\n",
    "    filters &= (df['classifier_conv_out'] == 128)          # C      <---- FIXME: Make sure this is the good values\n",
    "    filters &= (df['classifier_projection_out'] == 512)    # H      <---- FIXME: Make sure this is the good values\n",
    "\n",
    "    # Variable Parameters (CoordConv)\n",
    "    filters &= (df['extractor_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "    filters &= (df['stem_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "    filters &= (df['resblock_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "    filters &= (df['classifier_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "\n",
    "    # -- Other\n",
    "    #filters &= (df['note'].str.contains('table_7|table_5_final'))\n",
    "    #filters &= (df['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "    \n",
    "    return filters\n",
    "\n",
    "\n",
    "def get_table_coordconv_bigger_placement_filters(df):\n",
    "    filters = (df['date'] >= '2020-11-20')\n",
    "    #filters = (df['date'] >= '2020-09-20')\n",
    "\n",
    "    # -- Input parameters\n",
    "    filters &= (df['input_type'].str.contains('1D'))\n",
    "    filters &= (df['n_fft'] == 512)\n",
    "    filters &= (df['keep_freq_point'] == 256)\n",
    "    filters &= (df['hop_length'] == 2048)\n",
    "    filters &= (df['resized_width'].isnull())\n",
    "\n",
    "    # -- Text Processing\n",
    "    filters &= (df['rnn_state_size'] == 1024)              # G\n",
    "\n",
    "    # -- Extractor\n",
    "    filters &= (df['extractor_nb_block'] == 3)             # K\n",
    "    #filters &= (df['extractor_filters'] == [8, 16, 32])   # N\n",
    "    filters &= (df['extractor_projection_size'] == 64)     # P\n",
    "\n",
    "    # -- Resblocks\n",
    "    filters &= (df['nb_resblock'] == 3)                   # J       <---- FIXME: Make sure this is the good values\n",
    "    filters &= (df['resblocks_out_chan'] == 64)           # M       <---- FIXME: Make sure this is the good values\n",
    "\n",
    "    # -- Classifier\n",
    "    filters &= (df['classifier_conv_out'] == 128)          # C      <---- FIXME: Make sure this is the good values\n",
    "    filters &= (df['classifier_projection_out'] == 512)    # H      <---- FIXME: Make sure this is the good values\n",
    "\n",
    "    # Variable Parameters (CoordConv)\n",
    "    filters &= (df['extractor_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "    filters &= (df['stem_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "    filters &= (df['resblock_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "    filters &= (df['classifier_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "\n",
    "    # -- Other\n",
    "    #filters &= (df['note'].str.contains('table_7|table_5_final'))\n",
    "    filters &= (df['note'].str.contains('table_7_bigger'))\n",
    "    #filters &= (df['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "    \n",
    "    return filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.notebook.experiment_explorer import get_full_sync_experiment_from_drive_script\n",
    "\n",
    "get_full_sync_experiment_from_drive_script(exp, root_output_path, dryrun=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "    # RGB vs 1D\n",
    "    # Resnet    \n",
    "    # Mel Vs Spectrograms\n",
    "\n",
    "# Our model\n",
    "    # Baseline (4Resblock_128filters) + Parallel extractor\n",
    "    # Baseline (4Resblock_128filters) + Interleaved Extractor\n",
    "    # Our best configuration for parallel extractor\n",
    "    # Our best configuration for Interleaved extractor\n",
    "    \n",
    "# Parameter reduction\n",
    "    # Best extractor (Either parallel or interleaved)\n",
    "        # GRU\n",
    "        # Classifier\n",
    "        # Resblocks\n",
    "\n",
    "# Dataset Sizes\n",
    "\n",
    "# One modality\n",
    "\n",
    "# Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Our model\n",
    "    # Baseline (4Resblock_128filters) + Parallel extractor\n",
    "    # Baseline (4Resblock_128filters) + Interleaved Extractor\n",
    "    # Our best configuration for parallel extractor\n",
    "    # Our best configuration for Interleaved extractor\n",
    "    \n",
    "columns = ['extractor_filters', 'extractor_projection_size', 'test_acc', 'max_freq', 'n_fft', 'keep_freq_point', 'extractor_type', 'nb_trainable_param_round', 'note', 'folder']\n",
    "\n",
    "# From recent experiments\n",
    "filters = (experiments['date'] >= '2020-09-01')\n",
    "\n",
    "# Parallel or Interleaved extractor\n",
    "filters &= (experiments['extractor_type'].isin(['freq_time_interlaced', 'freq_time_separated']))\n",
    "\n",
    "# Baseline Resblocks config\n",
    "filters &= (experiments['nb_resblock'] == 4) & (experiments['resblocks_out_chan'] == 128)\n",
    "\n",
    "filters &= (experiments['n_mels'].isnull())\n",
    "\n",
    "\n",
    "exp = experiments[filters].sort_values('test_acc', ascending=False)\n",
    "\n",
    "# NOTE : Hardcoded... This is dependant on the order of the DF..\n",
    "names_by_index = {\n",
    "    500: '1D-ConvLearned',\n",
    "    391: 'RGB-Resnet-Imagenet-Stats',\n",
    "    248: 'RGB-ConvLearned',\n",
    "    130: 'RGB-Resnet-ClearStats',\n",
    "    392: 'RGB-Resnet-Imagenet-Renorm'\n",
    "}\n",
    "\n",
    "#for index, name in names_by_index.items():\n",
    "#    exp.loc[index, 'name'] = name\n",
    "\n",
    "exp['name'] = exp.apply(lambda x: '4ResBl-128F', axis=1)\n",
    "columns = ['name'] + columns\n",
    "\n",
    "color_by_multi_attribute(exp[columns], main_attribute=\"extractor_type\", attributes=['n_fft'], format_dict=latex_format_dict)\n",
    "\n",
    "#exp[columns].style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameter reduction\n",
    "    # Best extractor (Either parallel or interleaved)\n",
    "        # GRU\n",
    "    \n",
    "columns = ['rnn_state_size', 'extractor_filters', 'extractor_projection_size', 'test_acc', 'max_freq', 'n_fft', 'keep_freq_point', 'extractor_type', 'nb_trainable_param_round']#, 'note', 'folder']\n",
    "\n",
    "# From recent experiments\n",
    "filters = (experiments['date'] >= '2020-09-01')\n",
    "\n",
    "# Parallel or Interleaved extractor\n",
    "filters &= (experiments['extractor_type'].isin(['freq_time_interlaced', 'freq_time_separated']))\n",
    "\n",
    "# Baseline Resblocks config\n",
    "filters &= (experiments['nb_resblock'] == 3) & (experiments['resblocks_out_chan'] == 64)\n",
    "\n",
    "filters &= (experiments['n_mels'].isnull())\n",
    "\n",
    "\n",
    "exp = experiments[filters].sort_values('test_acc', ascending=False)\n",
    "\n",
    "# NOTE : Hardcoded... This is dependant on the order of the DF..\n",
    "names_by_index = {\n",
    "    500: '1D-ConvLearned',\n",
    "    391: 'RGB-Resnet-Imagenet-Stats',\n",
    "    248: 'RGB-ConvLearned',\n",
    "    130: 'RGB-Resnet-ClearStats',\n",
    "    392: 'RGB-Resnet-Imagenet-Renorm'\n",
    "}\n",
    "\n",
    "#for index, name in names_by_index.items():\n",
    "#    exp.loc[index, 'name'] = name\n",
    "\n",
    "exp['name'] = exp.apply(lambda x: '3ResBl-64F', axis=1)\n",
    "columns = ['name'] + columns\n",
    "\n",
    "color_by_multi_attribute(exp[columns], main_attribute=\"extractor_type\", attributes=['n_fft'], format_dict=latex_format_dict)\n",
    "\n",
    "#exp[columns].style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameter reduction\n",
    "    # Best extractor (Either parallel or interleaved)\n",
    "        # Classifier\n",
    "    \n",
    "columns = ['classifier_type', 'classifier_conv_out', 'classifier_projection_out', 'classifier_global_pool', 'extractor_filters', 'extractor_projection_size', 'test_acc', 'max_freq', 'n_fft', 'keep_freq_point', 'extractor_type', 'nb_trainable_param_round', 'note', 'folder']\n",
    "\n",
    "# From recent experiments\n",
    "filters = (experiments['date'] >= '2020-09-01')\n",
    "\n",
    "# Parallel or Interleaved extractor\n",
    "filters &= (experiments['extractor_type'].isin(['freq_time_interlaced', 'freq_time_separated']))\n",
    "\n",
    "# Baseline Resblocks config\n",
    "filters &= (experiments['nb_resblock'] == 3) & (experiments['resblocks_out_chan'] == 64)\n",
    "\n",
    "filters &= (experiments['n_mels'].isnull())\n",
    "\n",
    "\n",
    "exp = experiments[filters].sort_values('test_acc', ascending=False)\n",
    "\n",
    "# NOTE : Hardcoded... This is dependant on the order of the DF..\n",
    "names_by_index = {\n",
    "    500: '1D-ConvLearned',\n",
    "    391: 'RGB-Resnet-Imagenet-Stats',\n",
    "    248: 'RGB-ConvLearned',\n",
    "    130: 'RGB-Resnet-ClearStats',\n",
    "    392: 'RGB-Resnet-Imagenet-Renorm'\n",
    "}\n",
    "\n",
    "#for index, name in names_by_index.items():\n",
    "#    exp.loc[index, 'name'] = name\n",
    "\n",
    "exp['name'] = exp.apply(lambda x: '3ResBl-64F', axis=1)\n",
    "columns = ['name'] + columns\n",
    "\n",
    "color_by_multi_attribute(exp[columns], main_attribute=\"extractor_type\", attributes=['n_fft'], format_dict=latex_format_dict)\n",
    "\n",
    "#exp[columns].style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameter reduction\n",
    "    # Best extractor (Either parallel or interleaved)\n",
    "        # Resblocks\n",
    "    \n",
    "columns = ['nb_resblock', 'resblocks_out_chan', 'extractor_filters', 'extractor_projection_size', 'test_acc', 'max_freq', 'n_fft', 'keep_freq_point', 'extractor_type', 'nb_trainable_param_round', 'note', 'folder']\n",
    "\n",
    "# From recent experiments\n",
    "filters = (experiments['date'] >= '2020-09-01')\n",
    "\n",
    "# Parallel or Interleaved extractor\n",
    "filters &= (experiments['extractor_type'].isin(['freq_time_interlaced', 'freq_time_separated']))\n",
    "\n",
    "filters &= (experiments['n_mels'].isnull())\n",
    "\n",
    "\n",
    "exp = experiments[filters].sort_values('test_acc', ascending=False)\n",
    "\n",
    "# NOTE : Hardcoded... This is dependant on the order of the DF..\n",
    "names_by_index = {\n",
    "    500: '1D-ConvLearned',\n",
    "    391: 'RGB-Resnet-Imagenet-Stats',\n",
    "    248: 'RGB-ConvLearned',\n",
    "    130: 'RGB-Resnet-ClearStats',\n",
    "    392: 'RGB-Resnet-Imagenet-Renorm'\n",
    "}\n",
    "\n",
    "#for index, name in names_by_index.items():\n",
    "#    exp.loc[index, 'name'] = name\n",
    "\n",
    "exp['name'] = exp.apply(lambda x: '3ResBl-64F', axis=1)\n",
    "columns = ['name'] + columns\n",
    "\n",
    "color_by_multi_attribute(exp[columns], main_attribute=\"extractor_type\", attributes=['n_fft'], format_dict=latex_format_dict)\n",
    "\n",
    "#exp[columns].style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Network reduction -- GRU units\n",
    "df_filter = ((experiments['note'] == 'final_dropout') & (experiments['config'].str.contains('reduction')) & (~experiments['config'].str.contains('proj')) & (~experiments['config'].str.contains('conv')) & (experiments['classifier_type'] == 'fcn'))\n",
    "columns = ['nb_trainable_param', 'rnn_state_size', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "GRU_table = experiments[df_filter][columns].sort_values('nb_trainable_param', ascending=False).reset_index(drop=True)\n",
    "\n",
    "text = ['hola', 'quetal', 'muybien', 'tu', 'fff']\n",
    "GRU_table['text'] = GRU_table.apply(lambda s: text[s.name], axis=1)\n",
    "\n",
    "# Reorder columns (Set text first)\n",
    "GRU_table = GRU_table[['text'] + GRU_table.columns.tolist()[:-1]]\n",
    "\n",
    "#print(GRU_table.to_latex(index=False, formatters=latex_format_dict))\n",
    "GRU_table.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Network reduction -- Classifier\n",
    "df_filter =  (experiments['note'] == 'final') & (experiments['config'].str.contains('reduction'))\n",
    "df_filter &= (~experiments['config'].str.contains('extractor')) & (~experiments['config'].str.contains('proj'))\n",
    "df_filter &= (experiments['rnn_state_size'].isin([4096, 1024, 256]))\n",
    "\n",
    "columns = ['nb_trainable_param', 'rnn_state_size', 'classifier_type', 'classifier_conv_out', 'classifier_projection_out', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_trained']#, 'train_time']\n",
    "classifier = experiments[df_filter].sort_values('nb_trainable_param', ascending=False)[columns]\n",
    "\n",
    "#print(classifier.to_latex(index=False, formatters=latex_format_dict))\n",
    "classifier.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Network reduction -- Reduction Filters/Nb Resblocks\n",
    "df_filter =  (experiments['note'] == 'final') & (experiments['config'].str.contains('reduction'))\n",
    "df_filter &= (experiments['config'].str.contains('extractor')) & (~experiments['config'].str.contains('proj'))\n",
    "df_filter &= (experiments['rnn_state_size'].isin([4096, 1024, 256]))\n",
    "\n",
    "only_rnn_reduction_filter = (experiments['note'] == 'final') & (experiments['config'].isin(['reduction_original_rnn_1024_fcn_no_conv_hidden_256', \"reduction_original_rnn_1024_fcn_conv_256_hidden_512\"]))\n",
    "\n",
    "df_filter |= only_rnn_reduction_filter\n",
    "\n",
    "columns = ['nb_trainable_param', 'extractor_out_chan', 'stem_out_chan', 'nb_resblock', 'classifier_conv_out', 'classifier_projection_out', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "\n",
    "reduction_experiments = experiments[df_filter].sort_values('nb_trainable_param', ascending=False)[columns]\n",
    "\n",
    "#print(reduction_experiments.to_latex(index=False, formatters=latex_format_dict))\n",
    "reduction_experiments.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Extractor -- Parallel Extractor\n",
    "df_filter = (experiments['note'] == 'extractor') & (experiments['extractor_type'] == 'freq_time_separated')\n",
    "\n",
    "columns = ['extractor_filters', 'extractor_projection_size', 'extractor_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'nb_trainable_param']#, 'train_time']\n",
    "\n",
    "parallel_extractor = experiments[df_filter]\n",
    "\n",
    "# Average Results grouped over ['config', 'nb_scene', 'nb_q_per_scene']\n",
    "parallel_extractor = groupby_mean(parallel_extractor, \n",
    "                                     groupby_columns=['config', 'nb_scene', 'nb_q_per_scene'],\n",
    "                                     mean_columns=['train_acc', 'best_val_acc', 'test_acc'],\n",
    "                                    selected_columns=columns,\n",
    "                                    add_count_col=False)\n",
    "\n",
    "#parallel_extractor = convert_cols_to_int(parallel_extractor, ['nb_epoch_runned'])\n",
    "\n",
    "parallel_extractor = parallel_extractor.sort_values('nb_trainable_param', ascending=False)#[columns]\n",
    "\n",
    "#print(parallel_extractor.to_latex(index=False, formatters=latex_format_dict))\n",
    "parallel_extractor.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Extractor -- Interlaced Extractor -- Time First\n",
    "df_filter = (experiments['note'] == 'extractor') & (experiments['extractor_type'] == 'freq_time_interlaced')\n",
    "df_filter &= (experiments['config'].str.contains('timefirst'))\n",
    "\n",
    "columns = ['nb_trainable_param', 'extractor_nb_block', 'extractor_filters', 'extractor_projection_size', 'extractor_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "\n",
    "interleaved_extractor_timefirst = experiments[df_filter]\n",
    "\n",
    "# Average Results grouped over ['config', 'nb_scene', 'nb_q_per_scene']\n",
    "interleaved_extractor_timefirst = groupby_mean(interleaved_extractor_timefirst, \n",
    "                                     groupby_columns=['config', 'nb_scene', 'nb_q_per_scene'],\n",
    "                                     mean_columns=['train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned'],\n",
    "                                    selected_columns=columns,\n",
    "                                    add_count_col=False)\n",
    "\n",
    "interleaved_extractor_timefirst = convert_cols_to_int(interleaved_extractor_timefirst, ['nb_epoch_runned'])\n",
    "interleaved_extractor_timefirst = interleaved_extractor_timefirst.sort_values('test_acc', ascending=False)#[columns]\n",
    "\n",
    "#print(interleaved_extractor_timefirst.to_latex(index=False, formatters=latex_format_dict))\n",
    "interleaved_extractor_timefirst.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Feature Extractor -- Interlaced Extractor -- Freq First\n",
    "df_filter = (experiments['note'] == 'extractor') & (experiments['extractor_type'] == 'freq_time_interlaced')\n",
    "df_filter &= (~experiments['config'].str.contains('timefirst'))\n",
    "\n",
    "columns = ['nb_trainable_param', 'extractor_nb_block', 'extractor_filters', 'extractor_projection_size', 'extractor_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "\n",
    "interleaved_extractor_freqfirst = experiments[df_filter]\n",
    "\n",
    "# Average Results grouped over ['config', 'nb_scene', 'nb_q_per_scene']\n",
    "interleaved_extractor_freqfirst = groupby_mean(interleaved_extractor_freqfirst, \n",
    "                                     groupby_columns=['config', 'nb_scene', 'nb_q_per_scene'],\n",
    "                                     mean_columns=['train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned'],\n",
    "                                    selected_columns=columns,\n",
    "                                    add_count_col=False)\n",
    "\n",
    "interleaved_extractor_freqfirst = convert_cols_to_int(interleaved_extractor_freqfirst, ['nb_epoch_runned'])\n",
    "interleaved_extractor_freqfirst = interleaved_extractor_freqfirst.sort_values('nb_trainable_param', ascending=False)#[columns]\n",
    "\n",
    "#print(interleaved_extractor_freqfirst.to_latex(index=False, formatters=latex_format_dict))\n",
    "interleaved_extractor_freqfirst.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Dataset size comparison -- Mixed -- 100k, 200k, 400k samples\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "fig_name = \"dataset_size_all_samples.pdf\"\n",
    "df_filter = (experiments['note'] == 'dataset_size')\n",
    "columns = ['nb_sample', 'nb_scene', 'nb_q_per_scene', 'test_acc']\n",
    "dataset_size = experiments[df_filter].sort_values('nb_q_per_scene')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "lines = []\n",
    "\n",
    "grouped_by_sample_400k = dataset_size[dataset_size['nb_sample'] == 400000]\n",
    "\n",
    "# Get colorlist\n",
    "group_unique_keys = grouped_by_sample_400k['nb_scene'].unique()\n",
    "colorlist = {key: colors.rgb2hex(matplotlib.cm.gist_rainbow_r(i)) for key, i in\n",
    "             zip(group_unique_keys, np.linspace(0, 0.9, len(group_unique_keys)))}\n",
    "\n",
    "# Plot 400k lines & markers\n",
    "lines += ax.plot(grouped_by_sample_400k['nb_q_per_scene'], grouped_by_sample_400k['test_acc'], linewidth=1, linestyle=':', zorder=1)\n",
    "grouped_scatter(grouped_by_sample_400k, 'nb_scene', 'nb_q_per_scene', 'test_acc', ax = ax, show_label=True, colorlist=colorlist, \n",
    "                label_modifier=lambda n: f\"{int(n/1000)}k scenes  \", additional_params={\"marker\": \",\", \"zorder\":2, \"edgecolor\":lines[0].get_markerfacecolor(), \"linewidth\":1})\n",
    "\n",
    "# Plot 200k lines & markers\n",
    "grouped_by_sample_200k = dataset_size[dataset_size['nb_sample'] == 200000]\n",
    "lines += ax.plot(grouped_by_sample_200k['nb_q_per_scene'], grouped_by_sample_200k['test_acc'], linewidth=1, linestyle=':', zorder=1)\n",
    "grouped_scatter(grouped_by_sample_200k, 'nb_scene', 'nb_q_per_scene', 'test_acc', ax = ax, show_label=False, colorlist=colorlist, additional_params={\"marker\": \",\", \"zorder\":2, \"edgecolor\":lines[1].get_markerfacecolor(), \"linewidth\":1})\n",
    "\n",
    "# Plot 100k lines & markers\n",
    "grouped_by_sample_100k = dataset_size[dataset_size['nb_sample'] == 100000]\n",
    "lines += ax.plot(grouped_by_sample_100k['nb_q_per_scene'], grouped_by_sample_100k['test_acc'], linewidth=1, linestyle=':', zorder=1)\n",
    "grouped_scatter(grouped_by_sample_100k, 'nb_scene', 'nb_q_per_scene', 'test_acc', ax = ax, show_label=False, colorlist=colorlist, additional_params={\"marker\": \",\", \"zorder\":2, \"edgecolor\":lines[2].get_markerfacecolor(), \"linewidth\":1})\n",
    "\n",
    "# Remove marker border from legend\n",
    "for legend_handle in ax.get_legend().legendHandles:\n",
    "    legend_handle.set_linewidths(0)\n",
    "\n",
    "# Add Second legend\n",
    "ax.add_artist(matplotlib.legend.Legend(ax, lines, ['400k samples', '200k samples', '100k samples'], loc='center right'))\n",
    "\n",
    "# Set axis infos\n",
    "ax.set_xscale('log')\n",
    "ax.set_xticks(dataset_size['nb_q_per_scene'].unique())\n",
    "ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "ax.set_xlim([0.9, 43])\n",
    "ax.set_xlabel('Number of question per scene')\n",
    "ax.set_ylabel('Accuracy')\n",
    "\n",
    "#fig.savefig(f\"stats/{fig_name}\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset size comparison -- Mixed -- 100k, 200k, 400k samples\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import seaborn as sns\n",
    "\n",
    "fig_name = \"dataset_size_all_samples_giampi.pdf\"\n",
    "df_filter = (experiments['note'] == 'dataset_size')\n",
    "columns = ['nb_sample', 'nb_scene', 'nb_q_per_scene', 'test_acc']\n",
    "dataset_size = experiments[df_filter].sort_values('nb_q_per_scene')\n",
    "#print(dataset_size)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.set_palette(\"colorblind\")\n",
    "g = sns.barplot(x='nb_scene', y='test_acc', hue='nb_sample', data=dataset_size)\n",
    "# the following is an ugly hack that only works if the accuracy values are all different!!\n",
    "for patch in ax.patches:\n",
    "    if np.isnan(patch.get_height()):\n",
    "        continue\n",
    "    idx = np.argmin(np.abs(dataset_size.test_acc-patch.get_height()))\n",
    "    #g.text(patch.get_x()+patch.get_width()/2, patch.get_height(), dataset_size.nb_q_per_scene[idx], color='black', ha='center')\n",
    "    g.text(patch.get_x()+patch.get_width()/2, 0.96, dataset_size.nb_q_per_scene[idx], color='black', ha='center')\n",
    "g.text(1.5, 1.01, '# questions per scene', color='black')\n",
    "plt.xlabel('# scenes')\n",
    "plt.ylabel('Accuracy')\n",
    "h, l = ax.get_legend_handles_labels()\n",
    "ax.legend(h, l, title='# examples', loc='lower left')\n",
    "\n",
    "#fig.savefig(f\"stats/{fig_name}\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_name = \"dataset_size_all_samples_giampi2.pdf\"\n",
    "df_filter = (experiments['note'] == 'dataset_size')\n",
    "columns = ['nb_sample', 'nb_scene', 'nb_q_per_scene', 'test_acc']\n",
    "dataset_size = experiments[df_filter].sort_values('nb_q_per_scene')\n",
    "#print(dataset_size)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.set_palette(\"colorblind\")\n",
    "g = sns.barplot(x='nb_sample', y='test_acc', hue='nb_scene', data=dataset_size)\n",
    "# the following is an ugly hack that only works if the accuracy values are all different!!\n",
    "for patch in ax.patches:\n",
    "    if np.isnan(patch.get_height()):\n",
    "        continue\n",
    "    idx = np.argmin(np.abs(dataset_size.test_acc-patch.get_height()))\n",
    "    #g.text(patch.get_x()+patch.get_width()/2, patch.get_height(), dataset_size.nb_q_per_scene[idx], color='black', ha='center')\n",
    "    g.text(patch.get_x()+patch.get_width()/2, 0.96, dataset_size.nb_q_per_scene[idx], color='black', ha='center')\n",
    "g.text(0.5, 1.01, '# questions per scene', color='black')\n",
    "plt.xlabel('# examples')\n",
    "plt.ylabel('Accuracy')\n",
    "h, l = ax.get_legend_handles_labels()\n",
    "ax.legend(h, l, title='# scenes', loc='lower right')\n",
    "\n",
    "#fig.savefig(f\"stats/{fig_name}\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig_name = \"dataset_size_all_samples_giampi3.pdf\"\n",
    "df_filter = (experiments['note'] == 'dataset_size')\n",
    "columns = ['nb_sample', 'nb_scene', 'nb_q_per_scene', 'test_acc']\n",
    "dataset_size = experiments[df_filter].sort_values('nb_q_per_scene')\n",
    "subset100k = dataset_size.nb_sample == 100000\n",
    "subset200k = dataset_size.nb_sample == 200000\n",
    "subset400k = dataset_size.nb_sample == 400000\n",
    "#print(dataset_size)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(6,4), sharey=True)\n",
    "#sns.set_palette(\"colorblind\")\n",
    "g = sns.barplot(x='nb_q_per_scene', y='test_acc', data=dataset_size[subset100k], color='dodgerblue', ax=ax[0])\n",
    "ax[0].set_xlabel('')\n",
    "ax[0].set_xticklabels(['100k x 1', '50k x 2', '20k x 5', '10k x 10'], rotation=90)\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].set_title('100k records')\n",
    "mean = dataset_size[subset100k]['test_acc'].mean()\n",
    "ax[0].axhline(y=mean, linestyle=\"--\", color='orange')\n",
    "\n",
    "g = sns.barplot(x='nb_q_per_scene', y='test_acc', data=dataset_size[subset200k], color='dodgerblue', ax=ax[1])\n",
    "ax[1].set_xlabel('(# scenes) x (# questions per scene)')\n",
    "ax[1].set_xticklabels(['200k x 1', '100k x 2', '50k x 4', '20k x 10', '10k x 20'], rotation=90)\n",
    "ax[1].set_ylabel('')\n",
    "ax[1].set_title('200k records')\n",
    "mean = dataset_size[subset200k]['test_acc'].mean()\n",
    "ax[1].axhline(y=mean, linestyle=\"--\", color='orange')\n",
    "\n",
    "g = sns.barplot(x='nb_q_per_scene', y='test_acc', data=dataset_size[subset400k], color='dodgerblue', ax=ax[2])\n",
    "ax[2].set_xlabel('')\n",
    "ax[2].set_xticklabels(['400k x 1', '200k x 2', '100k x 4', '50k x 8', '20k x 20', '10k x 40'], rotation=90)\n",
    "ax[2].set_ylabel('')\n",
    "ax[2].set_title('400k records')\n",
    "mean = dataset_size[subset400k]['test_acc'].mean()\n",
    "ax[2].axhline(y=mean, linestyle=\"--\", color='orange')\n",
    "\n",
    "plt.subplots_adjust(wspace=-0.5)\n",
    "plt.tight_layout()\n",
    "#h, l = ax.get_legend_handles_labels()\n",
    "#ax.legend(h, l, title='# scenes', loc='lower right')\n",
    "\n",
    "fig.savefig(f\"stats/{fig_name}\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([f for f in dir(ax[2]) if '_' not in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax[2].lines[3].get_ydata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset size 400k - Data\n",
    "\n",
    "columns = ['nb_trainable_param', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "\n",
    "#print(grouped_by_sample_400k[columns].to_latex(index=False, formatters=latex_format_dict))\n",
    "grouped_by_sample_400k[columns].style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset size 200k - Data\n",
    "\n",
    "columns = ['nb_trainable_param', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "\n",
    "#print(grouped_by_sample_200k[columns].to_latex(index=False, formatters=latex_format_dict))\n",
    "grouped_by_sample_200k[columns].style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset size 100k - Data\n",
    "\n",
    "columns = ['nb_trainable_param', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "\n",
    "#print(grouped_by_sample_100k[columns].to_latex(index=False, formatters=latex_format_dict))\n",
    "grouped_by_sample_100k[columns].style.format(latex_format_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "film-aqa-torch-1.3",
   "language": "python",
   "name": "film-aqa-torch-1.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
