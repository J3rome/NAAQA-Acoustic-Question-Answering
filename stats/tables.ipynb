{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic functions -- Run Once\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "# Move up one folder to reach the repo root\n",
    "%cd ..\n",
    "\n",
    "from utils.notebook.generic import full_width_notebook\n",
    "\n",
    "full_width_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Paths, Imports & Configs\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from utils.notebook.experiment_explorer import get_experiments, get_format_dicts\n",
    "\n",
    "from utils.notebook.pandas import color_by_multi_attribute\n",
    "from utils.notebook.pandas import sub_cols_with_cond_and_create_new_col, grouped_scatter, groupby_mean, convert_cols_to_int\n",
    "\n",
    "root_data_path = \"data\"\n",
    "root_output_path = \"output_synced/training\"\n",
    "\n",
    "# Retrieve all experimentsi infos\n",
    "experiments = get_experiments(root_output_path)\n",
    "\n",
    "# Pretty printing\n",
    "format_dict, latex_format_dict = get_format_dicts()\n",
    "\n",
    "latex_format_dict_no_agg = latex_format_dict.copy()\n",
    "del latex_format_dict_no_agg['train_acc']\n",
    "del latex_format_dict_no_agg['best_val_acc']\n",
    "del latex_format_dict_no_agg['test_acc']\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "sorted(experiments.columns.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Table 1\n",
    "# Baseline model\n",
    "    # RGB vs 1D\n",
    "    # Resnet vs Baseline\n",
    "#columns = ['max_freq', 'test_acc', 'n_fft', 'extractor_type', 'nb_trainable_param_round']#, 'folder']\n",
    "#columns = ['max_freq', 'test_acc', 'n_fft', 'extractor_type', 'nb_trainable_param_round', 'RGB_colormap', 'normalisation', 'resized_width', 'nb_epoch_trained', 'folder', 'folder_dated']\n",
    "columns = ['test_acc', 'input_type', 'RGB_colormap', 'extractor_type', 'normalisation', 'nb_trainable_param_round', 'nb_epoch_trained', 'note', 'folder_dated']\n",
    "columns = ['extractor_type', 'input_type', 'normalisation', 'train_acc', 'best_val_acc', 'test_acc', 'nb_trainable_param_round', 'nb_epoch_trained',]\n",
    "\n",
    "#filters = (experiments['date'] >= '2020-11-20')\n",
    "filters = (experiments['date'] >= '2020-09-15')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "filters &= (~experiments['normalisation'].str.contains(\"imagenet_stats\", na=False))\n",
    "\n",
    "# -- Text Processing\n",
    "filters &= (experiments['rnn_state_size'] == 4096)              # G\n",
    "\n",
    "# -- Coordconv\n",
    "filters &= (experiments['extractor_spatial_location'] == 'None')\n",
    "filters &= (experiments['stem_spatial_location'] == 'Both')\n",
    "filters &= (experiments['resblock_spatial_location'] == 'Both')\n",
    "filters &= (experiments['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "# -- Resblocks\n",
    "filters &= (experiments['nb_resblock'] == 4)                    # J\n",
    "filters &= (experiments['resblocks_out_chan'] == 128)           # M\n",
    "\n",
    "# -- Classifier\n",
    "filters &= (experiments['classifier_conv_out'] == 512)          # C\n",
    "filters &= (experiments['classifier_projection_out'] == 1024)    # H\n",
    "\n",
    "# Variable Parameters (Input_type & Extractor)\n",
    "filters &= (~experiments['RGB_colormap'].str.contains('Blues', na=False))\n",
    "\n",
    "input_1d_filter = (experiments['input_type'].str.contains('1D'))\n",
    "input_1d_filter &= (experiments['n_fft'] == 512)\n",
    "input_1d_filter &= (experiments['keep_freq_point'] == 256) \n",
    "input_1d_filter &= (experiments['hop_length'] == 2048)\n",
    "\n",
    "filters &= (experiments['input_type'].str.contains('RGB') | input_1d_filter )\n",
    "\n",
    "filters &= (experiments['extractor_type'].str.contains('Baseline') | (experiments['extractor_type'].str.contains('Resnet')))\n",
    "\n",
    "# -- Other\n",
    "filters &= (experiments['note'].str.contains('table_1_final_final'))\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "\n",
    "# Remove duplicate experiment\n",
    "exp = exp.drop_duplicates(['extractor_type', 'train_acc', 'test_acc', 'random_seed'])\n",
    "\n",
    "# Keep most recent experiment\n",
    "#exp = exp.sort_values('date', ascending=False)#.drop_duplicates(['folder', 'random_seed'],keep='first')\n",
    "#exp = exp.sort_values('test_acc', ascending=False)\n",
    "\n",
    "#exp = experiments[filters].sort_values('test_acc', ascending=False)\n",
    "\n",
    "#columns = ['extractor_type', 'input_type', 'train_acc', 'best_val_acc', 'test_acc', 'nb_trainable_param_million']#, 'nb_epoch_trained',]\n",
    "\n",
    "#exp_grouped = groupby_mean(exp, ['extractor_type', 'input_type'], ['train_acc', 'best_val_acc', 'test_acc'], columns, add_count_col=True, add_std_str=True)\n",
    "\n",
    "\n",
    "groupby_columns = ['extractor_type', 'input_type']\n",
    "acc_columns = ['train_acc', 'best_val_acc', 'test_acc']\n",
    "extra_columns = ['nb_trainable_param_million']\n",
    "\n",
    "acc_std_columns = [f\"{c}_std\" for c in acc_columns]\n",
    "columns_to_group = groupby_columns + acc_columns + extra_columns\n",
    "columns_to_show = groupby_columns + acc_std_columns + extra_columns\n",
    "\n",
    "exp_grouped = groupby_mean(exp, groupby_columns, acc_columns, columns_to_group, add_count_col=True, add_std_str=True)\n",
    "exp_grouped = exp_grouped.sort_values('test_acc', ascending=False)#[columns_to_show]\n",
    "\n",
    "display(exp[['random_seed'] + columns_to_group])\n",
    "\n",
    "display(color_by_multi_attribute(exp_grouped, main_attribute=\"extractor_type\", attributes=['test_acc_std'], format_dict=latex_format_dict_no_agg))\n",
    "latex = exp[columns].to_latex(index=False, formatters=latex_format_dict).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "\n",
    "print(\"\\n\",latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1 + Table 2\n",
    "# Baseline model + Acoustic Extractors\n",
    "    # RGB vs 1D\n",
    "    # Resnet vs Baseline\n",
    "#columns = ['max_freq', 'test_acc', 'n_fft', 'extractor_type', 'nb_trainable_param_round']#, 'folder']\n",
    "#columns = ['max_freq', 'test_acc', 'n_fft', 'extractor_type', 'nb_trainable_param_round', 'RGB_colormap', 'normalisation', 'resized_width', 'nb_epoch_trained', 'folder', 'folder_dated']\n",
    "columns = ['test_acc', 'input_type', 'RGB_colormap', 'extractor_type', 'normalisation', 'nb_trainable_param_round', 'nb_epoch_trained', 'note', 'folder_dated']\n",
    "columns = ['extractor_type', 'input_type', 'normalisation', 'train_acc', 'best_val_acc', 'test_acc', 'nb_trainable_param_round', 'nb_epoch_trained',]\n",
    "\n",
    "#filters = (experiments['date'] >= '2020-11-20')\n",
    "filters = (experiments['date'] >= '2020-09-15')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "filters &= (~experiments['normalisation'].str.contains(\"imagenet_stats\", na=False))\n",
    "\n",
    "# -- Text Processing\n",
    "filters &= (experiments['rnn_state_size'] == 4096)              # G\n",
    "\n",
    "# -- Coordconv\n",
    "filters &= (experiments['extractor_spatial_location'] == 'None')\n",
    "filters &= (experiments['stem_spatial_location'] == 'Both')\n",
    "filters &= (experiments['resblock_spatial_location'] == 'Both')\n",
    "filters &= (experiments['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "# -- Resblocks\n",
    "filters &= (experiments['nb_resblock'] == 4)                    # J\n",
    "filters &= (experiments['resblocks_out_chan'] == 128)           # M\n",
    "\n",
    "# -- Classifier\n",
    "filters &= (experiments['classifier_conv_out'] == 512)          # C\n",
    "filters &= (experiments['classifier_projection_out'] == 1024)    # H\n",
    "\n",
    "# Variable Parameters (Input_type & Extractor)\n",
    "filters &= (~experiments['RGB_colormap'].str.contains('Blues', na=False))\n",
    "\n",
    "input_1d_filter = (experiments['input_type'].str.contains('1D'))\n",
    "input_1d_filter &= (experiments['n_fft'] == 512)\n",
    "input_1d_filter &= (experiments['keep_freq_point'] == 256) \n",
    "input_1d_filter &= (experiments['hop_length'] == 2048)\n",
    "\n",
    "filters &= (experiments['input_type'].str.contains('RGB') | input_1d_filter )\n",
    "\n",
    "filters &= (experiments['extractor_type'].str.contains('Baseline|Resnet|Parallel') | (experiments['extractor_type'].str.startswith('Interleaved')))\n",
    "#filters &= (experiments['extractor_nb_block'] == 3)             # K\n",
    "#filters &= (experiments['extractor_filters'] == [8, 16, 32])   # N\n",
    "#filters &= (experiments['extractor_projection_size'] == 64)     # P      <---- FIXME : Might want to try with 32\n",
    "\n",
    "# -- Other\n",
    "filters &= (experiments['note'].str.contains('table_1_final_final|table_2_final_final'))\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "\n",
    "# Remove duplicate experiment\n",
    "exp = exp.drop_duplicates(['extractor_type', 'train_acc', 'test_acc', 'random_seed'])\n",
    "\n",
    "# Keep most recent experiment\n",
    "#exp = exp.sort_values('date', ascending=False)#.drop_duplicates(['folder', 'random_seed'],keep='first')\n",
    "exp = exp.sort_values('config', ascending=False)\n",
    "\n",
    "groupby_columns = ['extractor_type', 'input_type']\n",
    "acc_columns = ['train_acc', 'best_val_acc', 'test_acc']\n",
    "extra_columns = ['nb_trainable_param_million']\n",
    "\n",
    "acc_std_columns = [f\"{c}_std\" for c in acc_columns]\n",
    "columns_to_group = groupby_columns + acc_columns + extra_columns\n",
    "columns_to_show = groupby_columns + acc_std_columns + extra_columns\n",
    "\n",
    "exp_grouped = groupby_mean(exp, groupby_columns, acc_columns, columns_to_group, add_count_col=True, add_std_str=True)[columns_to_show]\n",
    "\n",
    "display(color_by_multi_attribute(exp_grouped, main_attribute=\"extractor_type\", attributes=['test_acc_std'], format_dict=latex_format_dict))\n",
    "latex = exp_grouped.to_latex(index=False, formatters=latex_format_dict).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "\n",
    "print(\"\\n\",latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Table 2\n",
    "# TODO : Merge with table 1 ?\n",
    "# Acoustic Extractor\n",
    "    # J=4, M=128\n",
    "    # Parallel vs Interleaved\n",
    "#columns = ['max_freq', 'test_acc', 'n_fft', 'extractor_type', 'nb_trainable_param_round']#, 'folder']\n",
    "#columns = ['max_freq', 'test_acc', 'n_fft', 'extractor_type', 'nb_trainable_param_round', 'RGB_colormap', 'normalisation', 'resized_width', 'nb_epoch_trained', 'folder', 'folder_dated']\n",
    "#columns = ['extractor_type', 'nb_resblock', 'resblocks_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained', 'folder_dated']\n",
    "\n",
    "filters = (experiments['date'] >= '2020-11-20')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['input_type'].str.contains('1D'))\n",
    "filters &= (experiments['n_fft'] == 512)\n",
    "filters &= (experiments['keep_freq_point'] == 256)\n",
    "filters &= (experiments['hop_length'] == 2048)\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "\n",
    "# -- Text Processing\n",
    "#filters &= (experiments['rnn_state_size'] == 4096)              # G\n",
    "\n",
    "# -- Coordconv\n",
    "filters &= (experiments['extractor_spatial_location'] == 'None')\n",
    "filters &= (experiments['stem_spatial_location'] == 'Both')\n",
    "filters &= (experiments['resblock_spatial_location'] == 'Both')\n",
    "filters &= (experiments['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "# -- Resblocks\n",
    "filters &= (experiments['nb_resblock'] == 4)                    # J\n",
    "filters &= (experiments['resblocks_out_chan'] == 128)           # M\n",
    "\n",
    "# -- Classifier\n",
    "#filters &= (experiments['classifier_conv_out'] == 512)           # C \n",
    "#filters &= (experiments['classifier_projection_out'] == 1024)    # H\n",
    "\n",
    "# Variable Parameters (Extractor)\n",
    "filters &= (experiments['extractor_nb_block'] == 3)             # K\n",
    "#filters &= (experiments['extractor_filters'] == [8, 16, 32])   # N\n",
    "filters &= (experiments['extractor_projection_size'] == 64)     # P      <---- FIXME : Might want to try with 32\n",
    "filters &= (experiments['extractor_type'].str.contains('Parallel') | (experiments['extractor_type'].str.startswith('Interleaved')))\n",
    "\n",
    "# -- Others\n",
    "filters &= (experiments['note'].str.contains('table_2_final_final'))\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -- Comparison\n",
    "filters |= (experiments['note'].str.contains('table_1_final_final') & experiments['extractor_type'].str.contains('Baseline') & (experiments['input_type'].str.contains('1D')))\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "# Remove duplicate experiment\n",
    "exp = exp.drop_duplicates(['extractor_type', 'train_acc', 'test_acc', 'random_seed'])\n",
    "\n",
    "\n",
    "from utils.notebook.pandas import groupby_mean\n",
    "\n",
    "# Sort\n",
    "exp = exp.sort_values('config', ascending=False)\n",
    "\n",
    "# Display\n",
    "columns = ['extractor_type', 'train_acc', 'best_val_acc', 'test_acc', 'nb_trainable_param_million']#, 'count']#, 'random_seed']#, 'nb_epoch_trained']\n",
    "\n",
    "exp_grouped = groupby_mean(exp, ['extractor_type'], ['train_acc', 'best_val_acc', 'test_acc'], columns, add_count_col=True)\n",
    "\n",
    "display(color_by_multi_attribute(exp_grouped, main_attribute=\"extractor_type\", attributes=['test_acc', 'count'], format_dict=latex_format_dict_no_agg))\n",
    "latex = exp_grouped.to_latex(index=False, formatters=latex_format_dict_no_agg).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "\n",
    "print(\"\\n\",latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 3 - GRU Reduction\n",
    "# MISSING : All, G={4096,2048, 1024, 512, 256}\n",
    "# Static Parameters :\n",
    "    # Extractor = Parallel\n",
    "    # J = 4\n",
    "    # M = 128\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "    # K = 3\n",
    "    # N = [8, 16, 32]\n",
    "    # P = 64\n",
    "columns = ['extractor_type', 'nb_resblock', 'resblocks_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained']\n",
    "columns = ['extractor_filters', 'classifier_conv_out', 'classifier_projection_out',  'keep_freq_point', 'hop_length', 'extractor_type', 'nb_resblock', 'resblocks_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained', 'folder_dated']\n",
    "\n",
    "filters = (experiments['date'] >= '2020-11-20')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['input_type'].str.contains('1D'))\n",
    "filters &= (experiments['n_fft'] == 512)\n",
    "filters &= (experiments['keep_freq_point'] == 256)\n",
    "filters &= (experiments['hop_length'] == 2048)\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "\n",
    "# -- Coordconv\n",
    "filters &= (experiments['extractor_spatial_location'] == 'None')\n",
    "filters &= (experiments['stem_spatial_location'] == 'Both')\n",
    "filters &= (experiments['resblock_spatial_location'] == 'Both')\n",
    "filters &= (experiments['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "# -- Extractor\n",
    "filters &= experiments['extractor_type'].str.contains('Parallel')\n",
    "filters &= (experiments['extractor_nb_block'] == 3)             # K\n",
    "#filters &= (experiments['extractor_filters'] == [8, 16, 32])   # N\n",
    "filters &= (experiments['extractor_projection_size'] == 64)     # P      <---- FIXME : Might want to try with 32\n",
    "\n",
    "# -- Resblocks\n",
    "filters &= (experiments['nb_resblock'] == 4)                    # J\n",
    "filters &= (experiments['resblocks_out_chan'] == 128)           # M\n",
    "\n",
    "# -- Classifier\n",
    "#filters &= (experiments['classifier_conv_out'] == 512)           # C \n",
    "#filters &= (experiments['classifier_projection_out'] == 1024)    # H\n",
    "\n",
    "# Variable Parameters (Text-Processing GRU units)\n",
    "filters &= (experiments['rnn_state_size'].isin([4096, 2048, 1024, 512, 256])) # G\n",
    "\n",
    "# -- Other\n",
    "filters &= (experiments['note'].str.contains('table_3|table_2_final_final'))\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "# Keep most recent experiment\n",
    "#exp = exp.sort_values('date', ascending=False).drop_duplicates('folder',keep='first')\n",
    "#exp = exp.drop_duplicates('classifier_type',keep='first')\n",
    "exp = exp.sort_values('config', ascending=False)\n",
    "\n",
    "columns = ['random_seed', 'config', 'note', 'rnn_state_size', 'train_acc', 'best_val_acc', 'test_acc', 'nb_trainable_param_million', 'train_time', 'date']#, 'nb_epoch_trained']\n",
    "display(color_by_multi_attribute(exp[columns], main_attribute=\"rnn_state_size\", attributes=['test_acc'], format_dict=latex_format_dict))\n",
    "latex = exp[columns].to_latex(index=False, formatters=latex_format_dict).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "\n",
    "print(\"\\n\",latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 4 - Classifier Topologies\n",
    "# Static Parameters :\n",
    "    # Extractor = Parallel\n",
    "    # J = 4\n",
    "    # M = 128\n",
    "    # K = 3\n",
    "    # N = [8, 16, 32]\n",
    "    # P = 64\n",
    "columns = ['extractor_type', 'nb_resblock', 'resblocks_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained']\n",
    "#columns = ['extractor_filters', 'classifier_conv_out', 'classifier_projection_out',  'keep_freq_point', 'hop_length', 'extractor_type', 'nb_resblock', 'resblocks_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained', 'folder_dated']\n",
    "\n",
    "\n",
    "\n",
    "filters = (experiments['date'] >= '2020-11-20')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['input_type'].str.contains('1D'))\n",
    "filters &= (experiments['n_fft'] == 512)\n",
    "filters &= (experiments['keep_freq_point'] == 256)\n",
    "filters &= (experiments['hop_length'] == 2048)\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "\n",
    "# -- Text Processing\n",
    "filters &= (experiments['rnn_state_size'] == 1024)              # G\n",
    "\n",
    "# -- Coordconv\n",
    "filters &= (experiments['extractor_spatial_location'] == 'None')\n",
    "filters &= (experiments['stem_spatial_location'] == 'Both')\n",
    "filters &= (experiments['resblock_spatial_location'] == 'Both')\n",
    "filters &= (experiments['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "# -- Extractor\n",
    "filters &= experiments['extractor_type'].str.contains('Parallel')\n",
    "filters &= (experiments['extractor_nb_block'] == 3)             # K\n",
    "#filters &= (experiments['extractor_filters'] == [8, 16, 32])   # N\n",
    "filters &= (experiments['extractor_projection_size'] == 64)     # P      <---- FIXME : Might want to try with 32\n",
    "\n",
    "# -- Resblocks\n",
    "filters &= (experiments['nb_resblock'] == 4)                    # J\n",
    "filters &= (experiments['resblocks_out_chan'] == 128)           # M\n",
    "\n",
    "# Variable Parameters (Classifier Topologies)\n",
    "filters &= (experiments['classifier_type'].str.contains('fcn|conv'))\n",
    "filters &= (experiments['classifier_conv_out'].isin([512, 256, 128, None]))          # C\n",
    "filters &= (experiments['classifier_projection_out'].isin([1024, 512, 256, None]))   # H\n",
    "\n",
    "# Other\n",
    "filters &= (experiments['note'].str.contains('1_worker|table_3_table_3'))\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "# Drop duplicates (Error in experimentation)\n",
    "exp = exp.drop_duplicates(['classifier_type', 'classifier_conv_out', 'classifier_projection_out'],keep='first')\n",
    "\n",
    "# Keep most recent experiment\n",
    "#exp = exp.sort_values('date', ascending=False).drop_duplicates('folder',keep='first')\n",
    "exp = exp.sort_values('config', ascending=False)\n",
    "\n",
    "columns = ['random_seed','config', 'note', 'classifier_type', 'classifier_conv_out', 'classifier_projection_out', 'train_acc', 'best_val_acc', 'test_acc', 'nb_trainable_param_million', 'train_time']#, 'nb_epoch_trained']\n",
    "display(color_by_multi_attribute(exp[columns], main_attribute=\"classifier_type\", attributes=['test_acc', 'classifier_conv_out', 'classifier_projection_out', 'config'], format_dict=latex_format_dict))\n",
    "latex = exp[columns].to_latex(index=False, formatters=latex_format_dict).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "\n",
    "print(\"\\n\",latex)\n",
    "exp['train_time'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Table 5 - Resblocks\n",
    "    # Extractor = Parallel\n",
    "    # K = 3\n",
    "    # N = [8, 16, 32]\n",
    "    # P = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "columns = ['extractor_type', 'nb_resblock', 'resblocks_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained']\n",
    "#columns = ['extractor_filters', 'classifier_conv_out', 'classifier_projection_out',  'keep_freq_point', 'hop_length', 'extractor_type', 'nb_resblock', 'resblocks_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained', 'folder_dated']\n",
    "\n",
    "\n",
    "filters = (experiments['date'] >= '2020-11-20')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['input_type'].str.contains('1D'))\n",
    "filters &= (experiments['n_fft'] == 512)\n",
    "filters &= (experiments['keep_freq_point'] == 256)\n",
    "filters &= (experiments['hop_length'] == 2048)\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "\n",
    "# -- Text Processing\n",
    "filters &= (experiments['rnn_state_size'] == 1024)              # G\n",
    "\n",
    "# -- Coordconv\n",
    "filters &= (experiments['extractor_spatial_location'] == 'None')\n",
    "filters &= (experiments['stem_spatial_location'] == 'Both')\n",
    "filters &= (experiments['resblock_spatial_location'] == 'Both')\n",
    "filters &= (experiments['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "# -- Extractor\n",
    "filters &= experiments['extractor_type'].str.contains('Parallel')\n",
    "filters &= (experiments['extractor_nb_block'] == 3)             # K\n",
    "#filters &= (experiments['extractor_filters'] == [8, 16, 32])   # N\n",
    "filters &= (experiments['extractor_projection_size'] == 64)     # P      <---- FIXME : Might want to try with 32\n",
    "\n",
    "# -- Classifier\n",
    "filters &= (experiments['classifier_conv_out'] == 128)          # C      <---- FIXME: Make sure this is the good values\n",
    "filters &= (experiments['classifier_projection_out'] == 512)    # H      <---- FIXME: Make sure this is the good values\n",
    "\n",
    "# Variable Parameters (Resblocks)\n",
    "filters &= (experiments['nb_resblock'] <= 4)                    # J\n",
    "filters &= (experiments['resblocks_out_chan'].isin([128, 64, 32]))           # M\n",
    "\n",
    "# -- Other\n",
    "filters &= (experiments['note'].str.contains('table_5_final|table_4.*1_worker'))    # Table 4 result for comparison\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -- Comparison\n",
    "#filters |= ( (experiments['nb_resblock'] == 4) & (experiments['resblocks_out_chan'] == 128) & (experiments['note'].str.contains('table_4.*1_worker')) & experiments['extractor_type'].str.contains('Parallel') & (experiments['classifier_conv_out'] == 128) & (experiments['classifier_projection_out'] == 512) )\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "# Keep most recent experiment\n",
    "#exp = exp.sort_values('date', ascending=False).drop_duplicates('folder',keep='first')\n",
    "exp = exp.sort_values('config', ascending=False)\n",
    "#exp = exp.sort_values(['nb_resblock', 'resblocks_out_chan'], ascending=False)\n",
    "\n",
    "columns = ['note', 'config', 'random_seed', 'nb_resblock', 'resblocks_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'nb_trainable_param_million']#, 'random_seed']#, 'nb_epoch_trained']\n",
    "display(color_by_multi_attribute(exp[columns], main_attribute='resblocks_out_chan', attributes=['test_acc', 'nb_resblock', 'random_seed', 'config'], format_dict=latex_format_dict))\n",
    "latex = exp[columns].to_latex(index=False, formatters=latex_format_dict).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "\n",
    "print(\"\\n\",latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 6 - Extractor filter reduction\n",
    "    # G = 1024\n",
    "    # J = 3\n",
    "    # M = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "columns = ['note', 'extractor_type', 'nb_resblock', 'resblocks_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained']\n",
    "#columns = ['extractor_filters', 'classifier_conv_out', 'classifier_projection_out',  'keep_freq_point', 'hop_length', 'extractor_type', 'nb_resblock', 'resblocks_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained', 'folder_dated']\n",
    "\n",
    "\n",
    "filters = (experiments['date'] >= '2020-11-20')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['input_type'].str.contains('1D'))\n",
    "filters &= (experiments['n_fft'] == 512)\n",
    "filters &= (experiments['keep_freq_point'] == 256)\n",
    "filters &= (experiments['hop_length'] == 2048)\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "\n",
    "# -- Text Processing\n",
    "filters &= (experiments['rnn_state_size'] == 1024)              # G\n",
    "\n",
    "# -- Coordconv\n",
    "filters &= (experiments['extractor_spatial_location'] == 'None')\n",
    "filters &= (experiments['stem_spatial_location'] == 'Both')\n",
    "filters &= (experiments['resblock_spatial_location'] == 'Both')\n",
    "filters &= (experiments['classifier_spatial_location'] == 'Both')\n",
    "\n",
    "# -- Resblocks\n",
    "filters &= (experiments['nb_resblock'] == 3)                   # J       <---- FIXME: Make sure this is the good values\n",
    "filters &= (experiments['resblocks_out_chan'] == 64)           # M       <---- FIXME: Make sure this is the good values\n",
    "\n",
    "# -- Classifier\n",
    "filters &= (experiments['classifier_conv_out'] == 128)          # C      <---- FIXME: Make sure this is the good values\n",
    "filters &= (experiments['classifier_projection_out'] == 512)    # H      <---- FIXME: Make sure this is the good values\n",
    "\n",
    "# Variable Parameters (Extractor configuration)\n",
    "#filters &= experiments['extractor_type'].str.contains('Parallel|Interleaved')\n",
    "filters &= experiments['extractor_type'].str.contains('Parallel')\n",
    "filters &= (experiments['extractor_nb_block'] <= 4)             # K\n",
    "#filters &= (experiments['extractor_filters'] == [8, 16, 32])   # N\n",
    "filters &= (experiments['extractor_projection_size'].isin([128, 64, 32, None]))     # P\n",
    "\n",
    "# -- Other\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "# Handle duplicate\n",
    "#exp = exp.drop_duplicates(['extractor_nb_block', 'extractor_projection_size'], keep='first')\n",
    "\n",
    "# Keep most recent experiment\n",
    "#exp = exp.sort_values('date', ascending=False).drop_duplicates('folder',keep='first')\n",
    "exp = exp.sort_values('config', ascending=False)\n",
    "\n",
    "columns = ['random_seed', 'config', 'extractor_nb_block', 'extractor_filters', 'extractor_projection_size', 'resblocks_out_chan', 'train_acc', 'test_acc','nb_trainable_param_million']#, 'train_time']#, 'nb_epoch_trained']\n",
    "display(color_by_multi_attribute(exp[columns], main_attribute=\"extractor_nb_block\", attributes=['test_acc', 'random_seed', 'config'], format_dict=latex_format_dict))\n",
    "latex = exp[columns].to_latex(index=False, formatters=latex_format_dict).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "\n",
    "print(\"\\n\",latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Table 7 - CoordConv\n",
    "    # K = 3\n",
    "    # N_0 = 8\n",
    "    # P = 64\n",
    "    # G = 1024\n",
    "    # J = 3\n",
    "    # M = 64\n",
    "    # ClassifierTopology = FCN\n",
    "    # C = 512\n",
    "    # H = 1024\n",
    "columns = ['extractor_spatial_location', 'stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location' , 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained']\n",
    "#columns = ['extractor_filters', 'classifier_conv_out', 'classifier_projection_out',  'keep_freq_point', 'hop_length', 'extractor_type', 'nb_resblock', 'resblocks_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'best_val_loss', 'test_loss', 'nb_trainable_param_round', 'nb_epoch_trained', 'folder_dated']\n",
    "\n",
    "\n",
    "filters = (experiments['date'] >= '2020-11-20')\n",
    "#filters = (experiments['date'] >= '2020-09-20')\n",
    "\n",
    "# -- Input parameters\n",
    "filters &= (experiments['input_type'].str.contains('1D'))\n",
    "filters &= (experiments['n_fft'] == 512)\n",
    "filters &= (experiments['keep_freq_point'] == 256)\n",
    "filters &= (experiments['hop_length'] == 2048)\n",
    "filters &= (experiments['resized_width'].isnull())\n",
    "\n",
    "# -- Text Processing\n",
    "filters &= (experiments['rnn_state_size'] == 1024)              # G\n",
    "\n",
    "# -- Extractor\n",
    "filters &= (experiments['extractor_nb_block'] == 3)             # K\n",
    "#filters &= (experiments['extractor_filters'] == [8, 16, 32])   # N\n",
    "filters &= (experiments['extractor_projection_size'] == 64)     # P\n",
    "\n",
    "# -- Resblocks\n",
    "filters &= (experiments['nb_resblock'] == 3)                   # J       <---- FIXME: Make sure this is the good values\n",
    "filters &= (experiments['resblocks_out_chan'] == 64)           # M       <---- FIXME: Make sure this is the good values\n",
    "\n",
    "# -- Classifier\n",
    "filters &= (experiments['classifier_conv_out'] == 128)          # C      <---- FIXME: Make sure this is the good values\n",
    "filters &= (experiments['classifier_projection_out'] == 512)    # H      <---- FIXME: Make sure this is the good values\n",
    "\n",
    "# Variable Parameters (CoordConv)\n",
    "filters &= (experiments['extractor_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "filters &= (experiments['stem_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "filters &= (experiments['resblock_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "filters &= (experiments['classifier_spatial_location'].str.contains('None|Time|Freq|Both'))\n",
    "\n",
    "# -- Other\n",
    "filters &= (experiments['note'].str.contains('table_7|table_5_final'))\n",
    "#filters &= (experiments['random_seed'] == 876944)   # FIXME : Add more seeds and do the mean\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "exp = experiments[filters]\n",
    "\n",
    "# Keep most recent experiment\n",
    "#exp = exp.sort_values('date', ascending=False).drop_duplicates(['nb_resblock', 'resblocks_out_chan'],keep='first')\n",
    "#exp = exp.sort_values('test_acc', ascending=False).drop_duplicates(['note', 'extractor_spatial_location', 'stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location'],keep='first')\n",
    "exp = exp.sort_values('config', ascending=False)\n",
    "\n",
    "# Display\n",
    "groupby_columns = ['extractor_spatial_location', 'stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location']\n",
    "acc_columns = ['train_acc', 'best_val_acc', 'test_acc']\n",
    "extra_columns = ['nb_trainable_param_million']\n",
    "\n",
    "acc_std_columns = [f\"{c}_std\" for c in acc_columns]\n",
    "columns = groupby_columns + acc_columns + extra_columns\n",
    "columns_to_show = groupby_columns + acc_std_columns + extra_columns\n",
    "\n",
    "exp_grouped = groupby_mean(exp, groupby_columns, acc_columns, columns, add_count_col=True, add_std_str=True)\n",
    "train_std_mean, val_std_mean, test_std_mean = exp_grouped['train_acc_std'].mean(), exp_grouped['best_val_acc_std'].mean(), exp_grouped['test_acc_std'].mean()\n",
    "accuracy_std_mean = np.mean([train_std_mean, val_std_mean, test_std_mean])\n",
    "\n",
    "print(f\"STD Means -- Global means : {accuracy_std_mean} Train : ± {train_std_mean} - Val : ± {val_std_mean} - Test : ± {test_std_mean}\")\n",
    "exp_grouped = exp_grouped.sort_values('test_acc', ascending=False)#[columns]\n",
    "\n",
    "#display(exp[columns])\n",
    "\n",
    "display(color_by_multi_attribute(exp_grouped, main_attribute=None, \n",
    "                                 attributes=['extractor_spatial_location', 'stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location', 'test_acc'],\n",
    "                                 #attributes=['stem_spatial_location', 'resblock_spatial_location', 'classifier_spatial_location', 'test_acc'],\n",
    "                                 cmaps=['Blues', 'YlOrRd', 'YlOrRd', 'YlOrRd', 'YlOrRd'], \n",
    "                                 format_dict=latex_format_dict))\n",
    "\n",
    "latex = exp_grouped.to_latex(index=False, formatters=latex_format_dict).replace(\"\\\\textasciitilde\", \"$\\\\approx$\")\n",
    "\n",
    "print(\"\\n\",latex)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.notebook.experiment_explorer import get_full_sync_experiment_from_drive_script\n",
    "\n",
    "get_full_sync_experiment_from_drive_script(exp, root_output_path, dryrun=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "    # RGB vs 1D\n",
    "    # Resnet    \n",
    "    # Mel Vs Spectrograms\n",
    "\n",
    "# Our model\n",
    "    # Baseline (4Resblock_128filters) + Parallel extractor\n",
    "    # Baseline (4Resblock_128filters) + Interleaved Extractor\n",
    "    # Our best configuration for parallel extractor\n",
    "    # Our best configuration for Interleaved extractor\n",
    "    \n",
    "# Parameter reduction\n",
    "    # Best extractor (Either parallel or interleaved)\n",
    "        # GRU\n",
    "        # Classifier\n",
    "        # Resblocks\n",
    "\n",
    "# Dataset Sizes\n",
    "\n",
    "# One modality\n",
    "\n",
    "# Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Our model\n",
    "    # Baseline (4Resblock_128filters) + Parallel extractor\n",
    "    # Baseline (4Resblock_128filters) + Interleaved Extractor\n",
    "    # Our best configuration for parallel extractor\n",
    "    # Our best configuration for Interleaved extractor\n",
    "    \n",
    "columns = ['extractor_filters', 'extractor_projection_size', 'test_acc', 'max_freq', 'n_fft', 'keep_freq_point', 'extractor_type', 'nb_trainable_param_round', 'note', 'folder']\n",
    "\n",
    "# From recent experiments\n",
    "filters = (experiments['date'] >= '2020-09-01')\n",
    "\n",
    "# Parallel or Interleaved extractor\n",
    "filters &= (experiments['extractor_type'].isin(['freq_time_interlaced', 'freq_time_separated']))\n",
    "\n",
    "# Baseline Resblocks config\n",
    "filters &= (experiments['nb_resblock'] == 4) & (experiments['resblocks_out_chan'] == 128)\n",
    "\n",
    "filters &= (experiments['n_mels'].isnull())\n",
    "\n",
    "\n",
    "exp = experiments[filters].sort_values('test_acc', ascending=False)\n",
    "\n",
    "# NOTE : Hardcoded... This is dependant on the order of the DF..\n",
    "names_by_index = {\n",
    "    500: '1D-ConvLearned',\n",
    "    391: 'RGB-Resnet-Imagenet-Stats',\n",
    "    248: 'RGB-ConvLearned',\n",
    "    130: 'RGB-Resnet-ClearStats',\n",
    "    392: 'RGB-Resnet-Imagenet-Renorm'\n",
    "}\n",
    "\n",
    "#for index, name in names_by_index.items():\n",
    "#    exp.loc[index, 'name'] = name\n",
    "\n",
    "exp['name'] = exp.apply(lambda x: '4ResBl-128F', axis=1)\n",
    "columns = ['name'] + columns\n",
    "\n",
    "color_by_multi_attribute(exp[columns], main_attribute=\"extractor_type\", attributes=['n_fft'], format_dict=latex_format_dict)\n",
    "\n",
    "#exp[columns].style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameter reduction\n",
    "    # Best extractor (Either parallel or interleaved)\n",
    "        # GRU\n",
    "    \n",
    "columns = ['rnn_state_size', 'extractor_filters', 'extractor_projection_size', 'test_acc', 'max_freq', 'n_fft', 'keep_freq_point', 'extractor_type', 'nb_trainable_param_round']#, 'note', 'folder']\n",
    "\n",
    "# From recent experiments\n",
    "filters = (experiments['date'] >= '2020-09-01')\n",
    "\n",
    "# Parallel or Interleaved extractor\n",
    "filters &= (experiments['extractor_type'].isin(['freq_time_interlaced', 'freq_time_separated']))\n",
    "\n",
    "# Baseline Resblocks config\n",
    "filters &= (experiments['nb_resblock'] == 3) & (experiments['resblocks_out_chan'] == 64)\n",
    "\n",
    "filters &= (experiments['n_mels'].isnull())\n",
    "\n",
    "\n",
    "exp = experiments[filters].sort_values('test_acc', ascending=False)\n",
    "\n",
    "# NOTE : Hardcoded... This is dependant on the order of the DF..\n",
    "names_by_index = {\n",
    "    500: '1D-ConvLearned',\n",
    "    391: 'RGB-Resnet-Imagenet-Stats',\n",
    "    248: 'RGB-ConvLearned',\n",
    "    130: 'RGB-Resnet-ClearStats',\n",
    "    392: 'RGB-Resnet-Imagenet-Renorm'\n",
    "}\n",
    "\n",
    "#for index, name in names_by_index.items():\n",
    "#    exp.loc[index, 'name'] = name\n",
    "\n",
    "exp['name'] = exp.apply(lambda x: '3ResBl-64F', axis=1)\n",
    "columns = ['name'] + columns\n",
    "\n",
    "color_by_multi_attribute(exp[columns], main_attribute=\"extractor_type\", attributes=['n_fft'], format_dict=latex_format_dict)\n",
    "\n",
    "#exp[columns].style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameter reduction\n",
    "    # Best extractor (Either parallel or interleaved)\n",
    "        # Classifier\n",
    "    \n",
    "columns = ['classifier_type', 'classifier_conv_out', 'classifier_projection_out', 'classifier_global_pool', 'extractor_filters', 'extractor_projection_size', 'test_acc', 'max_freq', 'n_fft', 'keep_freq_point', 'extractor_type', 'nb_trainable_param_round', 'note', 'folder']\n",
    "\n",
    "# From recent experiments\n",
    "filters = (experiments['date'] >= '2020-09-01')\n",
    "\n",
    "# Parallel or Interleaved extractor\n",
    "filters &= (experiments['extractor_type'].isin(['freq_time_interlaced', 'freq_time_separated']))\n",
    "\n",
    "# Baseline Resblocks config\n",
    "filters &= (experiments['nb_resblock'] == 3) & (experiments['resblocks_out_chan'] == 64)\n",
    "\n",
    "filters &= (experiments['n_mels'].isnull())\n",
    "\n",
    "\n",
    "exp = experiments[filters].sort_values('test_acc', ascending=False)\n",
    "\n",
    "# NOTE : Hardcoded... This is dependant on the order of the DF..\n",
    "names_by_index = {\n",
    "    500: '1D-ConvLearned',\n",
    "    391: 'RGB-Resnet-Imagenet-Stats',\n",
    "    248: 'RGB-ConvLearned',\n",
    "    130: 'RGB-Resnet-ClearStats',\n",
    "    392: 'RGB-Resnet-Imagenet-Renorm'\n",
    "}\n",
    "\n",
    "#for index, name in names_by_index.items():\n",
    "#    exp.loc[index, 'name'] = name\n",
    "\n",
    "exp['name'] = exp.apply(lambda x: '3ResBl-64F', axis=1)\n",
    "columns = ['name'] + columns\n",
    "\n",
    "color_by_multi_attribute(exp[columns], main_attribute=\"extractor_type\", attributes=['n_fft'], format_dict=latex_format_dict)\n",
    "\n",
    "#exp[columns].style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameter reduction\n",
    "    # Best extractor (Either parallel or interleaved)\n",
    "        # Resblocks\n",
    "    \n",
    "columns = ['nb_resblock', 'resblocks_out_chan', 'extractor_filters', 'extractor_projection_size', 'test_acc', 'max_freq', 'n_fft', 'keep_freq_point', 'extractor_type', 'nb_trainable_param_round', 'note', 'folder']\n",
    "\n",
    "# From recent experiments\n",
    "filters = (experiments['date'] >= '2020-09-01')\n",
    "\n",
    "# Parallel or Interleaved extractor\n",
    "filters &= (experiments['extractor_type'].isin(['freq_time_interlaced', 'freq_time_separated']))\n",
    "\n",
    "filters &= (experiments['n_mels'].isnull())\n",
    "\n",
    "\n",
    "exp = experiments[filters].sort_values('test_acc', ascending=False)\n",
    "\n",
    "# NOTE : Hardcoded... This is dependant on the order of the DF..\n",
    "names_by_index = {\n",
    "    500: '1D-ConvLearned',\n",
    "    391: 'RGB-Resnet-Imagenet-Stats',\n",
    "    248: 'RGB-ConvLearned',\n",
    "    130: 'RGB-Resnet-ClearStats',\n",
    "    392: 'RGB-Resnet-Imagenet-Renorm'\n",
    "}\n",
    "\n",
    "#for index, name in names_by_index.items():\n",
    "#    exp.loc[index, 'name'] = name\n",
    "\n",
    "exp['name'] = exp.apply(lambda x: '3ResBl-64F', axis=1)\n",
    "columns = ['name'] + columns\n",
    "\n",
    "color_by_multi_attribute(exp[columns], main_attribute=\"extractor_type\", attributes=['n_fft'], format_dict=latex_format_dict)\n",
    "\n",
    "#exp[columns].style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Network reduction -- GRU units\n",
    "df_filter = ((experiments['note'] == 'final_dropout') & (experiments['config'].str.contains('reduction')) & (~experiments['config'].str.contains('proj')) & (~experiments['config'].str.contains('conv')) & (experiments['classifier_type'] == 'fcn'))\n",
    "columns = ['nb_trainable_param', 'rnn_state_size', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "GRU_table = experiments[df_filter][columns].sort_values('nb_trainable_param', ascending=False).reset_index(drop=True)\n",
    "\n",
    "text = ['hola', 'quetal', 'muybien', 'tu', 'fff']\n",
    "GRU_table['text'] = GRU_table.apply(lambda s: text[s.name], axis=1)\n",
    "\n",
    "# Reorder columns (Set text first)\n",
    "GRU_table = GRU_table[['text'] + GRU_table.columns.tolist()[:-1]]\n",
    "\n",
    "#print(GRU_table.to_latex(index=False, formatters=latex_format_dict))\n",
    "GRU_table.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Network reduction -- Classifier\n",
    "df_filter =  (experiments['note'] == 'final') & (experiments['config'].str.contains('reduction'))\n",
    "df_filter &= (~experiments['config'].str.contains('extractor')) & (~experiments['config'].str.contains('proj'))\n",
    "df_filter &= (experiments['rnn_state_size'].isin([4096, 1024, 256]))\n",
    "\n",
    "columns = ['nb_trainable_param', 'rnn_state_size', 'classifier_type', 'classifier_conv_out', 'classifier_projection_out', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_trained']#, 'train_time']\n",
    "classifier = experiments[df_filter].sort_values('nb_trainable_param', ascending=False)[columns]\n",
    "\n",
    "#print(classifier.to_latex(index=False, formatters=latex_format_dict))\n",
    "classifier.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Network reduction -- Reduction Filters/Nb Resblocks\n",
    "df_filter =  (experiments['note'] == 'final') & (experiments['config'].str.contains('reduction'))\n",
    "df_filter &= (experiments['config'].str.contains('extractor')) & (~experiments['config'].str.contains('proj'))\n",
    "df_filter &= (experiments['rnn_state_size'].isin([4096, 1024, 256]))\n",
    "\n",
    "only_rnn_reduction_filter = (experiments['note'] == 'final') & (experiments['config'].isin(['reduction_original_rnn_1024_fcn_no_conv_hidden_256', \"reduction_original_rnn_1024_fcn_conv_256_hidden_512\"]))\n",
    "\n",
    "df_filter |= only_rnn_reduction_filter\n",
    "\n",
    "columns = ['nb_trainable_param', 'extractor_out_chan', 'stem_out_chan', 'nb_resblock', 'classifier_conv_out', 'classifier_projection_out', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "\n",
    "reduction_experiments = experiments[df_filter].sort_values('nb_trainable_param', ascending=False)[columns]\n",
    "\n",
    "#print(reduction_experiments.to_latex(index=False, formatters=latex_format_dict))\n",
    "reduction_experiments.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Extractor -- Parallel Extractor\n",
    "df_filter = (experiments['note'] == 'extractor') & (experiments['extractor_type'] == 'freq_time_separated')\n",
    "\n",
    "columns = ['extractor_filters', 'extractor_projection_size', 'extractor_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'nb_trainable_param']#, 'train_time']\n",
    "\n",
    "parallel_extractor = experiments[df_filter]\n",
    "\n",
    "# Average Results grouped over ['config', 'nb_scene', 'nb_q_per_scene']\n",
    "parallel_extractor = groupby_mean(parallel_extractor, \n",
    "                                     groupby_columns=['config', 'nb_scene', 'nb_q_per_scene'],\n",
    "                                     mean_columns=['train_acc', 'best_val_acc', 'test_acc'],\n",
    "                                    selected_columns=columns,\n",
    "                                    add_count_col=False)\n",
    "\n",
    "#parallel_extractor = convert_cols_to_int(parallel_extractor, ['nb_epoch_runned'])\n",
    "\n",
    "parallel_extractor = parallel_extractor.sort_values('nb_trainable_param', ascending=False)#[columns]\n",
    "\n",
    "#print(parallel_extractor.to_latex(index=False, formatters=latex_format_dict))\n",
    "parallel_extractor.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Extractor -- Interlaced Extractor -- Time First\n",
    "df_filter = (experiments['note'] == 'extractor') & (experiments['extractor_type'] == 'freq_time_interlaced')\n",
    "df_filter &= (experiments['config'].str.contains('timefirst'))\n",
    "\n",
    "columns = ['nb_trainable_param', 'extractor_nb_block', 'extractor_filters', 'extractor_projection_size', 'extractor_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "\n",
    "interleaved_extractor_timefirst = experiments[df_filter]\n",
    "\n",
    "# Average Results grouped over ['config', 'nb_scene', 'nb_q_per_scene']\n",
    "interleaved_extractor_timefirst = groupby_mean(interleaved_extractor_timefirst, \n",
    "                                     groupby_columns=['config', 'nb_scene', 'nb_q_per_scene'],\n",
    "                                     mean_columns=['train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned'],\n",
    "                                    selected_columns=columns,\n",
    "                                    add_count_col=False)\n",
    "\n",
    "interleaved_extractor_timefirst = convert_cols_to_int(interleaved_extractor_timefirst, ['nb_epoch_runned'])\n",
    "interleaved_extractor_timefirst = interleaved_extractor_timefirst.sort_values('test_acc', ascending=False)#[columns]\n",
    "\n",
    "#print(interleaved_extractor_timefirst.to_latex(index=False, formatters=latex_format_dict))\n",
    "interleaved_extractor_timefirst.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Feature Extractor -- Interlaced Extractor -- Freq First\n",
    "df_filter = (experiments['note'] == 'extractor') & (experiments['extractor_type'] == 'freq_time_interlaced')\n",
    "df_filter &= (~experiments['config'].str.contains('timefirst'))\n",
    "\n",
    "columns = ['nb_trainable_param', 'extractor_nb_block', 'extractor_filters', 'extractor_projection_size', 'extractor_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "\n",
    "interleaved_extractor_freqfirst = experiments[df_filter]\n",
    "\n",
    "# Average Results grouped over ['config', 'nb_scene', 'nb_q_per_scene']\n",
    "interleaved_extractor_freqfirst = groupby_mean(interleaved_extractor_freqfirst, \n",
    "                                     groupby_columns=['config', 'nb_scene', 'nb_q_per_scene'],\n",
    "                                     mean_columns=['train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned'],\n",
    "                                    selected_columns=columns,\n",
    "                                    add_count_col=False)\n",
    "\n",
    "interleaved_extractor_freqfirst = convert_cols_to_int(interleaved_extractor_freqfirst, ['nb_epoch_runned'])\n",
    "interleaved_extractor_freqfirst = interleaved_extractor_freqfirst.sort_values('nb_trainable_param', ascending=False)#[columns]\n",
    "\n",
    "#print(interleaved_extractor_freqfirst.to_latex(index=False, formatters=latex_format_dict))\n",
    "interleaved_extractor_freqfirst.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Dataset size comparison -- Mixed -- 100k, 200k, 400k samples\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "fig_name = \"dataset_size_all_samples.pdf\"\n",
    "df_filter = (experiments['note'] == 'dataset_size')\n",
    "columns = ['nb_sample', 'nb_scene', 'nb_q_per_scene', 'test_acc']\n",
    "dataset_size = experiments[df_filter].sort_values('nb_q_per_scene')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "lines = []\n",
    "\n",
    "grouped_by_sample_400k = dataset_size[dataset_size['nb_sample'] == 400000]\n",
    "\n",
    "# Get colorlist\n",
    "group_unique_keys = grouped_by_sample_400k['nb_scene'].unique()\n",
    "colorlist = {key: colors.rgb2hex(matplotlib.cm.gist_rainbow_r(i)) for key, i in\n",
    "             zip(group_unique_keys, np.linspace(0, 0.9, len(group_unique_keys)))}\n",
    "\n",
    "# Plot 400k lines & markers\n",
    "lines += ax.plot(grouped_by_sample_400k['nb_q_per_scene'], grouped_by_sample_400k['test_acc'], linewidth=1, linestyle=':', zorder=1)\n",
    "grouped_scatter(grouped_by_sample_400k, 'nb_scene', 'nb_q_per_scene', 'test_acc', ax = ax, show_label=True, colorlist=colorlist, \n",
    "                label_modifier=lambda n: f\"{int(n/1000)}k scenes  \", additional_params={\"marker\": \",\", \"zorder\":2, \"edgecolor\":lines[0].get_markerfacecolor(), \"linewidth\":1})\n",
    "\n",
    "# Plot 200k lines & markers\n",
    "grouped_by_sample_200k = dataset_size[dataset_size['nb_sample'] == 200000]\n",
    "lines += ax.plot(grouped_by_sample_200k['nb_q_per_scene'], grouped_by_sample_200k['test_acc'], linewidth=1, linestyle=':', zorder=1)\n",
    "grouped_scatter(grouped_by_sample_200k, 'nb_scene', 'nb_q_per_scene', 'test_acc', ax = ax, show_label=False, colorlist=colorlist, additional_params={\"marker\": \",\", \"zorder\":2, \"edgecolor\":lines[1].get_markerfacecolor(), \"linewidth\":1})\n",
    "\n",
    "# Plot 100k lines & markers\n",
    "grouped_by_sample_100k = dataset_size[dataset_size['nb_sample'] == 100000]\n",
    "lines += ax.plot(grouped_by_sample_100k['nb_q_per_scene'], grouped_by_sample_100k['test_acc'], linewidth=1, linestyle=':', zorder=1)\n",
    "grouped_scatter(grouped_by_sample_100k, 'nb_scene', 'nb_q_per_scene', 'test_acc', ax = ax, show_label=False, colorlist=colorlist, additional_params={\"marker\": \",\", \"zorder\":2, \"edgecolor\":lines[2].get_markerfacecolor(), \"linewidth\":1})\n",
    "\n",
    "# Remove marker border from legend\n",
    "for legend_handle in ax.get_legend().legendHandles:\n",
    "    legend_handle.set_linewidths(0)\n",
    "\n",
    "# Add Second legend\n",
    "ax.add_artist(matplotlib.legend.Legend(ax, lines, ['400k samples', '200k samples', '100k samples'], loc='center right'))\n",
    "\n",
    "# Set axis infos\n",
    "ax.set_xscale('log')\n",
    "ax.set_xticks(dataset_size['nb_q_per_scene'].unique())\n",
    "ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "ax.set_xlim([0.9, 43])\n",
    "ax.set_xlabel('Number of question per scene')\n",
    "ax.set_ylabel('Accuracy')\n",
    "\n",
    "fig.savefig(f\"stats/{fig_name}\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset size comparison -- Mixed -- 100k, 200k, 400k samples\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import seaborn as sns\n",
    "\n",
    "fig_name = \"dataset_size_all_samples_giampi.pdf\"\n",
    "df_filter = (experiments['note'] == 'dataset_size')\n",
    "columns = ['nb_sample', 'nb_scene', 'nb_q_per_scene', 'test_acc']\n",
    "dataset_size = experiments[df_filter].sort_values('nb_q_per_scene')\n",
    "#print(dataset_size)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.set_palette(\"colorblind\")\n",
    "g = sns.barplot(x='nb_scene', y='test_acc', hue='nb_sample', data=dataset_size)\n",
    "# the following is an ugly hack that only works if the accuracy values are all different!!\n",
    "for patch in ax.patches:\n",
    "    if np.isnan(patch.get_height()):\n",
    "        continue\n",
    "    idx = np.argmin(np.abs(dataset_size.test_acc-patch.get_height()))\n",
    "    #g.text(patch.get_x()+patch.get_width()/2, patch.get_height(), dataset_size.nb_q_per_scene[idx], color='black', ha='center')\n",
    "    g.text(patch.get_x()+patch.get_width()/2, 0.96, dataset_size.nb_q_per_scene[idx], color='black', ha='center')\n",
    "g.text(1.5, 1.01, '# questions per scene', color='black')\n",
    "plt.xlabel('# scenes')\n",
    "plt.ylabel('Accuracy')\n",
    "h, l = ax.get_legend_handles_labels()\n",
    "ax.legend(h, l, title='# examples', loc='lower left')\n",
    "\n",
    "fig.savefig(f\"stats/{fig_name}\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_name = \"dataset_size_all_samples_giampi2.pdf\"\n",
    "df_filter = (experiments['note'] == 'dataset_size')\n",
    "columns = ['nb_sample', 'nb_scene', 'nb_q_per_scene', 'test_acc']\n",
    "dataset_size = experiments[df_filter].sort_values('nb_q_per_scene')\n",
    "#print(dataset_size)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.set_palette(\"colorblind\")\n",
    "g = sns.barplot(x='nb_sample', y='test_acc', hue='nb_scene', data=dataset_size)\n",
    "# the following is an ugly hack that only works if the accuracy values are all different!!\n",
    "for patch in ax.patches:\n",
    "    if np.isnan(patch.get_height()):\n",
    "        continue\n",
    "    idx = np.argmin(np.abs(dataset_size.test_acc-patch.get_height()))\n",
    "    #g.text(patch.get_x()+patch.get_width()/2, patch.get_height(), dataset_size.nb_q_per_scene[idx], color='black', ha='center')\n",
    "    g.text(patch.get_x()+patch.get_width()/2, 0.96, dataset_size.nb_q_per_scene[idx], color='black', ha='center')\n",
    "g.text(0.5, 1.01, '# questions per scene', color='black')\n",
    "plt.xlabel('# examples')\n",
    "plt.ylabel('Accuracy')\n",
    "h, l = ax.get_legend_handles_labels()\n",
    "ax.legend(h, l, title='# scenes', loc='lower right')\n",
    "\n",
    "fig.savefig(f\"stats/{fig_name}\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig_name = \"dataset_size_all_samples_giampi3.pdf\"\n",
    "df_filter = (experiments['note'] == 'dataset_size')\n",
    "columns = ['nb_sample', 'nb_scene', 'nb_q_per_scene', 'test_acc']\n",
    "dataset_size = experiments[df_filter].sort_values('nb_q_per_scene')\n",
    "subset100k = dataset_size.nb_sample == 100000\n",
    "subset200k = dataset_size.nb_sample == 200000\n",
    "subset400k = dataset_size.nb_sample == 400000\n",
    "#print(dataset_size)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(6,4), sharey=True)\n",
    "#sns.set_palette(\"colorblind\")\n",
    "g = sns.barplot(x='nb_q_per_scene', y='test_acc', data=dataset_size[subset100k], color='dodgerblue', ax=ax[0])\n",
    "ax[0].set_xlabel('')\n",
    "ax[0].set_xticklabels(['100k x 1', '50k x 2', '20k x 5', '10k x 10'], rotation=90)\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].set_title('100k records')\n",
    "mean = dataset_size[subset100k]['test_acc'].mean()\n",
    "ax[0].axhline(y=mean, linestyle=\"--\", color='orange')\n",
    "\n",
    "g = sns.barplot(x='nb_q_per_scene', y='test_acc', data=dataset_size[subset200k], color='dodgerblue', ax=ax[1])\n",
    "ax[1].set_xlabel('(# scenes) x (# questions per scene)')\n",
    "ax[1].set_xticklabels(['200k x 1', '100k x 2', '50k x 4', '20k x 10', '10k x 20'], rotation=90)\n",
    "ax[1].set_ylabel('')\n",
    "ax[1].set_title('200k records')\n",
    "mean = dataset_size[subset200k]['test_acc'].mean()\n",
    "ax[1].axhline(y=mean, linestyle=\"--\", color='orange')\n",
    "\n",
    "g = sns.barplot(x='nb_q_per_scene', y='test_acc', data=dataset_size[subset400k], color='dodgerblue', ax=ax[2])\n",
    "ax[2].set_xlabel('')\n",
    "ax[2].set_xticklabels(['400k x 1', '200k x 2', '100k x 4', '50k x 8', '20k x 20', '10k x 40'], rotation=90)\n",
    "ax[2].set_ylabel('')\n",
    "ax[2].set_title('400k records')\n",
    "mean = dataset_size[subset400k]['test_acc'].mean()\n",
    "ax[2].axhline(y=mean, linestyle=\"--\", color='orange')\n",
    "\n",
    "plt.subplots_adjust(wspace=-0.5)\n",
    "plt.tight_layout()\n",
    "#h, l = ax.get_legend_handles_labels()\n",
    "#ax.legend(h, l, title='# scenes', loc='lower right')\n",
    "\n",
    "fig.savefig(f\"stats/{fig_name}\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([f for f in dir(ax[2]) if '_' not in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax[2].lines[3].get_ydata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset size 400k - Data\n",
    "\n",
    "columns = ['nb_trainable_param', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "\n",
    "#print(grouped_by_sample_400k[columns].to_latex(index=False, formatters=latex_format_dict))\n",
    "grouped_by_sample_400k[columns].style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset size 200k - Data\n",
    "\n",
    "columns = ['nb_trainable_param', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "\n",
    "#print(grouped_by_sample_200k[columns].to_latex(index=False, formatters=latex_format_dict))\n",
    "grouped_by_sample_200k[columns].style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset size 100k - Data\n",
    "\n",
    "columns = ['nb_trainable_param', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "\n",
    "#print(grouped_by_sample_100k[columns].to_latex(index=False, formatters=latex_format_dict))\n",
    "grouped_by_sample_100k[columns].style.format(latex_format_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "film-aqa-torch-1.3",
   "language": "python",
   "name": "film-aqa-torch-1.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
