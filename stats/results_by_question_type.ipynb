{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic functions -- Run Once\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "# Move up one folder to reach the repo root\n",
    "%cd ..\n",
    "\n",
    "from utils.notebook.generic import full_width_notebook\n",
    "\n",
    "full_width_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths, Imports & Configs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.file import read_json\n",
    "\n",
    "from utils.generic import get_answer_to_family_map, chain_load_experiment_stats, separate_stats_by_set\n",
    "#from utils.generic import chain_load_batch_metrics\n",
    "from utils.notebook.result_analysis import load_experiment_predictions, sort_correct_incorrect_predictions\n",
    "from utils.notebook.result_analysis import plot_confusion_matrix, plot_predictions_distribution_per_question_family\n",
    "from utils.notebook.result_analysis import plot_predictions_confidence, plot_acc_loss_by_epoch, plot_predictions_confidence_gap\n",
    "from utils.notebook.generic import separate_preds_ground_truth\n",
    "\n",
    "root_data_path = \"data\"\n",
    "root_output_path = \"output_synced/training\"\n",
    "\n",
    "# No coordconv\n",
    "folder_path = \"CLEAR_50k_4_inst_audio_win_512_hop_2048_keep_256_norm_zero_one_norm_clear_stats_table_7_CoordConv_Extr_None_Stem_None_Resblock_None_Classifier_None_40_epoch_189369_table_7_table_7_final/2020-12-07_06h02\"\n",
    "\n",
    "# With only time coordconv\n",
    "folder_path = \"CLEAR_50k_4_inst_audio_win_512_hop_2048_keep_256_norm_zero_one_norm_clear_stats_table_7_CoordConv_Extr_None_Stem_None_Resblock_Time_Classifier_None_40_epoch_876944_table_7_table_7_final/2020-12-01_14h29\"\n",
    "\n",
    "# Resnet\n",
    "folder_path = \"CLEAR_50k_4_inst_audio_win_512_hop_2048_keep_256_RGB_norm_zero_one_norm_clear_stats_resnet_table_1_baseline_40_epoch_427438_table_1_table_1_final_final/2020-12-06_15h43\"\n",
    "\n",
    "# Test\n",
    "folder_path = 'CLEAR_50k_4_inst_audio_win_512_hop_2048_keep_256_norm_zero_one_norm_clear_stats_extractor_slim_parallel_3_block_64_proj_spatial_time_resblock_classifier_40_epoch_876944_1d_spatial_test/2020-11-07_23h58'\n",
    "\n",
    "# NAAQA\n",
    "folder_path = 'CLEAR_50k_4_inst_audio_win_512_hop_2048_keep_256_norm_zero_one_norm_clear_stats_table_2_parallel_extractor_40_epoch_876944_table_2_table_2_final_final/2020-11-29_21h51'\n",
    "\n",
    "folder_path = 'CLEAR_50k_4_inst_audio_win_512_hop_2048_mels_128_norm_zero_one_norm_clear_stats_table_7_bigger_interleaved_CoordConv_Extr_None_Stem_None_Resblock_Time_Classifier_None_40_epoch_876944_review_coordinate_maps_mel_part_1/2021-10-28_02h17'\n",
    "\n",
    "experiment_output_path = 'output/inference/CLEAR_cogent_50k_4_inst_audio_test_cogent/2021-11-04_20h20'\n",
    "\n",
    "experiment_output_path = 'output/inference/CLEAR_cogent_50k_4_inst_audio_test_cogent/2021-11-04_20h55'\n",
    "\n",
    "#experiment_output_path = f\"{root_output_path}/{folder_path}\"\n",
    "epoch_id = \"best\"\n",
    "\n",
    "data_name = \"CLEAR_cogent_50k_4_inst_audio\"\n",
    "data_path = f\"{root_data_path}/{data_name}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_filters = set()\n",
    "for q in questions:\n",
    "    if sum([1 for p in q['program'] if p['type'] == \"relate\"]) > 0:\n",
    "        continue\n",
    "        \n",
    "    test1 = [n['type'] for n in q['program'] if 'filter' in n['type']]\n",
    "    test2 = [n['type'] for n in q['program'] if 'filter' in n['type'] and len(n['value_inputs']) > 0]\n",
    "    \n",
    "    if len(test1) != len(test2):\n",
    "        print(set(test1) - set(test2))\n",
    "        \n",
    "    filters = {n['type'] for n in q['program'] if 'filter' in n['type']}\n",
    "    all_filters.update(filters)\n",
    "    \n",
    "all_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{q['template_index'].split('-')[0] for q in questions if ' or ' in q['question']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[q for q in [qo for qo in with_or if qo['program'][-1]['type'] == 'or']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_q = [questions[p['question_id']] for p in predictions if p['ground_truth_answer_family'] == 'boolean']\n",
    "{q['program'][-1]['type'] for q in bool_q}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "{q['question'] for q in questions if 'count' in q['template_index'] and q['program'][-1]['type'] == 'count_different_instrument'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([1 for p in predictions if p['correct']])/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_to_family_map\n",
    "questions[0]\n",
    "#get_answer_to_family_map(f'{data_path}/attributes.json', to_lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from files\n",
    "answer_to_family_map = get_answer_to_family_map(f'{data_path}/attributes.json', to_lowercase=True, reduced_text=True)\n",
    "answer_families = list(set(answer_to_family_map.values()))\n",
    "\n",
    "predictions = load_experiment_predictions(experiment_output_path, epoch_id, set_type='test', reduced_text=True)\n",
    "questions = read_json(f\"{data_path}/questions/CLEAR_test_questions.json\")['questions']\n",
    "\n",
    "for pred in predictions:\n",
    "    question = questions[pred['question_id']]\n",
    "    \n",
    "    pred['relate_count'] = sum([1 for p in question['program'] if p['type'] == \"relate\"])\n",
    "    pred['position_filter'] = len([1 for p in question['program'] if \"filter_position\" in p['type']]) > 0\n",
    "    pred['has_relate'] = pred['relate_count'] > 0\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions, columns=['question_id', 'scene_id', 'scene_length', 'correct', 'prediction', 'ground_truth', 'prediction_answer_family', 'ground_truth_answer_family', 'confidence', 'relate_count', 'has_relate', 'position_filter'])\n",
    "grouped = predictions_df.groupby(['ground_truth_answer_family','correct','relate_count', 'position_filter'], as_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE : THIS IS DEFINITELY NOT THE GOOD WAY OF DOING THIS... JUST NEED SOME QUICK DATA\n",
    "\n",
    "families = {k[0] for k in grouped.groups.keys()}\n",
    "\n",
    "grouped_count = grouped.count()\n",
    "\n",
    "agg = []\n",
    "for family in families:\n",
    "    global_correct_count = grouped_count[(grouped_count['ground_truth_answer_family'] == family) & (grouped_count['correct'] == True)]['prediction'].sum()\n",
    "    global_incorrect_count = grouped_count[(grouped_count['ground_truth_answer_family'] == family) & (grouped_count['correct'] == False)]['prediction'].sum()\n",
    "    \n",
    "    correct_count_no_relate = grouped_count[(grouped_count['ground_truth_answer_family'] == family) & (grouped_count['correct'] == True) & (grouped_count['relate_count'] == 0)]['prediction'].sum()\n",
    "    incorrect_count_no_relate = grouped_count[(grouped_count['ground_truth_answer_family'] == family) & (grouped_count['correct'] == False) & (grouped_count['relate_count'] == 0)]['prediction'].sum()\n",
    "    \n",
    "    correct_count_one_relate = grouped_count[(grouped_count['ground_truth_answer_family'] == family) & (grouped_count['correct'] == True) & (grouped_count['relate_count'] == 1)]['prediction'].sum()\n",
    "    incorrect_count_one_relate = grouped_count[(grouped_count['ground_truth_answer_family'] == family) & (grouped_count['correct'] == False) & (grouped_count['relate_count'] == 1)]['prediction'].sum()\n",
    "    \n",
    "    correct_count_two_relate = grouped_count[(grouped_count['ground_truth_answer_family'] == family) & (grouped_count['correct'] == True) & (grouped_count['relate_count'] == 2)]['prediction'].sum()\n",
    "    incorrect_count_two_relate = grouped_count[(grouped_count['ground_truth_answer_family'] == family) & (grouped_count['correct'] == False) & (grouped_count['relate_count'] == 2)]['prediction'].sum()\n",
    "        \n",
    "    if correct_count_two_relate + incorrect_count_two_relate > 0:\n",
    "        acc_two_relate = correct_count_two_relate / (correct_count_two_relate + incorrect_count_two_relate)\n",
    "    else:\n",
    "        acc_two_relate = pd.NA\n",
    "        \n",
    "    correct_with_filter_position = grouped_count[(grouped_count['ground_truth_answer_family'] == family) & (grouped_count['correct'] == True) & (grouped_count['position_filter'] == True)]['prediction'].sum()\n",
    "    incorrect_with_filter_position = grouped_count[(grouped_count['ground_truth_answer_family'] == family) & (grouped_count['correct'] == False) & (grouped_count['position_filter'] == True)]['prediction'].sum()\n",
    "    \n",
    "    correct_no_filter_position = grouped_count[(grouped_count['ground_truth_answer_family'] == family) & (grouped_count['correct'] == True) & (grouped_count['position_filter'] == False)]['prediction'].sum()\n",
    "    incorrect_no_filter_position = grouped_count[(grouped_count['ground_truth_answer_family'] == family) & (grouped_count['correct'] == False) & (grouped_count['position_filter'] == False)]['prediction'].sum()\n",
    "    \n",
    "    agg.append({\n",
    "        'family' : family,\n",
    "        'acc_global': global_correct_count / (global_correct_count + global_incorrect_count),\n",
    "        'acc_with_filter_position': correct_with_filter_position / (correct_with_filter_position + incorrect_with_filter_position),\n",
    "        'acc_no_filter_position': correct_no_filter_position / (correct_no_filter_position + incorrect_no_filter_position),\n",
    "        'acc_no_relate': correct_count_no_relate / (correct_count_no_relate + incorrect_count_no_relate),\n",
    "        'acc_one_relate': correct_count_one_relate / (correct_count_one_relate + incorrect_count_one_relate),\n",
    "        'acc_two_relate': acc_two_relate,\n",
    "        \n",
    "    })\n",
    "    \n",
    "df = pd.DataFrame(agg).sort_values('family', ascending=False)\n",
    "\n",
    "from utils.notebook.pandas import color_by_multi_attribute\n",
    "\n",
    "colored_df = color_by_multi_attribute(df, main_attribute=\"family\", \n",
    "                                 attributes=['acc_global', 'acc_with_filter_position', 'acc_no_filter_position', 'acc_no_relate', 'acc_one_relate', 'acc_two_relate'], \n",
    "                                 cmaps=['Blues','ocean_r','ocean_r','ocean_r','ocean_r','ocean_r','ocean_r'])\n",
    "\n",
    "colored_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {'acc_no_relate': 'No relation', 'acc_one_relate': '1 relation', 'acc_two_relate': '2 relation'}\n",
    "df[list(cols.keys())].mean(axis=0).rename(cols).plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# No coordinate maps -- Parallel feature extractor\n",
    "colored_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time coordinate maps in resblocks only -- Parallel feature extractor\n",
    "colored_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinate maps everywhere (Both) -- Resnet feature extractor\n",
    "colored_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "film-aqa-torch-1.3",
   "language": "python",
   "name": "film-aqa-torch-1.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
