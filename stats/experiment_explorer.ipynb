{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic functions -- Run Once\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "# Move up one folder to reach the repo root\n",
    "%cd ..\n",
    "\n",
    "from utils.notebook.generic import full_width_notebook\n",
    "\n",
    "full_width_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Paths, Imports & Configs\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from utils.notebook.experiment_explorer import get_experiments\n",
    "\n",
    "from utils.notebook.pandas import sub_cols_with_cond_and_create_new_col, grouped_scatter, groupby_mean, convert_cols_to_int\n",
    "\n",
    "root_data_path = \"data\"\n",
    "#root_output_path = \"output/training\"\n",
    "#root_output_path = \"/archive/abdj2702/training_limited_0.85\"\n",
    "root_output_path = \"output_synced/training\"\n",
    "\n",
    "# Helpers column selectors\n",
    "run_info_columns = ['prefix', 'nb_sample', 'config', 'nb_epoch_trained', 'stopped_early']\n",
    "more_accuracy_info_columns = ['0.6_at_epoch', '0.7_at_epoch', '0.8_at_epoch', '0.9_at_epoch']\n",
    "accuracy_columns = ['best_val_acc', 'train_acc', 'test_acc']\n",
    "loss_columns = ['best_val_loss', 'train_loss', 'test_loss']\n",
    "all_training_stats = ['all_train_acc', 'all_train_loss', 'all_val_acc', 'all_val_loss']\n",
    "model_config_columns = ['nb_trainable_param', 'word_embedding_dim', 'rnn_state_size', 'extractor_type', \n",
    "                        'stem_out_chan', 'nb_resblock', 'resblocks_out_chan', 'classifier_conv_out_chan', \n",
    "                        'classifier_type', 'classifier_global_pool', 'nb_answer']\n",
    "optimizer_columns = ['optimizer_type', 'optimizer_lr', 'optimizer_weight_decay', 'dropout_drop_prob']\n",
    "preprocessing_columns = ['pad_to_largest', 'resized_height', 'resized_width']\n",
    "timing_columns = ['train_time', 'mean_epoch_time']\n",
    "other_columns = ['nb_scene', 'nb_q_per_scene', 'date', 'batch_size', 'resnet_features', 'test_version', \n",
    "                 'random_seed', 'nb_non_trainable_param', 'total_nb_param', 'nb_epoch', 'stop_accuracy', 'folder', 'gpu_name']\n",
    "\n",
    "# Retrieve all experimentsi infos\n",
    "experiments = get_experiments(root_output_path)\n",
    "\n",
    "# Pretty printing\n",
    "format_dict = {\n",
    "    'total_nb_param': \"{:,d}\".format,\n",
    "    'nb_non_trainable_param': \"{:,d}\".format,\n",
    "    'nb_trainable_param': \"{:,d}\".format,\n",
    "    'nb_trainable_param_round': \"~ {:,d}\".format,\n",
    "    'nb_sample': \"{:,d}\".format,\n",
    "    'nb_scene': \"{:,d}\".format,\n",
    "    'rnn_state_size': \"{:,d}\".format,\n",
    "    'optimizer_lr': \"{:.2e}\".format,\n",
    "    'optimizer_weight_decay': \"{:.2e}\".format,\n",
    "    'best_val_acc': lambda x: \"{:.2f}%\".format(x*100) if not pd.isnull(x) else None,\n",
    "    'train_acc': lambda x: \"{:.2f}%\".format(x*100) if not pd.isnull(x) else None,\n",
    "    'test_acc': lambda x: \"{:.2f}%\".format(x*100) if not pd.isnull(x) else None,\n",
    "    '0.6_at_epoch': lambda x: x if not pd.isnull(x) else None,\n",
    "    '0.7_at_epoch': lambda x: x if not pd.isnull(x) else None,\n",
    "    '0.8_at_epoch': lambda x: x if not pd.isnull(x) else None,\n",
    "    '0.9_at_epoch': lambda x: x if not pd.isnull(x) else None\n",
    "}\n",
    "\n",
    "latex_format_dict = deepcopy(format_dict)\n",
    "latex_format_dict['nb_sample'] = lambda x: \"{:d}k\".format(x//1000)\n",
    "latex_format_dict['nb_scene'] = lambda x: \"{:d}k\".format(x//1000)\n",
    "latex_format_dict['best_val_acc'] = lambda x: \"{:.2f}\".format(x*100) if not pd.isnull(x) else None\n",
    "latex_format_dict['train_acc'] = lambda x: \"{:.2f}\".format(x*100) if not pd.isnull(x) else None\n",
    "latex_format_dict['test_acc'] = lambda x: \"{:.2f}\".format(x*100) if not pd.isnull(x) else None\n",
    "latex_format_dict['classifier_type'] = lambda x: 'Fcn' if x == 'fcn' else 'Conv-Avg'\n",
    "latex_format_dict['classifier_conv_out'] = lambda x: '{:d}'.format(int(x)) if not pd.isnull(x) else \"--\"\n",
    "latex_format_dict['classifier_projection_out'] = lambda x: '{:d}'.format(int(x)) if not pd.isnull(x) else \"--\"\n",
    "latex_format_dict['extractor_projection_size'] = lambda x: '{:d}'.format(int(x)) if not pd.isnull(x) else \"--\"\n",
    "latex_format_dict['extractor_filters'] = lambda x: str(x)[1:-1]  # Remove the '[' and ']' of str(array)\n",
    "\n",
    "# Round number params to the closest thousand to facilitate comparison\n",
    "experiments['nb_trainable_param_round'] = experiments['nb_trainable_param'].apply(lambda x: x//1000 * 1000)\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "exp_results_cols = run_info_columns + ['nb_scene', 'nb_q_per_scene'] + accuracy_columns + more_accuracy_info_columns + ['nb_trainable_param_round', 'note']\n",
    "exp_results = experiments[exp_results_cols].sort_values(['nb_scene', 'test_acc'], ascending=[True, False])\n",
    "\n",
    "experiments.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "experiments[experiments['config'].str.contains(\"3_block_64_proj\")].sort_values('test_acc', ascending=False)[exp_results_cols].style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(experiments['note'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#experiments[experiments['note'] == 'batching']['config'].values.tolist()\n",
    "df_filter = (experiments['config'].isin(experiments[experiments['note'] == 'batching']['config'].values.tolist()))\n",
    "df_filter &= (experiments['nb_scene'] == 50000) & (experiments['nb_q_per_scene'] == 4)\n",
    "df_filter &= (experiments['note'] == 'batching') | (experiments['note'] == 'extractor')\n",
    "df_filter |= ((experiments['config']=='reduction_original_rnn_4096') & (experiments['note'] == 'final_dropout'))\n",
    "experiments[df_filter].drop_duplicates(subset=['config', 'nb_scene', 'nb_q_per_scene', 'note'], keep='first').sort_values('config')[exp_results_cols + ['folder']]\n",
    "#experiments[experiments['note'] == 'batching'].sort_values('date', ascending=False)[exp_results_cols].style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delete_experiment_from_drive_script(df, dryrun=False):\n",
    "    for f, d in df[['folder', 'date']].values:\n",
    "        res_path = f\"{f}/{d.strftime('%Y-%m-%d_%Hh%M')}\"\n",
    "        cmd = f\"rclone delete Drive:result/training/{res_path} -P\"\n",
    "        if dryrun:\n",
    "            cmd += \" --dry-run\"\n",
    "        print(cmd)\n",
    "        \n",
    "get_delete_experiment_from_drive_script(experiments[experiments['note'] == 'resnet_noratio'], dryrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments[((experiments['note'] == 'extractor') & (experiments['extractor_type'] == 'freq_time_interlaced'))].sort_values('test_acc', ascending=False)[exp_results_cols + ['extractor_type']].style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = groupby_mean(experiments[(experiments['note'] == 'extractor')], ['config', 'nb_sample'], ['best_val_acc', 'train_acc', 'test_acc', '0.6_at_epoch', '0.7_at_epoch', '0.8_at_epoch'], exp_results_cols, add_count_col=True)\n",
    "\n",
    "df = convert_cols_to_int(df, ['0.6_at_epoch', '0.7_at_epoch', '0.8_at_epoch'])\n",
    "\n",
    "df.style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available configs :\")\n",
    "set(experiments['config'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(experiments.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp_results[(exp_results['note'] == 'extractor')].sort_values(['nb_sample', 'test_acc']).style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_filter = (~exp_results['config'].str.contains('film_original')) & (~exp_results['config'].str.contains('freq_time')) & (~exp_results['config'].str.contains('extractor')) & (~exp_results['config'].str.contains('resblock'))\n",
    "df_filter &= (exp_results['nb_sample'] == 200000) & (~exp_results['config'].str.contains('avg')) & (exp_results['stopped_early'] != 'stop_threshold')\n",
    "experiments[exp_results_cols + ['rnn_state_size']][df_filter].groupby('rnn_state_size').mean().sort_values(['test_acc'])#.style.format(format_dict)\n",
    "#exp_results[df_filter].sort_values(['test_acc']).style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_results[(exp_results['stopped_early'] == 'stop_threshold') & (~exp_results['config'].str.contains('extractor'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp_results[exp_results['nb_scene'] == 50000]\n",
    "#exp_results[exp_results['nb_sample'] == 200000].sort_values(['nb_scene', 'nb_q_per_scene']).style.format(format_dict)\n",
    "exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp_results[(exp_results['nb_scene'] <= 10000) & (exp_results['config'].str.contains('reduction'))].sort_values('test_acc').style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = ((experiments['config'].str.contains('reduction')) & (~experiments['config'].str.contains('stem')) & (~experiments['config'].str.contains('extractor')) & (~experiments['config'].str.contains('resblock')) & (~experiments['config'].str.contains('avg'))) | ((experiments['config'] == 'film_original') & (exp_results['nb_scene'] == 20000) & (exp_results['nb_q_per_scene'] == 20))\n",
    "reduction_experiments = experiments[experiments['config'].str.contains('reduction')][exp_results_cols + timing_columns].sort_values('config')\n",
    "reduction_experiments#[reduction_experiments['stopped_early'] == 'NO']['folder'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_results[(exp_results['config'].str.contains('interlaced_smallest'))].sort_values('test_acc', ascending=True).style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "\n",
    "def plot_training_stats(dataframe, names=None, title=None, colormap=cm.viridis, ax=None):\n",
    "    nb_rows = len(dataframe.index)\n",
    "\n",
    "    colorlist = {key: colors.rgb2hex(colormap(i)) for key, i in\n",
    "                 zip(dataframe.index, np.linspace(0, 0.9, nb_rows))}\n",
    "\n",
    "    if title is None:\n",
    "        title = \"Training Stats\"\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, axs = plt.subplots(2,1)\n",
    "        \n",
    "    fig.suptitle(title)\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[1].set_title(\"Loss\")\n",
    "        \n",
    "    for row in dataframe.itertuples():\n",
    "        label = f\"{row.config} - {row.nb_scene//1000}k_{row.nb_q_per_scene}_q\"\n",
    "        lines = axs[0].plot(row.all_train_acc, label=f\"TRAIN - {label}\")\n",
    "        axs[0].plot(row.all_val_acc, color=lines[0].get_color(), linestyle=\"--\")\n",
    "        \n",
    "        axs[1].plot(row.all_train_loss, color=lines[0].get_color())\n",
    "        axs[1].plot(row.all_val_loss, label=f\"VAL - {label}\", color=lines[0].get_color(), linestyle=\"--\")\n",
    "        \n",
    "    # Draw legend out of the plot\n",
    "    for ax in axs:\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.5, box.height])\n",
    "\n",
    "        ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "    #for key, group in dataframe.groupby(group_key):\n",
    "    #    group.plot.scatter(ax=ax, x=x_axis, y=y_axis, c=colorlist[key], label=key, title=title)\n",
    "    \n",
    "with_training_stats = experiments[exp_results_cols + all_training_stats]\n",
    "fig, ax = plot_training_stats(with_training_stats[(with_training_stats['config'].str.contains('separated'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_stats(with_training_stats[with_training_stats['nb_q_per_scene'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of test_acc by (nb_sample, nb_scene)\n",
    "exp_results[(~exp_results['config'].str.contains('film_original')) & (~exp_results['config'].str.contains('extractor'))].hist(column='train_acc', by=['nb_sample', 'nb_scene'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "grouped_scatter(experiments, 'config', 'nb_sample', 'test_acc')\n",
    "\n",
    "#grouped_scatter(experiments[experiments['config'] == 'film_original'], 'nb_q_per_scene', 'nb_scene', 'test_acc')\n",
    "\n",
    "test = experiments.copy()\n",
    "\n",
    "test['perf_delta_orig_vs_small_rnn'] = test[test['config'] == 'film_original']['test_acc'] - test[test['config'] == 'film_original_small_rnn']['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sub_cols_with_cond_and_create_new_col(experiments.copy(), 'perf_delta_orig_vs_small_rnn', 'test_acc', test['config'] == 'film_original_small_rnn', test['config'] == 'film_original', test['config'] == 'film_original_small_rnn')\n",
    "\n",
    "test.sort_values(['nb_sample', 'nb_scene'], ascending=False)[run_info_columns + ['test_acc', 'perf_delta_orig_vs_small_rnn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table = experiments[experiments['config'] == 'film_original'][['nb_sample', 'nb_scene', 'nb_q_per_scene', 'train_acc', 'best_val_acc', 'test_acc', '0.8_at_epoch']].sort_values(['nb_sample', 'nb_scene']).fillna(\"None\").to_latex(formatters=latex_format_dict)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Network reduction -- GRU units\n",
    "df_filter = ((experiments['note'] == 'final_dropout') & (experiments['config'].str.contains('reduction')) & (~experiments['config'].str.contains('proj')) & (~experiments['config'].str.contains('conv')) & (experiments['classifier_type'] == 'fcn'))\n",
    "columns = ['nb_trainable_param', 'rnn_state_size', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "reduction_experiments = experiments[df_filter][columns].sort_values('nb_trainable_param', ascending=False)\n",
    "print(reduction_experiments.to_latex(index=False, formatters=latex_format_dict))\n",
    "#reduction_experiments.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Network reduction -- Classifier\n",
    "df_filter =  (experiments['note'] == 'final') & (experiments['config'].str.contains('reduction'))\n",
    "df_filter &= (~experiments['config'].str.contains('extractor')) & (~experiments['config'].str.contains('proj'))\n",
    "df_filter &= (experiments['rnn_state_size'].isin([4096, 1024, 256]))\n",
    "\n",
    "columns = ['nb_trainable_param', 'rnn_state_size', 'classifier_type', 'classifier_conv_out', 'classifier_projection_out', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_trained']#, 'train_time']\n",
    "# This will drop duplicates and keep the biggest test_acc of the duplicates\n",
    "#reduction_experiments = experiments[df_filter].sort_values('test_acc', ascending=False).drop_duplicates(subset=['config', 'nb_scene', 'nb_q_per_scene'], keep='first')\n",
    "# Sort back via trainable params\n",
    "reduction_experiments = experiments[df_filter]\n",
    "\n",
    "# Cleanup\n",
    "\n",
    "reduction_experiments = reduction_experiments.sort_values('nb_trainable_param', ascending=False)[columns]\n",
    "print(reduction_experiments.to_latex(index=False, formatters=latex_format_dict))\n",
    "#reduction_experiments.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Network reduction -- Reduction Filters/Nb Resblocks\n",
    "df_filter =  (experiments['note'] == 'final') & (experiments['config'].str.contains('reduction'))\n",
    "df_filter &= (experiments['config'].str.contains('extractor')) & (~experiments['config'].str.contains('proj'))\n",
    "df_filter &= (experiments['rnn_state_size'].isin([4096, 1024, 256]))\n",
    "\n",
    "only_rnn_reduction_filter = (experiments['note'] == 'final') & (experiments['config'].isin(['reduction_original_rnn_1024_fcn_no_conv_hidden_256', \"reduction_original_rnn_1024_fcn_conv_256_hidden_512\"]))\n",
    "\n",
    "df_filter |= only_rnn_reduction_filter\n",
    "\n",
    "columns = ['config', 'nb_trainable_param', 'extractor_out_chan', 'stem_out_chan', 'nb_resblock', 'classifier_conv_out', 'classifier_projection_out', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "# This will drop duplicates and keep the biggest test_acc of the duplicates\n",
    "#reduction_experiments = experiments[df_filter].sort_values('test_acc', ascending=False).drop_duplicates(subset=['config', 'nb_scene', 'nb_q_per_scene'], keep='first')\n",
    "# Sort back via trainable params\n",
    "reduction_experiments = experiments[df_filter]\n",
    "\n",
    "#reduction_experiments = reduction_experiments.sort_values(['rnn_state_size', 'extractor_out_chan', 'stem_out_chan', 'nb_resblock', 'classifier_conv_out', 'classifier_projection_out'], ascending=False)[columns]\n",
    "#reduction_experiments = reduction_experiments.sort_values('nb_trainable_param', ascending=False)[columns]\n",
    "reduction_experiments = reduction_experiments.sort_values('test_acc', ascending=False)[columns]\n",
    "#print(reduction_experiments.to_latex(index=False, formatters=latex_format_dict))\n",
    "reduction_experiments.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Extractor -- Parallel Extractor\n",
    "df_filter = (experiments['note'] == 'extractor') & (experiments['extractor_type'] == 'freq_time_separated')\n",
    "\n",
    "columns = ['mean_epoch_time','stem_out_chan', 'config','nb_trainable_param', 'extractor_nb_block', 'extractor_filters', 'extractor_projection_size', 'extractor_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "\n",
    "reduction_experiments = experiments[df_filter]\n",
    "\n",
    "# Average Results grouped over ['config', 'nb_scene', 'nb_q_per_scene']\n",
    "reduction_experiments = groupby_mean(reduction_experiments, \n",
    "                                     groupby_columns=['config', 'nb_scene', 'nb_q_per_scene'],\n",
    "                                     mean_columns=['train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned'],\n",
    "                                    selected_columns=columns,\n",
    "                                    add_count_col=False)\n",
    "\n",
    "reduction_experiments = convert_cols_to_int(reduction_experiments, ['nb_epoch_runned'])\n",
    "\n",
    "reduction_experiments = reduction_experiments.sort_values('mean_epoch_time', ascending=False)#[columns]\n",
    "#print(reduction_experiments.to_latex(index=False, formatters=latex_format_dict))\n",
    "reduction_experiments.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Extractor -- Interlaced Extractor -- Time First\n",
    "df_filter = (experiments['note'] == 'extractor') & (experiments['extractor_type'] == 'freq_time_interlaced')\n",
    "df_filter &= (experiments['config'].str.contains('timefirst'))\n",
    "\n",
    "columns = ['nb_trainable_param', 'extractor_nb_block', 'extractor_filters', 'extractor_projection_size', 'extractor_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "\n",
    "reduction_experiments = experiments[df_filter]\n",
    "\n",
    "#reduction_experiments.loc[:, 'time_first'] = experiments['config'].str.contains('timefirst')\n",
    "\n",
    "# Average Results grouped over ['config', 'nb_scene', 'nb_q_per_scene']\n",
    "reduction_experiments = groupby_mean(reduction_experiments, \n",
    "                                     groupby_columns=['config', 'nb_scene', 'nb_q_per_scene'],\n",
    "                                     mean_columns=['train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned'],\n",
    "                                    selected_columns=columns,\n",
    "                                    add_count_col=False)\n",
    "\n",
    "reduction_experiments = convert_cols_to_int(reduction_experiments, ['nb_epoch_runned'])\n",
    "\n",
    "reduction_experiments = reduction_experiments.sort_values('test_acc', ascending=False)#[columns]\n",
    "#print(reduction_experiments.to_latex(index=False, formatters=latex_format_dict))\n",
    "reduction_experiments.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Feature Extractor -- Interlaced Extractor -- Freq First\n",
    "df_filter = (experiments['note'] == 'extractor') & (experiments['extractor_type'] == 'freq_time_interlaced')\n",
    "df_filter &= (~experiments['config'].str.contains('timefirst'))\n",
    "\n",
    "columns = ['nb_trainable_param', 'extractor_nb_block', 'extractor_filters', 'extractor_projection_size', 'extractor_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "\n",
    "reduction_experiments = experiments[df_filter]\n",
    "\n",
    "#reduction_experiments.loc[:, 'time_first'] = experiments['config'].str.contains('timefirst')\n",
    "\n",
    "# Average Results grouped over ['config', 'nb_scene', 'nb_q_per_scene']\n",
    "reduction_experiments = groupby_mean(reduction_experiments, \n",
    "                                     groupby_columns=['config', 'nb_scene', 'nb_q_per_scene'],\n",
    "                                     mean_columns=['train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned'],\n",
    "                                    selected_columns=columns,\n",
    "                                    add_count_col=False)\n",
    "\n",
    "reduction_experiments = convert_cols_to_int(reduction_experiments, ['nb_epoch_runned'])\n",
    "\n",
    "reduction_experiments = reduction_experiments.sort_values('nb_trainable_param', ascending=False)#[columns]\n",
    "print(reduction_experiments.to_latex(index=False, formatters=latex_format_dict))\n",
    "#reduction_experiments.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Extractor -- Interlaced Extractor -- Both Freq First and Time First\n",
    "df_filter = (experiments['note'] == 'extractor') & (experiments['extractor_type'] == 'freq_time_interlaced')\n",
    "#df_filter &= (~experiments['config'].str.contains('timefirst'))\n",
    "\n",
    "columns = ['nb_trainable_param', 'first', 'extractor_nb_block', 'extractor_filters', 'extractor_projection_size', 'extractor_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "\n",
    "reduction_experiments = experiments[df_filter]\n",
    "\n",
    "reduction_experiments.loc[:, 'first'] = experiments['config'].apply(lambda c: 'Time' if 'timefirst' in c else 'Frequency')\n",
    "\n",
    "# Average Results grouped over ['config', 'nb_scene', 'nb_q_per_scene']\n",
    "reduction_experiments = groupby_mean(reduction_experiments, \n",
    "                                     groupby_columns=['config', 'nb_scene', 'nb_q_per_scene'],\n",
    "                                     mean_columns=['train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned'],\n",
    "                                    selected_columns=columns,\n",
    "                                    add_count_col=False)\n",
    "\n",
    "reduction_experiments = convert_cols_to_int(reduction_experiments, ['nb_epoch_runned'])\n",
    "\n",
    "reduction_experiments = reduction_experiments.sort_values(['first', 'nb_trainable_param'], ascending=False)#[columns]\n",
    "print(reduction_experiments.to_latex(index=False, formatters=latex_format_dict))\n",
    "#reduction_experiments.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Dataset size comparison -- Mixed -- 100k, 200k, 400k samples\n",
    "\n",
    "fig_name = \"dataset_size_all_samples.pdf\"\n",
    "df_filter = (experiments['note'] == 'dataset_size')\n",
    "columns = ['nb_sample', 'nb_scene', 'nb_q_per_scene', 'test_acc']\n",
    "exp = experiments[df_filter][columns]\n",
    "exp = exp.sort_values('nb_q_per_scene')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "lines = []\n",
    "\n",
    "grouped_by_sample = exp[exp['nb_sample'] == 400000]\n",
    "\n",
    "# Get colorlist\n",
    "group_unique_keys = grouped_by_sample['nb_scene'].unique()\n",
    "colorlist = {key: colors.rgb2hex(matplotlib.cm.gist_rainbow_r(i)) for key, i in\n",
    "             zip(group_unique_keys, np.linspace(0, 0.9, len(group_unique_keys)))}\n",
    "\n",
    "# Plot 400k lines & markers\n",
    "lines += ax.plot(grouped_by_sample['nb_q_per_scene'], grouped_by_sample['test_acc'], linewidth=1, linestyle=':', zorder=1)\n",
    "grouped_scatter(grouped_by_sample, 'nb_scene', 'nb_q_per_scene', 'test_acc', ax = ax, show_label=True, colorlist=colorlist, \n",
    "                label_modifier=lambda n: f\"{int(n/1000)}k scenes  \", additional_params={\"marker\": \",\", \"zorder\":2, \"edgecolor\":lines[0].get_markerfacecolor(), \"linewidth\":1})\n",
    "\n",
    "# Plot 200k lines & markers\n",
    "grouped_by_sample = exp[exp['nb_sample'] == 200000]\n",
    "lines += ax.plot(grouped_by_sample['nb_q_per_scene'], grouped_by_sample['test_acc'], linewidth=1, linestyle=':', zorder=1)\n",
    "grouped_scatter(grouped_by_sample, 'nb_scene', 'nb_q_per_scene', 'test_acc', ax = ax, show_label=False, colorlist=colorlist, additional_params={\"marker\": \",\", \"zorder\":2, \"edgecolor\":lines[1].get_markerfacecolor(), \"linewidth\":1})\n",
    "\n",
    "# Plot 100k lines & markers\n",
    "grouped_by_sample = exp[exp['nb_sample'] == 100000]\n",
    "lines += ax.plot(grouped_by_sample['nb_q_per_scene'], grouped_by_sample['test_acc'], linewidth=1, linestyle=':', zorder=1)\n",
    "grouped_scatter(grouped_by_sample, 'nb_scene', 'nb_q_per_scene', 'test_acc', ax = ax, show_label=False, colorlist=colorlist, additional_params={\"marker\": \",\", \"zorder\":2, \"edgecolor\":lines[2].get_markerfacecolor(), \"linewidth\":1})\n",
    "\n",
    "# Remove marker border from legend\n",
    "for legend_handle in ax.get_legend().legendHandles:\n",
    "    legend_handle.set_linewidths(0)\n",
    "\n",
    "# Add Second legend\n",
    "ax.add_artist(matplotlib.legend.Legend(ax, lines, ['400k samples', '200k samples', '100k samples'], loc='center right'))\n",
    "\n",
    "# Set axis infos\n",
    "ax.set_xscale('log')\n",
    "ax.set_xticks(exp['nb_q_per_scene'].unique())\n",
    "ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "ax.set_xlim([0.9, 43])\n",
    "ax.set_xlabel('Number of question per scene')\n",
    "ax.set_ylabel('Accuracy')\n",
    "\n",
    "fig.savefig(f\"stats/{fig_name}\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Batching -- Pad per batch\n",
    "df_filter = experiments['note'] == 'batching_real'\n",
    "\n",
    "columns = ['config', 'nb_trainable_param', 'extractor_type', 'extractor_nb_block', 'extractor_filters', 'extractor_projection_size', 'extractor_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "\n",
    "reduction_experiments = experiments[df_filter]\n",
    "\n",
    "reduction_experiments = reduction_experiments.sort_values('nb_trainable_param', ascending=False)#[columns]\n",
    "#print(reduction_experiments.to_latex(index=False, formatters=latex_format_dict))\n",
    "reduction_experiments[columns].style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_used_in_batching_exp = experiments[experiments['note'] == 'batching_real']['config'].values.tolist()\n",
    "df_filter = (experiments['config'].isin(config_used_in_batching_exp))\n",
    "df_filter &= (experiments['nb_scene'] == 50000) & (experiments['nb_q_per_scene'] == 4)\n",
    "#df_filter &= (~pd.isnull(experiments['note']))\n",
    "df_filter &= (experiments['note'].isin(['batching_real', 'final_dropout', 'extractor']))\n",
    "\n",
    "exp = experiments[df_filter]\n",
    "\n",
    "exp = exp.sort_values('test_acc', ascending=False).drop_duplicates(['nb_scene', 'nb_q_per_scene', 'config', 'note'], keep='first')\n",
    "\n",
    "#exp['padding'] = \"Whole set\" if exp['note'] == \"batching_real\" else \"Per batch\"\n",
    "exp['batching'] = exp['note'].apply(lambda x: \"Pad to set\" if x == \"batching_real\" else \"Pad to batch\")\n",
    "\n",
    "exp[exp_results_cols + ['batching']].sort_values('config')\n",
    "\n",
    "#experiments[df_filter][exp_results_cols + ['random_seed']].sort_values('config', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## More reduction with freq_time extractor\n",
    "df_filter = (experiments['note'] == 'reduction_extractor')\n",
    "df_filter |= (experiments['config'] == 'reduction_original_rnn_1024_fcn_conv_256_hidden_512_extractor_32_stem_32_resblock_3')\n",
    "\n",
    "\n",
    "columns = ['config', 'nb_trainable_param', 'extractor_type', 'extractor_nb_block', 'extractor_filters', 'extractor_projection_size', 'extractor_out_chan', 'stem_out_chan', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned']#, 'train_time']\n",
    "\n",
    "reduction_experiments = experiments[df_filter]\n",
    "\n",
    "reduction_experiments = reduction_experiments.sort_values('nb_trainable_param', ascending=False)#[columns]\n",
    "#print(reduction_experiments.to_latex(index=False, formatters=latex_format_dict))\n",
    "reduction_experiments[columns].style.format(latex_format_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "film-aqa-torch-1.3",
   "language": "python",
   "name": "film-aqa-torch-1.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
