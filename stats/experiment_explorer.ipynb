{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic functions -- Run Once\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "# Move up one folder to reach the repo root\n",
    "%cd ..\n",
    "\n",
    "from utils.notebook.generic import full_width_notebook\n",
    "\n",
    "full_width_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Paths, Imports & Configs\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from utils.notebook.experiment_explorer import get_experiments\n",
    "\n",
    "from utils.notebook.pandas import sub_cols_with_cond_and_create_new_col, grouped_scatter\n",
    "\n",
    "root_data_path = \"data\"\n",
    "#root_output_path = \"output/training\"\n",
    "root_output_path = \"output/synced_training\"\n",
    "\n",
    "# Helpers column selectors\n",
    "run_info_columns = ['prefix', 'nb_sample', 'config', 'nb_epoch_runned', 'stopped_early']\n",
    "more_accuracy_info_columns = ['0.6_at_epoch', '0.7_at_epoch', '0.8_at_epoch', '0.9_at_epoch']\n",
    "accuracy_columns = ['best_val_acc', 'train_acc', 'test_acc']\n",
    "loss_columns = ['best_val_loss', 'train_loss', 'test_loss']\n",
    "all_training_stats = ['all_train_acc', 'all_train_loss', 'all_val_acc', 'all_val_loss']\n",
    "model_config_columns = ['nb_trainable_param', 'word_embedding_dim', 'rnn_state_size', 'extractor_type', \n",
    "                        'stem_out_chan', 'nb_resblock', 'resblocks_out_chan', 'classifier_conv_out_chan', \n",
    "                        'classifier_type', 'classifier_global_pool', 'nb_answer']\n",
    "optimizer_columns = ['optimizer_type', 'optimizer_lr', 'optimizer_weight_decay', 'dropout_drop_prob']\n",
    "preprocessing_columns = ['pad_to_largest', 'resized_height', 'resized_width']\n",
    "timing_columns = ['train_time', 'mean_epoch_time']\n",
    "other_columns = ['nb_scene', 'nb_q_per_scene', 'date', 'batch_size', 'resnet_features', 'test_version', \n",
    "                 'random_seed', 'nb_non_trainable_param', 'total_nb_param', 'nb_epoch', 'stop_accuracy', 'folder', 'gpu_name']\n",
    "\n",
    "# Retrieve all experimentsi infos\n",
    "experiments = get_experiments(root_output_path)\n",
    "\n",
    "# Pretty printing\n",
    "format_dict = {\n",
    "    'total_nb_param': \"{:,d}\".format,\n",
    "    'nb_non_trainable_param': \"{:,d}\".format,\n",
    "    'nb_trainable_param': \"{:,d}\".format,\n",
    "    'nb_trainable_param_round': \"~ {:,d}\".format,\n",
    "    'nb_sample': \"{:,d}\".format,\n",
    "    'nb_scene': \"{:,d}\".format,\n",
    "    'rnn_state_size': \"{:,d}\".format,\n",
    "    'optimizer_lr': \"{:.2e}\".format,\n",
    "    'optimizer_weight_decay': \"{:.2e}\".format,\n",
    "    'best_val_acc': lambda x: \"{:.2f}%\".format(x*100) if not pd.isnull(x) else None,\n",
    "    'train_acc': lambda x: \"{:.2f}%\".format(x*100) if not pd.isnull(x) else None,\n",
    "    'test_acc': lambda x: \"{:.2f}%\".format(x*100) if not pd.isnull(x) else None,\n",
    "    '0.6_at_epoch': lambda x: x if not pd.isnull(x) else None,\n",
    "    '0.7_at_epoch': lambda x: x if not pd.isnull(x) else None,\n",
    "    '0.8_at_epoch': lambda x: x if not pd.isnull(x) else None,\n",
    "    '0.9_at_epoch': lambda x: x if not pd.isnull(x) else None\n",
    "}\n",
    "\n",
    "latex_format_dict = deepcopy(format_dict)\n",
    "latex_format_dict['nb_sample'] = lambda x: \"{:d}k\".format(x//1000)\n",
    "latex_format_dict['nb_scene'] = lambda x: \"{:d}k\".format(x//1000)\n",
    "latex_format_dict['best_val_acc'] = lambda x: \"{:.2f}\".format(x*100) if not pd.isnull(x) else None\n",
    "latex_format_dict['train_acc'] = lambda x: \"{:.2f}\".format(x*100) if not pd.isnull(x) else None\n",
    "latex_format_dict['test_acc'] = lambda x: \"{:.2f}\".format(x*100) if not pd.isnull(x) else None\n",
    "\n",
    "# Round number params to the closest thousand to facilitate comparison\n",
    "experiments['nb_trainable_param_round'] = experiments['nb_trainable_param'].apply(lambda x: x//1000 * 1000)\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "exp_results_cols = run_info_columns + ['nb_scene', 'nb_q_per_scene'] + accuracy_columns + more_accuracy_info_columns + ['nb_trainable_param_round', 'gpu_name']\n",
    "exp_results = experiments[exp_results_cols].sort_values(['nb_scene', 'test_acc'], ascending=[True, False])\n",
    "\n",
    "experiments.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available configs :\")\n",
    "set(experiments['config'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_results[(exp_results['stopped_early'] == 'stop_threshold') & (~exp_results['config'].str.contains('extractor'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp_results[exp_results['nb_scene'] == 50000]\n",
    "#exp_results[exp_results['nb_sample'] == 200000].sort_values(['nb_scene', 'nb_q_per_scene']).style.format(format_dict)\n",
    "exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp_results[(exp_results['nb_scene'] <= 10000) & (exp_results['config'].str.contains('reduction'))].sort_values('test_acc').style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = ((experiments['config'].str.contains('reduction')) & (~experiments['config'].str.contains('stem')) & (~experiments['config'].str.contains('extractor')) & (~experiments['config'].str.contains('resblock')) & (~experiments['config'].str.contains('avg'))) | ((experiments['config'] == 'film_original') & (exp_results['nb_scene'] == 20000) & (exp_results['nb_q_per_scene'] == 20))\n",
    "reduction_experiments = experiments[experiments['config'].str.contains('reduction')][exp_results_cols + timing_columns].sort_values('config')\n",
    "reduction_experiments#[reduction_experiments['stopped_early'] == 'NO']['folder'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_results[(exp_results['config'].str.contains('interlaced_smallest'))].sort_values('test_acc', ascending=True).style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "\n",
    "def plot_training_stats(dataframe, names=None, title=None, colormap=cm.viridis, ax=None):\n",
    "    nb_rows = len(dataframe.index)\n",
    "\n",
    "    colorlist = {key: colors.rgb2hex(colormap(i)) for key, i in\n",
    "                 zip(dataframe.index, np.linspace(0, 0.9, nb_rows))}\n",
    "\n",
    "    if title is None:\n",
    "        title = \"Training Stats\"\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, axs = plt.subplots(2,1)\n",
    "        \n",
    "    fig.suptitle(title)\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[1].set_title(\"Loss\")\n",
    "        \n",
    "    for row in dataframe.itertuples():\n",
    "        label = f\"{row.config} - {row.nb_scene//1000}k_{row.nb_q_per_scene}_q\"\n",
    "        lines = axs[0].plot(row.all_train_acc, label=f\"TRAIN - {label}\")\n",
    "        axs[0].plot(row.all_val_acc, color=lines[0].get_color(), linestyle=\"--\")\n",
    "        \n",
    "        axs[1].plot(row.all_train_loss, color=lines[0].get_color())\n",
    "        axs[1].plot(row.all_val_loss, label=f\"VAL - {label}\", color=lines[0].get_color(), linestyle=\"--\")\n",
    "        \n",
    "    # Draw legend out of the plot\n",
    "    for ax in axs:\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.5, box.height])\n",
    "\n",
    "        ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "    #for key, group in dataframe.groupby(group_key):\n",
    "    #    group.plot.scatter(ax=ax, x=x_axis, y=y_axis, c=colorlist[key], label=key, title=title)\n",
    "    \n",
    "with_training_stats = experiments[exp_results_cols + all_training_stats]\n",
    "fig, ax = plot_training_stats(with_training_stats[(with_training_stats['config'].str.contains('separated'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_stats(with_training_stats[with_training_stats['nb_q_per_scene'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of test_acc by (nb_sample, nb_scene)\n",
    "exp_results[(~exp_results['config'].str.contains('film_original')) & (~exp_results['config'].str.contains('extractor'))].hist(column='train_acc', by=['nb_sample', 'nb_scene'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "grouped_scatter(experiments, 'config', 'nb_sample', 'test_acc')\n",
    "\n",
    "#grouped_scatter(experiments[experiments['config'] == 'film_original'], 'nb_q_per_scene', 'nb_scene', 'test_acc')\n",
    "\n",
    "test = experiments.copy()\n",
    "\n",
    "test['perf_delta_orig_vs_small_rnn'] = test[test['config'] == 'film_original']['test_acc'] - test[test['config'] == 'film_original_small_rnn']['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sub_cols_with_cond_and_create_new_col(experiments.copy(), 'perf_delta_orig_vs_small_rnn', 'test_acc', test['config'] == 'film_original_small_rnn', test['config'] == 'film_original', test['config'] == 'film_original_small_rnn')\n",
    "\n",
    "test.sort_values(['nb_sample', 'nb_scene'], ascending=False)[run_info_columns + ['test_acc', 'perf_delta_orig_vs_small_rnn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table = experiments[experiments['config'] == 'film_original'][['nb_sample', 'nb_scene', 'nb_q_per_scene', 'train_acc', 'best_val_acc', 'test_acc', '0.8_at_epoch']].sort_values(['nb_sample', 'nb_scene']).fillna(\"None\").to_latex(formatters=latex_format_dict)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Network reduction -- GRU units\n",
    "df_filter = ((experiments['config'].str.contains('reduction')) & (~experiments['config'].str.contains('stem')) & (~experiments['config'].str.contains('extractor')) & (~experiments['config'].str.contains('resblock')) & (~experiments['config'].str.contains('avg'))) | ((experiments['config'] == 'film_original') & (exp_results['nb_scene'] == 20000) & (exp_results['nb_q_per_scene'] == 20))\n",
    "columns = ['rnn_state_size', 'nb_trainable_param', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned', 'train_time', 'random_seed']\n",
    "reduction_experiments = experiments[df_filter][columns].sort_values('nb_trainable_param', ascending=False)\n",
    "#print(reduction_experiments.to_latex(index=False, formatters=latex_format_dict))\n",
    "reduction_experiments.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Network reduction -- 1x1 Conv classifier\n",
    "df_filter = ((experiments['config'].str.contains('reduction')) & (~experiments['config'].str.contains('stem')) & (~experiments['config'].str.contains('extractor')) & (~experiments['config'].str.contains('resblock')) & (experiments['config'].str.contains('avg'))) | ((experiments['config'] == 'film_original_avg') & (exp_results['nb_scene'] == 20000) & (exp_results['nb_q_per_scene'] == 20))\n",
    "columns = ['rnn_state_size', 'nb_trainable_param', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned', 'train_time']\n",
    "reduction_experiments = experiments[df_filter][columns].sort_values('nb_trainable_param', ascending=False)\n",
    "#print(reduction_experiments.to_latex(index=False, formatters=latex_format_dict))\n",
    "reduction_experiments.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Network reduction -- Extractor 64\n",
    "#reduction_original_rnn_256_avg_extractor_64\n",
    "#reduction_original_rnn_256_avg_extractor_64_stem_64\n",
    "#reduction_original_rnn_256_avg_extractor_64_stem_64_1_resblock\n",
    "#reduction_original_rnn_256_avg_extractor_64_stem_64_2_resblock\n",
    "#reduction_original_rnn_256_avg_extractor_64_stem_64_3_resblock\n",
    "\n",
    "df_filter = experiments['config'].str.contains('reduction_original_rnn_256_avg_extractor_64')\n",
    "columns = ['nb_resblock', 'extractor_features', 'stem_out_chan', 'nb_trainable_param', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned', 'train_time']\n",
    "reduction_experiments = experiments[df_filter]\n",
    "reduction_experiments.loc[:, 'extractor_features'] = 64\n",
    "\n",
    "reduction_experiments = reduction_experiments[columns].sort_values('nb_trainable_param', ascending=False)\n",
    "#print(reduction_experiments.to_latex(index=False, formatters=latex_format_dict))\n",
    "reduction_experiments.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Network reduction -- Extractor 32\n",
    "#reduction_original_rnn_256_avg_extractor_32\n",
    "#reduction_original_rnn_256_avg_extractor_32_stem_32\n",
    "#reduction_original_rnn_256_avg_extractor_32_stem_32_1_resblock\n",
    "#reduction_original_rnn_256_avg_extractor_32_stem_32_2_resblock\n",
    "#reduction_original_rnn_256_avg_extractor_32_stem_32_3_resblock\n",
    "\n",
    "df_filter = (experiments['config'].str.contains('reduction_original_rnn_256_avg_extractor_32')) & (experiments['nb_epoch_runned'] <= 40)\n",
    "columns = ['nb_resblock', 'extractor_features', 'stem_out_chan', 'nb_trainable_param', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned', 'train_time']\n",
    "reduction_experiments = experiments[df_filter]\n",
    "reduction_experiments.loc[:, 'extractor_features'] = 32\n",
    "\n",
    "reduction_experiments = reduction_experiments[columns].sort_values('nb_trainable_param', ascending=False)\n",
    "#print(reduction_experiments.to_latex(index=False, formatters=latex_format_dict))\n",
    "reduction_experiments.style.format(latex_format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Network reduction -- Combined Extractor 32 & 64\n",
    "#reduction_original_rnn_256_avg_extractor_64\n",
    "#reduction_original_rnn_256_avg_extractor_64_stem_64\n",
    "#reduction_original_rnn_256_avg_extractor_64_stem_64_1_resblock\n",
    "#reduction_original_rnn_256_avg_extractor_64_stem_64_2_resblock\n",
    "#reduction_original_rnn_256_avg_extractor_64_stem_64_3_resblock\n",
    "\n",
    "df_64_filter = experiments['config'].str.contains('reduction_original_rnn_256_avg_extractor_64')\n",
    "df_32_filter = (experiments['config'].str.contains('reduction_original_rnn_256_avg_extractor_32')) & (experiments['nb_epoch_runned'] <= 40)\n",
    "columns = ['rnn_state_size', 'nb_resblock', 'extractor_features', 'stem_out_chan', 'nb_trainable_param', 'train_acc', 'best_val_acc', 'test_acc', 'nb_epoch_runned', 'train_time']\n",
    "reduction_experiments = experiments[df_64_filter | df_32_filter]\n",
    "reduction_experiments.loc[df_64_filter, 'extractor_features'] = 64\n",
    "reduction_experiments.loc[df_32_filter, 'extractor_features'] = 32\n",
    "reduction_experiments['train_time'] = reduction_experiments['train_time'].apply(lambda x: x._repr_base(format=\"sub_day\").split('.')[0])\n",
    "\n",
    "reduction_experiments = reduction_experiments[columns].sort_values(['extractor_features', 'stem_out_chan', 'nb_resblock'], ascending=[False, False, False])\n",
    "print(reduction_experiments.to_latex(index=False, formatters=latex_format_dict))\n",
    "#reduction_experiments.style.format(latex_format_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "film-aqa-torch-1.3",
   "language": "python",
   "name": "film-aqa-torch-1.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
