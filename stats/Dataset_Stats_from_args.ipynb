{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abdj2702/dev/maitrise/film-aqa\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:99% !important; }\n",
       "div.cell.selected { border-left-width: 1px !important; }\n",
       "div.output_scroll { resize: vertical !important }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Magic functions -- Run Once\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "# Move up one folder to reach the repo root\n",
    "%cd ..\n",
    "\n",
    "from utils.notebook.generic import full_width_notebook\n",
    "full_width_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdj2702/dev/maitrise/film-aqa/models/tools/lr_finder.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task 'Notebook Data Analysis' for version 'CLEAR_50k_4_inst_1024_win_50_overlap'\n",
      "\n",
      "Using device 'cuda:0'\n",
      "Creating Datasets\n",
      "Creating Dataloaders\n",
      "Preparation done\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import Markdown\n",
    "from main import parse_args_string, prepare_for_task\n",
    "\n",
    "data_root_path = \"data\"\n",
    "random_seed = 876944\n",
    "pad_per_batch = False\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "show_test_set_stats = False\n",
    "\n",
    "data_version_name = \"CLEAR_50k_4_inst_1024_win_50_overlap\"\n",
    "\n",
    "# FIXME : Clear mean & std might be wrong (It is written in the config file)\n",
    "\n",
    "arguments = (\n",
    "    f\"--notebook_data_analysis --version_name {data_version_name} \"\n",
    "    f\"--random_seed {random_seed} --dict_folder questions \"\n",
    "    f\"--no_feature_extractor --h5_image_input\"\n",
    ")\n",
    "\n",
    "if pad_per_batch:\n",
    "    arguments += \"--pad_per_batch\"\n",
    "            \n",
    "args = parse_args_string(arguments)\n",
    "task_and_more, dataloaders, model_and_more = prepare_for_task(args)\n",
    "print(\"Preparation done\")\n",
    "task, args, flags, paths, device = task_and_more\n",
    "film_model_config, film_model, optimizer, loss_criterion, scheduler, tensorboard = model_and_more\n",
    "datasets = {set_type:dloader.dataset for set_type, dloader in dataloaders.items() if set_type != 'test' or show_test_set_stats}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "def get_scene_metrics(dataset):\n",
    "    scenes = [s['definition'] for s in dataset.scenes.values()]\n",
    "    \n",
    "    scenes_metrics = []\n",
    "    individual_sound_durations = {}\n",
    "    \n",
    "    for scene in scenes:\n",
    "        scene_metrics = {\n",
    "            'id': int(scene['scene_index']),\n",
    "            'instruments' : Counter(),\n",
    "            'notes': Counter(),\n",
    "            'brightnesses': Counter(),\n",
    "            'loudnesses': Counter(),\n",
    "            'silence_duration': scene['silence_before'],\n",
    "            'sound_durations': [],\n",
    "            'sound_duration_mean': 0\n",
    "        }\n",
    "        \n",
    "        \n",
    "        for pos, sound in enumerate(scene['objects']):\n",
    "            scene_metrics['instruments'][sound['instrument']] += 1\n",
    "            scene_metrics['notes'][sound['note']] += 1\n",
    "            scene_metrics['brightnesses'][sound['brightness']] += 1\n",
    "            scene_metrics['loudnesses'][sound['loudness']] += 1\n",
    "            scene_metrics['silence_duration'] += sound['silence_after']\n",
    "            scene_metrics['sound_durations'].append(sound['duration'])\n",
    "            individual_sound_durations[sound['id']] = sound['duration']\n",
    "            \n",
    "        scene_metrics['number_sound'] = len(scene['objects'])\n",
    "            \n",
    "        scene_metrics['sound_duration_mean'] = mean(scene_metrics['sound_durations'])\n",
    "        scene_metrics['scene_total_duration'] = sum(scene_metrics['sound_durations']) + scene_metrics['silence_duration']\n",
    "        \n",
    "        scenes_metrics.append(scene_metrics)\n",
    "        \n",
    "        \n",
    "    # Global metrics\n",
    "    nb_sounds = [s['number_sound'] for s in scenes_metrics]\n",
    "    total_durations = [s['scene_total_duration'] for s in scenes_metrics]\n",
    "    silence_durations = [s['silence_duration'] for s in scenes_metrics]\n",
    "    individual_sound_durations = individual_sound_durations.values()\n",
    "    \n",
    "    \n",
    "    global_scene_metrics = {\n",
    "        'mean_number_sound' : mean(nb_sounds),\n",
    "        'min_number_sound' : min(nb_sounds),\n",
    "        'max_number_sound' : max(nb_sounds),\n",
    "        \n",
    "        'mean_duration' : mean(total_durations),\n",
    "        'min_duration' : min(total_durations),\n",
    "        'max_duration' : max(total_durations),\n",
    "        \n",
    "        'mean_silence_duration' : mean(silence_durations),\n",
    "        'min_silence_duration' : min(silence_durations),\n",
    "        'max_silence_duration' : max(silence_durations),\n",
    "        \n",
    "        'mean_sound_duration' : mean(individual_sound_durations),\n",
    "        'min_sound_duration' : min(individual_sound_durations),\n",
    "        'max_sound_duration' : max(individual_sound_durations),\n",
    "    }\n",
    "        \n",
    "    return global_scene_metrics, scenes_metrics\n",
    "\n",
    "\n",
    "def get_question_metrics(dataset):\n",
    "    # Global stats\n",
    "    global_metrics = {\n",
    "        'vocab_dist': Counter(),\n",
    "        'unique_word_per_position': [[] for i in range(dataset.longest_question_length)],\n",
    "        'word_per_position': [[] for i in range(dataset.longest_question_length)],\n",
    "        'answer_dist': Counter(),\n",
    "        'answer_family_dist': Counter(),\n",
    "        'total_unk_count': 0,\n",
    "        'total_word_count': 0,\n",
    "        'unique_word_list': dict(),\n",
    "        'unique_word_count': 0\n",
    "    }\n",
    "    \n",
    "    per_game_metrics = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        game = dataset.get_game(i, decode_tokens=True)\n",
    "        words = game['question'].split(' ')\n",
    "        \n",
    "        # Answer related\n",
    "        answer = game['answer']\n",
    "        global_metrics['answer_dist'][answer] += 1\n",
    "        answer_family = dataset.answer_to_family[answer]\n",
    "        global_metrics['answer_family_dist'][answer_family] += 1\n",
    "        \n",
    "        \n",
    "        # Program Related\n",
    "        question_program = game['program']\n",
    "        relation_nodes = [node for node in question_program if node['type'] == 'relate']\n",
    "        nb_relation = len(relation_nodes)\n",
    "        \n",
    "        # TODO :\n",
    "        # Scenes metrics\n",
    "            # How many different\n",
    "                # Instrument\n",
    "                # Brightness\n",
    "                # Loudness\n",
    "                # Notes\n",
    "            # How many sounds similar to answer\n",
    "                # Instrument\n",
    "                # Brightness\n",
    "                # Loudness\n",
    "                # Notes\n",
    "            # Nb sound in scene\n",
    "            # Silence metrics\n",
    "            \n",
    "        # TODO : How many attribute define the \"related\" value\n",
    "        # TODO : Nb filter associated with requested object (How many attributes are we refering too Ex : sound = 0 loud sound = 1, loud bright sound = 2, loud bright F# = 3)\n",
    "        # TODO : Are we refering to another object with similar properties in the same question ? (Ex another loud sound, another sound of the same instrument, etc)\n",
    "        game_metrics = {\n",
    "            'id': game['id'],\n",
    "            'scene_id': game['image']['id'],\n",
    "            'answer': answer,\n",
    "            'answer_family': answer_family,\n",
    "            'have_relation': nb_relation > 0,\n",
    "            'nb_relation': nb_relation,\n",
    "            'relations': [node['value_inputs'][0] for node in relation_nodes],\n",
    "            'nb_output_per_relation': [len(node['_output']) for node in relation_nodes],\n",
    "            'unk_count': 0,\n",
    "            'length': len(words),\n",
    "            'refer_to_answer_family_in_question': answer_family in words,   # FIXME : This won't work for count, position_global and postion_instrument\n",
    "            'answer_in_question': answer in words,    # FIXME : We are most probably refering to another object of the scene IE : What is the loudness of the cello playing after the \"loud\" violin ?\n",
    "            'word_dist': Counter(),\n",
    "            'word_per_position': [[] for i in range(dataset.longest_question_length)]\n",
    "        }\n",
    "        \n",
    "        for word_pos, word in enumerate(words):\n",
    "            if word != '<unk>':\n",
    "                global_metrics['vocab_dist'][word] += 1\n",
    "                global_metrics['total_word_count'] += 1\n",
    "                \n",
    "            global_metrics['unique_word_list'][word] = 1   # We only need the key, faster to assign 1 everytime then check if present in list\n",
    "            game_metrics['word_dist'][word] += 1\n",
    "            game_metrics['word_per_position'][word_pos].append(word)\n",
    "            global_metrics['word_per_position'][word_pos].append(word)\n",
    "         \n",
    "        game_metrics['unk_count'] = game_metrics['word_dist']['<unk>']\n",
    "        global_metrics['total_unk_count'] += game_metrics['unk_count']\n",
    "                \n",
    "        per_game_metrics.append(game_metrics)\n",
    "            \n",
    "            \n",
    "    lengths = [m['length'] for m in per_game_metrics]\n",
    "    global_metrics['mean_length'] = mean(lengths)\n",
    "    global_metrics['min_length'] = min(lengths)\n",
    "    global_metrics['max_length'] = max(lengths)\n",
    "    \n",
    "    global_metrics['unique_word_list'] = list(global_metrics['unique_word_list'].keys())\n",
    "    global_metrics['unique_word_count'] = len(global_metrics['unique_word_list'])\n",
    "    \n",
    "    for pos, words in enumerate(global_metrics['word_per_position']):\n",
    "        global_metrics['unique_word_per_position'][pos] = list(set(words))\n",
    "        \n",
    "                \n",
    "    return global_metrics, per_game_metrics\n",
    "        \n",
    "    \n",
    "def parse_program(question_program):\n",
    "    relations = []\n",
    "    \n",
    "    for i, node in enumerate(question_program):\n",
    "        if node['type'] == 'scene':\n",
    "            # Nothing to do with scene node\n",
    "            continue\n",
    "            \n",
    "        elif node['type'].startswith('filter'):\n",
    "            print(\"filter\")\n",
    "        elif node['type'] == 'relate':\n",
    "            relations.append(node['value_input'][0])\n",
    "            \n",
    "        elif node['type'].startswith('query'):\n",
    "            print(\"YO\")\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "question_global_metrics, per_game_metrics = get_question_metrics(datasets['train'])\n",
    "scenes_global_metrics, scenes_metrics = get_scene_metrics(datasets['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['vocab_dist', 'unique_word_per_position', 'word_per_position', 'answer_dist', 'answer_family_dist', 'total_unk_count', 'total_word_count', 'unique_word_list', 'unique_word_count', 'mean_length', 'min_length', 'max_length'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_global_metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.12387142857143\n",
      "6\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(question_global_metrics['mean_length'])\n",
    "print(question_global_metrics['min_length'])\n",
    "print(question_global_metrics['max_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'scene_id': 0,\n",
       " 'answer': 'quiet',\n",
       " 'answer_family': 'loudness',\n",
       " 'have_relation': True,\n",
       " 'nb_relation': 1,\n",
       " 'relations': ['before'],\n",
       " 'nb_output_per_relation': [8],\n",
       " 'unk_count': 0,\n",
       " 'length': 16,\n",
       " 'refer_to_answer_family_in_question': True,\n",
       " 'answer_in_question': True,\n",
       " 'word_dist': Counter({'what': 1,\n",
       "          'is': 1,\n",
       "          'the': 3,\n",
       "          'loudness': 1,\n",
       "          'of': 1,\n",
       "          'dark': 1,\n",
       "          'clarinet': 1,\n",
       "          'sound': 2,\n",
       "          'playing': 1,\n",
       "          'before': 1,\n",
       "          'quiet': 1,\n",
       "          'bright': 1,\n",
       "          '?': 1}),\n",
       " 'word_per_position': [['what'],\n",
       "  ['is'],\n",
       "  ['the'],\n",
       "  ['loudness'],\n",
       "  ['of'],\n",
       "  ['the'],\n",
       "  ['dark'],\n",
       "  ['clarinet'],\n",
       "  ['sound'],\n",
       "  ['playing'],\n",
       "  ['before'],\n",
       "  ['the'],\n",
       "  ['quiet'],\n",
       "  ['bright'],\n",
       "  ['sound'],\n",
       "  ['?'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  []]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_game_metrics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['vocab_dist', 'unique_word_per_position', 'word_per_position', 'answer_dist', 'answer_family_dist', 'total_unk_count', 'total_word_count', 'unique_word_list', 'unique_word_count'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_global_metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07504285714285715"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(question_global_metrics['answer_dist'].items(), key= lambda x:x[1], reverse=True)[0][1] / 140000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'scene_id': 0,\n",
       " 'answer': 'quiet',\n",
       " 'answer_family': 'loudness',\n",
       " 'have_relation': True,\n",
       " 'nb_relation': 1,\n",
       " 'relations': ['before'],\n",
       " 'nb_output_per_relation': [8],\n",
       " 'unk_count': 0,\n",
       " 'length': 16,\n",
       " 'refer_to_answer_family_in_question': True,\n",
       " 'answer_in_question': True,\n",
       " 'word_dist': Counter({'what': 1,\n",
       "          'is': 1,\n",
       "          'the': 3,\n",
       "          'loudness': 1,\n",
       "          'of': 1,\n",
       "          'dark': 1,\n",
       "          'clarinet': 1,\n",
       "          'sound': 2,\n",
       "          'playing': 1,\n",
       "          'before': 1,\n",
       "          'quiet': 1,\n",
       "          'bright': 1,\n",
       "          '?': 1}),\n",
       " 'word_per_position': [['what'],\n",
       "  ['is'],\n",
       "  ['the'],\n",
       "  ['loudness'],\n",
       "  ['of'],\n",
       "  ['the'],\n",
       "  ['dark'],\n",
       "  ['clarinet'],\n",
       "  ['sound'],\n",
       "  ['playing'],\n",
       "  ['before'],\n",
       "  ['the'],\n",
       "  ['quiet'],\n",
       "  ['bright'],\n",
       "  ['sound'],\n",
       "  ['?'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  []]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_game_metrics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_templates_infos(dataset):\n",
    "    all_templates = []\n",
    "    templates_per_scene = {}\n",
    "    for scene_id, scene_info in dataset.scenes.items():\n",
    "        templates_idx = [dataset.questions[question_id]['template_index'] for question_id in scene_info['question_idx']]\n",
    "        templates_per_scene[scene_id] = templates_idx\n",
    "        all_templates += templates_idx\n",
    "        \n",
    "    return all_templates, templates_per_scene\n",
    "\n",
    "# TODO: Show discrete histogram of all templates\n",
    "# TODO: Show 2d matrix of templates_per_scene (Too much data ?)\n",
    "all_templates, templates_per_scene = get_templates_infos(datasets['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "next(iter(datasets['train'].scenes.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['train'].get_game(0, decode_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenes Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.notebook.dataset_analysis import scene_object_per_position, plot_attribute_per_position_matrix, plot_scene_distribution_per_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max([len(s['definition']['objects']) for s in dataset.scenes.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Scene Position Analysis per attribute\n",
    "attributes = ['instrument', 'loudness', 'note', 'brightness', 'id']\n",
    "\n",
    "for set_type, dataset in datasets.items():\n",
    "    display(Markdown(f\"## [{set_type.capitalize()}] Scene Position Analysis\"))\n",
    "    for attribute in attributes:\n",
    "        obj_per_position = scene_object_per_position(list(dataset.scenes.values()), attribute=attribute)\n",
    "        plot_attribute_per_position_matrix(obj_per_position, attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scene distribution per attribute\n",
    "\n",
    "for set_type, dataset in datasets.items():\n",
    "    display(Markdown(f\"## [{set_type.capitalize()}] Scene distribution Analysis\"))\n",
    "    for attribute in attributes:\n",
    "        plot_scene_distribution_per_attribute(list(dataset.scenes.values()), attribute, norm_hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Durations\n",
    "from utils.notebook.dataset_analysis import plot_scene_duration_hist, plot_scene_total_silence_distribution, plot_scene_silence_by_position_distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i, (set_type, dataset) in enumerate(datasets.items()):\n",
    "    display(Markdown(f\"## [{set_type.capitalize()}] Scene durations Analysis\"))\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "        \n",
    "    plot_scene_duration_hist(dataset.scenes.values(), title=f\"[{set_type.capitalize()}]Scene durations\", legend_label=f\"{set_type.capitalize()}\", fig_ax=(fig, axs[0]), norm_hist=False)\n",
    "    plot_scene_total_silence_distribution(dataset.scenes.values(), title=f\"[{set_type.capitalize()}]Silence durations\", legend_label=f\"{set_type.capitalize()}\", fig_ax=(fig, axs[1]), norm_hist=False)\n",
    "    plot_scene_silence_by_position_distribution(dataset.scenes.values(), title=f\"[{set_type.capitalize()}]Silence per position\", legend_label=f\"{set_type.capitalize()}\", norm_hist=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "film-aqa-torch-1.3",
   "language": "python",
   "name": "film-aqa-torch-1.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
